2021-05-25 17:24:36.090627 (MainThread): Running with dbt=0.19.1
2021-05-25 17:24:36.265185 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/home/femke/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-05-25 17:24:36.266884 (MainThread): Tracking: tracking
2021-05-25 17:24:36.277056 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f62d1e9ee80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f62d37d7130>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f62d37d71f0>]}
2021-05-25 17:24:36.292579 (MainThread): Partial parsing not enabled
2021-05-25 17:24:36.293274 (MainThread): Parsing macros/catalog.sql
2021-05-25 17:24:36.301684 (MainThread): Parsing macros/adapters.sql
2021-05-25 17:24:36.323794 (MainThread): Parsing macros/etc.sql
2021-05-25 17:24:36.325649 (MainThread): Parsing macros/materializations/snapshot.sql
2021-05-25 17:24:36.327290 (MainThread): Parsing macros/materializations/copy.sql
2021-05-25 17:24:36.331515 (MainThread): Parsing macros/materializations/table.sql
2021-05-25 17:24:36.338584 (MainThread): Parsing macros/materializations/incremental.sql
2021-05-25 17:24:36.358737 (MainThread): Parsing macros/materializations/view.sql
2021-05-25 17:24:36.360814 (MainThread): Parsing macros/materializations/seed.sql
2021-05-25 17:24:36.363179 (MainThread): Parsing macros/core.sql
2021-05-25 17:24:36.365817 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-05-25 17:24:36.366841 (MainThread): Parsing macros/schema_tests/unique.sql
2021-05-25 17:24:36.368008 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-05-25 17:24:36.369258 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-05-25 17:24:36.371174 (MainThread): Parsing macros/materializations/helpers.sql
2021-05-25 17:24:36.379497 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-05-25 17:24:36.387735 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-05-25 17:24:36.392131 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-05-25 17:24:36.406236 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-05-25 17:24:36.426670 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-05-25 17:24:36.427859 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-05-25 17:24:36.440791 (MainThread): Parsing macros/materializations/table/table.sql
2021-05-25 17:24:36.445602 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-05-25 17:24:36.449152 (MainThread): Parsing macros/materializations/view/view.sql
2021-05-25 17:24:36.453657 (MainThread): Parsing macros/materializations/common/merge.sql
2021-05-25 17:24:36.463188 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-05-25 17:24:36.464397 (MainThread): Parsing macros/etc/query.sql
2021-05-25 17:24:36.465117 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-05-25 17:24:36.465752 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-05-25 17:24:36.467200 (MainThread): Parsing macros/etc/datetime.sql
2021-05-25 17:24:36.473280 (MainThread): Parsing macros/etc/is_incremental.sql
2021-05-25 17:24:36.474649 (MainThread): Parsing macros/adapters/common.sql
2021-05-25 17:24:36.507395 (MainThread): Partial parsing not enabled
2021-05-25 17:24:36.523249 (MainThread): Acquiring new bigquery connection "model.resourceplanner.my_second_dbt_model".
2021-05-25 17:24:36.529884 (MainThread): Acquiring new bigquery connection "model.resourceplanner.my_first_dbt_model".
2021-05-25 17:24:36.574234 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '4e3d3a52-ae59-4c23-af5f-d66a62bff050', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f62d0f1ae80>]}
2021-05-25 17:24:36.576595 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '4e3d3a52-ae59-4c23-af5f-d66a62bff050', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f62d0fea5e0>]}
2021-05-25 17:24:36.576743 (MainThread): Found 2 models, 4 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-05-25 17:24:36.577331 (MainThread): 
2021-05-25 17:24:36.577542 (MainThread): Acquiring new bigquery connection "master".
2021-05-25 17:24:36.578087 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_oef-stage".
2021-05-25 17:24:36.578202 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-05-25 17:24:36.578266 (ThreadPoolExecutor-0_0): Got an error when attempting to create a bigquery client: ''NoneType' object has no attribute 'keys''
2021-05-25 17:24:36.578506 (MainThread): Connection 'master' was properly closed.
2021-05-25 17:24:36.578549 (MainThread): Connection 'list_oef-stage' was properly closed.
2021-05-25 17:24:36.578659 (MainThread): ERROR: Database Error
  'NoneType' object has no attribute 'keys'
2021-05-25 17:24:36.578803 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f62d10c5a60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f62d0fea580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f62d0f1a730>]}
2021-05-25 17:24:36.578894 (MainThread): Flushing usage events
2021-05-26 10:54:44.818441 (MainThread): Running with dbt=0.19.1
2021-05-26 10:54:44.988903 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/home/femke/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-05-26 10:54:44.989591 (MainThread): Tracking: tracking
2021-05-26 10:54:44.999698 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fef1f4f4c70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fef20e280a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fef20e284c0>]}
2021-05-26 10:54:45.015261 (MainThread): Partial parsing not enabled
2021-05-26 10:54:45.015997 (MainThread): Parsing macros/catalog.sql
2021-05-26 10:54:45.024293 (MainThread): Parsing macros/adapters.sql
2021-05-26 10:54:45.044206 (MainThread): Parsing macros/etc.sql
2021-05-26 10:54:45.045620 (MainThread): Parsing macros/materializations/snapshot.sql
2021-05-26 10:54:45.046842 (MainThread): Parsing macros/materializations/copy.sql
2021-05-26 10:54:45.049994 (MainThread): Parsing macros/materializations/table.sql
2021-05-26 10:54:45.057090 (MainThread): Parsing macros/materializations/incremental.sql
2021-05-26 10:54:45.065735 (MainThread): Parsing macros/materializations/view.sql
2021-05-26 10:54:45.067709 (MainThread): Parsing macros/materializations/seed.sql
2021-05-26 10:54:45.070239 (MainThread): Parsing macros/core.sql
2021-05-26 10:54:45.073192 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-05-26 10:54:45.074407 (MainThread): Parsing macros/schema_tests/unique.sql
2021-05-26 10:54:45.075556 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-05-26 10:54:45.076852 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-05-26 10:54:45.078736 (MainThread): Parsing macros/materializations/helpers.sql
2021-05-26 10:54:45.085381 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-05-26 10:54:45.086690 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-05-26 10:54:45.091380 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-05-26 10:54:45.105315 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-05-26 10:54:45.126032 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-05-26 10:54:45.127247 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-05-26 10:54:45.139667 (MainThread): Parsing macros/materializations/table/table.sql
2021-05-26 10:54:45.144272 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-05-26 10:54:45.147744 (MainThread): Parsing macros/materializations/view/view.sql
2021-05-26 10:54:45.152628 (MainThread): Parsing macros/materializations/common/merge.sql
2021-05-26 10:54:45.161661 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-05-26 10:54:45.162799 (MainThread): Parsing macros/etc/query.sql
2021-05-26 10:54:45.163500 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-05-26 10:54:45.164128 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-05-26 10:54:45.165541 (MainThread): Parsing macros/etc/datetime.sql
2021-05-26 10:54:45.171541 (MainThread): Parsing macros/etc/is_incremental.sql
2021-05-26 10:54:45.172711 (MainThread): Parsing macros/adapters/common.sql
2021-05-26 10:54:45.204202 (MainThread): Partial parsing not enabled
2021-05-26 10:54:45.220505 (MainThread): Acquiring new bigquery connection "model.resourceplanner.my_second_dbt_model".
2021-05-26 10:54:45.227310 (MainThread): Acquiring new bigquery connection "model.resourceplanner.my_first_dbt_model".
2021-05-26 10:54:45.272967 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '334e029b-f04b-4b69-9ec2-e2cd62473cfe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fef1e570f70>]}
2021-05-26 10:54:45.275636 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '334e029b-f04b-4b69-9ec2-e2cd62473cfe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fef1e64c490>]}
2021-05-26 10:54:45.275777 (MainThread): Found 2 models, 4 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-05-26 10:54:45.276377 (MainThread): 
2021-05-26 10:54:45.276591 (MainThread): Acquiring new bigquery connection "master".
2021-05-26 10:54:45.277177 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_oef-stage".
2021-05-26 10:54:45.277307 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-05-26 10:54:45.724650 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_oef-stage_TestRecoursePlanner".
2021-05-26 10:54:45.725051 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2021-05-26 10:54:45.728674 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-05-26 10:54:45.991776 (MainThread): 12:54:45 | Concurrency: 5 threads (target='dev')
2021-05-26 10:54:45.992182 (MainThread): 12:54:45 | 
2021-05-26 10:54:45.994083 (Thread-1): Began running node model.resourceplanner.my_first_dbt_model
2021-05-26 10:54:45.994259 (Thread-1): 12:54:45 | 1 of 2 START table model TestRecoursePlanner.my_first_dbt_model...... [RUN]
2021-05-26 10:54:45.994492 (Thread-1): Acquiring new bigquery connection "model.resourceplanner.my_first_dbt_model".
2021-05-26 10:54:45.994560 (Thread-1): Compiling model.resourceplanner.my_first_dbt_model
2021-05-26 10:54:45.996196 (Thread-1): Writing injected SQL for node "model.resourceplanner.my_first_dbt_model"
2021-05-26 10:54:45.996440 (Thread-1): finished collecting timing info
2021-05-26 10:54:46.043074 (Thread-1): Writing runtime SQL for node "model.resourceplanner.my_first_dbt_model"
2021-05-26 10:54:46.043655 (Thread-1): Opening a new connection, currently in state closed
2021-05-26 10:54:46.046933 (Thread-1): On model.resourceplanner.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "Bigquery", "target_name": "dev", "node_id": "model.resourceplanner.my_first_dbt_model"} */


  create or replace table `oef-stage`.`TestRecoursePlanner`.`my_first_dbt_model`
  
  
  OPTIONS()
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
    
2021-05-26 10:54:47.122483 (Thread-1): Unhandled error while running:
/* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "Bigquery", "target_name": "dev", "node_id": "model.resourceplanner.my_first_dbt_model"} */


  create or replace table `oef-stage`.`TestRecoursePlanner`.`my_first_dbt_model`
  
  
  OPTIONS()
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
    
2021-05-26 10:54:47.122600 (Thread-1): 404 GET https://bigquery.googleapis.com/bigquery/v2/projects/oef-stage/queries/395bafb2-8921-454e-84a7-5de71f68afb3?maxResults=0&location=EU&prettyPrint=false: Not found: Job oef-stage:EU.395bafb2-8921-454e-84a7-5de71f68afb3

(job ID: 395bafb2-8921-454e-84a7-5de71f68afb3)

                                                              -----Query Job SQL Follows-----                                                              

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "Bigquery", "target_name": "dev", "node_id": "model.resourceplanner.my_first_dbt_model"} */
   2:
   3:
   4:  create or replace table `oef-stage`.`TestRecoursePlanner`.`my_first_dbt_model`
   5:  
   6:  
   7:  OPTIONS()
   8:  as (
   9:    /*
  10:    Welcome to your first dbt model!
  11:    Did you know that you can also configure models directly within SQL files?
  12:    This will override configurations stated in dbt_project.yml
  13:
  14:    Try changing "table" to "view" below
  15:*/
  16:
  17:
  18:
  19:with source_data as (
  20:
  21:    select 1 as id
  22:    union all
  23:    select null as id
  24:
  25:)
  26:
  27:select *
  28:from source_data
  29:
  30:/*
  31:    Uncomment the line below to remove records with null `id` values
  32:*/
  33:
  34:-- where id is not null
  35:  );
  36:    
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
2021-05-26 10:54:47.122712 (Thread-1): finished collecting timing info
2021-05-26 10:54:47.123065 (Thread-1): Runtime Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  404 GET https://bigquery.googleapis.com/bigquery/v2/projects/oef-stage/queries/395bafb2-8921-454e-84a7-5de71f68afb3?maxResults=0&location=EU&prettyPrint=false: Not found: Job oef-stage:EU.395bafb2-8921-454e-84a7-5de71f68afb3
  
  (job ID: 395bafb2-8921-454e-84a7-5de71f68afb3)
Traceback (most recent call last):
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 149, in exception_handler
    yield
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 327, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 520, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1146, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/job/base.py", line 631, in result
    return super(_AsyncJob, self).result(timeout=timeout, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/future/polling.py", line 129, in result
    self._blocking_poll(timeout=timeout, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1042, in _blocking_poll
    super(QueryJob, self)._blocking_poll(timeout=timeout, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/future/polling.py", line 107, in _blocking_poll
    retry_(self._done_or_raise)(**kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/future/polling.py", line 85, in _done_or_raise
    if not self.done(**kwargs):
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1022, in done
    self._query_results = self._client._get_query_results(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 1557, in _get_query_results
    resource = self._call_api(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 636, in _call_api
    return call()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/_http.py", line 438, in api_request
    raise exceptions.from_http_response(response)
google.api_core.exceptions.NotFound: 404 GET https://bigquery.googleapis.com/bigquery/v2/projects/oef-stage/queries/395bafb2-8921-454e-84a7-5de71f68afb3?maxResults=0&location=EU&prettyPrint=false: Not found: Job oef-stage:EU.395bafb2-8921-454e-84a7-5de71f68afb3

(job ID: 395bafb2-8921-454e-84a7-5de71f68afb3)

                                                              -----Query Job SQL Follows-----                                                              

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "Bigquery", "target_name": "dev", "node_id": "model.resourceplanner.my_first_dbt_model"} */
   2:
   3:
   4:  create or replace table `oef-stage`.`TestRecoursePlanner`.`my_first_dbt_model`
   5:  
   6:  
   7:  OPTIONS()
   8:  as (
   9:    /*
  10:    Welcome to your first dbt model!
  11:    Did you know that you can also configure models directly within SQL files?
  12:    This will override configurations stated in dbt_project.yml
  13:
  14:    Try changing "table" to "view" below
  15:*/
  16:
  17:
  18:
  19:with source_data as (
  20:
  21:    select 1 as id
  22:    union all
  23:    select null as id
  24:
  25:)
  26:
  27:select *
  28:from source_data
  29:
  30:/*
  31:    Uncomment the line below to remove records with null `id` values
  32:*/
  33:
  34:-- where id is not null
  35:  );
  36:    
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/base.py", line 287, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/base.py", line 389, in run
    return self.execute(compiled_node, manifest)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/run.py", line 248, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 128, in macro
  File "/home/femke/dbt-env/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/home/femke/dbt-env/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 227, in execute
    return self.connections.execute(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 338, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 329, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 181, in exception_handler
    raise RuntimeException(exc_message)
dbt.exceptions.RuntimeException: Runtime Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  404 GET https://bigquery.googleapis.com/bigquery/v2/projects/oef-stage/queries/395bafb2-8921-454e-84a7-5de71f68afb3?maxResults=0&location=EU&prettyPrint=false: Not found: Job oef-stage:EU.395bafb2-8921-454e-84a7-5de71f68afb3
  
  (job ID: 395bafb2-8921-454e-84a7-5de71f68afb3)
2021-05-26 10:54:47.124993 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '334e029b-f04b-4b69-9ec2-e2cd62473cfe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fef1e658cd0>]}
2021-05-26 10:54:47.125544 (Thread-1): 12:54:47 | 1 of 2 ERROR creating table model TestRecoursePlanner.my_first_dbt_model [ERROR in 1.13s]
2021-05-26 10:54:47.125735 (Thread-1): Finished running node model.resourceplanner.my_first_dbt_model
2021-05-26 10:54:47.126212 (Thread-3): Began running node model.resourceplanner.my_second_dbt_model
2021-05-26 10:54:47.126296 (Thread-3): 12:54:47 | 2 of 2 SKIP relation TestRecoursePlanner.my_second_dbt_model......... [SKIP]
2021-05-26 10:54:47.126405 (Thread-3): Finished running node model.resourceplanner.my_second_dbt_model
2021-05-26 10:54:47.127103 (MainThread): Acquiring new bigquery connection "master".
2021-05-26 10:54:47.127328 (MainThread): 12:54:47 | 
2021-05-26 10:54:47.127479 (MainThread): 12:54:47 | Finished running 1 table model, 1 view model in 1.85s.
2021-05-26 10:54:47.127570 (MainThread): Connection 'master' was properly closed.
2021-05-26 10:54:47.127609 (MainThread): Connection 'model.resourceplanner.my_first_dbt_model' was properly closed.
2021-05-26 10:54:47.127640 (MainThread): Connection 'list_oef-stage_TestRecoursePlanner' was properly closed.
2021-05-26 10:54:47.135410 (MainThread): 
2021-05-26 10:54:47.135538 (MainThread): Completed with 1 error and 0 warnings:
2021-05-26 10:54:47.135637 (MainThread): 
2021-05-26 10:54:47.136721 (MainThread): Runtime Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
2021-05-26 10:54:47.136822 (MainThread):   404 GET https://bigquery.googleapis.com/bigquery/v2/projects/oef-stage/queries/395bafb2-8921-454e-84a7-5de71f68afb3?maxResults=0&location=EU&prettyPrint=false: Not found: Job oef-stage:EU.395bafb2-8921-454e-84a7-5de71f68afb3
2021-05-26 10:54:47.136938 (MainThread):   
2021-05-26 10:54:47.137023 (MainThread):   (job ID: 395bafb2-8921-454e-84a7-5de71f68afb3)
2021-05-26 10:54:47.137109 (MainThread): 
Done. PASS=0 WARN=0 ERROR=1 SKIP=1 TOTAL=2
2021-05-26 10:54:47.137259 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fef1e626ac0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fef1e551610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fef1e61d310>]}
2021-05-26 10:54:47.137386 (MainThread): Flushing usage events
2021-05-26 11:50:35.195832 (MainThread): Running with dbt=0.19.1
2021-05-26 11:50:35.360740 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/home/femke/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-05-26 11:50:35.361357 (MainThread): Tracking: tracking
2021-05-26 11:50:35.371490 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0907878f40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f090912f250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f090912f610>]}
2021-05-26 11:50:35.388287 (MainThread): Partial parsing not enabled
2021-05-26 11:50:35.388997 (MainThread): Parsing macros/catalog.sql
2021-05-26 11:50:35.396909 (MainThread): Parsing macros/adapters.sql
2021-05-26 11:50:35.417743 (MainThread): Parsing macros/etc.sql
2021-05-26 11:50:35.419106 (MainThread): Parsing macros/materializations/snapshot.sql
2021-05-26 11:50:35.420312 (MainThread): Parsing macros/materializations/copy.sql
2021-05-26 11:50:35.423396 (MainThread): Parsing macros/materializations/table.sql
2021-05-26 11:50:35.430275 (MainThread): Parsing macros/materializations/incremental.sql
2021-05-26 11:50:35.438759 (MainThread): Parsing macros/materializations/view.sql
2021-05-26 11:50:35.440647 (MainThread): Parsing macros/materializations/seed.sql
2021-05-26 11:50:35.442960 (MainThread): Parsing macros/core.sql
2021-05-26 11:50:35.445506 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-05-26 11:50:35.446523 (MainThread): Parsing macros/schema_tests/unique.sql
2021-05-26 11:50:35.447620 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-05-26 11:50:35.448858 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-05-26 11:50:35.450655 (MainThread): Parsing macros/materializations/helpers.sql
2021-05-26 11:50:35.456519 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-05-26 11:50:35.457767 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-05-26 11:50:35.462080 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-05-26 11:50:35.476880 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-05-26 11:50:35.497273 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-05-26 11:50:35.498504 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-05-26 11:50:35.511234 (MainThread): Parsing macros/materializations/table/table.sql
2021-05-26 11:50:35.515741 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-05-26 11:50:35.519031 (MainThread): Parsing macros/materializations/view/view.sql
2021-05-26 11:50:35.523292 (MainThread): Parsing macros/materializations/common/merge.sql
2021-05-26 11:50:35.532282 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-05-26 11:50:35.533425 (MainThread): Parsing macros/etc/query.sql
2021-05-26 11:50:35.534108 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-05-26 11:50:35.534720 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-05-26 11:50:35.536061 (MainThread): Parsing macros/etc/datetime.sql
2021-05-26 11:50:35.541899 (MainThread): Parsing macros/etc/is_incremental.sql
2021-05-26 11:50:35.542989 (MainThread): Parsing macros/adapters/common.sql
2021-05-26 11:50:35.573881 (MainThread): Partial parsing not enabled
2021-05-26 11:50:35.590129 (MainThread): Acquiring new bigquery connection "model.resourceplanner.my_second_dbt_model".
2021-05-26 11:50:35.596808 (MainThread): Acquiring new bigquery connection "model.resourceplanner.my_first_dbt_model".
2021-05-26 11:50:35.640477 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd337bef9-45d4-4cab-8eac-f0d274e834b6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0906876dc0>]}
2021-05-26 11:50:35.643014 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd337bef9-45d4-4cab-8eac-f0d274e834b6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0906953520>]}
2021-05-26 11:50:35.643143 (MainThread): Found 2 models, 4 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-05-26 11:50:35.643735 (MainThread): 
2021-05-26 11:50:35.643947 (MainThread): Acquiring new bigquery connection "master".
2021-05-26 11:50:35.644484 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_oef-stage".
2021-05-26 11:50:35.644599 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-05-26 11:50:36.091985 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_oef-stage_TestRecoursePlanner".
2021-05-26 11:50:36.092139 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2021-05-26 11:50:36.095221 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-05-26 11:50:36.340504 (MainThread): 13:50:36 | Concurrency: 5 threads (target='dev')
2021-05-26 11:50:36.340728 (MainThread): 13:50:36 | 
2021-05-26 11:50:36.342375 (Thread-1): Began running node model.resourceplanner.my_first_dbt_model
2021-05-26 11:50:36.342526 (Thread-1): 13:50:36 | 1 of 2 START table model TestRecoursePlanner.my_first_dbt_model...... [RUN]
2021-05-26 11:50:36.342718 (Thread-1): Acquiring new bigquery connection "model.resourceplanner.my_first_dbt_model".
2021-05-26 11:50:36.342786 (Thread-1): Compiling model.resourceplanner.my_first_dbt_model
2021-05-26 11:50:36.344339 (Thread-1): Writing injected SQL for node "model.resourceplanner.my_first_dbt_model"
2021-05-26 11:50:36.344545 (Thread-1): finished collecting timing info
2021-05-26 11:50:36.372938 (Thread-1): Writing runtime SQL for node "model.resourceplanner.my_first_dbt_model"
2021-05-26 11:50:36.373401 (Thread-1): Opening a new connection, currently in state closed
2021-05-26 11:50:36.382104 (Thread-1): On model.resourceplanner.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "Bigquery", "target_name": "dev", "node_id": "model.resourceplanner.my_first_dbt_model"} */


  create or replace table `oef-stage`.`TestRecoursePlanner`.`my_first_dbt_model`
  
  
  OPTIONS()
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
    
2021-05-26 11:50:37.122720 (Thread-1): Unhandled error while running:
/* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "Bigquery", "target_name": "dev", "node_id": "model.resourceplanner.my_first_dbt_model"} */


  create or replace table `oef-stage`.`TestRecoursePlanner`.`my_first_dbt_model`
  
  
  OPTIONS()
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
    
2021-05-26 11:50:37.122839 (Thread-1): 404 GET https://bigquery.googleapis.com/bigquery/v2/projects/oef-stage/queries/820f8106-d727-4194-b4bf-234cd254d360?maxResults=0&location=EU&prettyPrint=false: Not found: Job oef-stage:EU.820f8106-d727-4194-b4bf-234cd254d360

(job ID: 820f8106-d727-4194-b4bf-234cd254d360)

                                                              -----Query Job SQL Follows-----                                                              

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "Bigquery", "target_name": "dev", "node_id": "model.resourceplanner.my_first_dbt_model"} */
   2:
   3:
   4:  create or replace table `oef-stage`.`TestRecoursePlanner`.`my_first_dbt_model`
   5:  
   6:  
   7:  OPTIONS()
   8:  as (
   9:    /*
  10:    Welcome to your first dbt model!
  11:    Did you know that you can also configure models directly within SQL files?
  12:    This will override configurations stated in dbt_project.yml
  13:
  14:    Try changing "table" to "view" below
  15:*/
  16:
  17:
  18:
  19:with source_data as (
  20:
  21:    select 1 as id
  22:    union all
  23:    select null as id
  24:
  25:)
  26:
  27:select *
  28:from source_data
  29:
  30:/*
  31:    Uncomment the line below to remove records with null `id` values
  32:*/
  33:
  34:-- where id is not null
  35:  );
  36:    
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
2021-05-26 11:50:37.122961 (Thread-1): finished collecting timing info
2021-05-26 11:50:37.123189 (Thread-1): Runtime Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  404 GET https://bigquery.googleapis.com/bigquery/v2/projects/oef-stage/queries/820f8106-d727-4194-b4bf-234cd254d360?maxResults=0&location=EU&prettyPrint=false: Not found: Job oef-stage:EU.820f8106-d727-4194-b4bf-234cd254d360
  
  (job ID: 820f8106-d727-4194-b4bf-234cd254d360)
Traceback (most recent call last):
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 149, in exception_handler
    yield
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 327, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 520, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1146, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/job/base.py", line 631, in result
    return super(_AsyncJob, self).result(timeout=timeout, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/future/polling.py", line 129, in result
    self._blocking_poll(timeout=timeout, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1042, in _blocking_poll
    super(QueryJob, self)._blocking_poll(timeout=timeout, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/future/polling.py", line 107, in _blocking_poll
    retry_(self._done_or_raise)(**kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/future/polling.py", line 85, in _done_or_raise
    if not self.done(**kwargs):
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1022, in done
    self._query_results = self._client._get_query_results(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 1557, in _get_query_results
    resource = self._call_api(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 636, in _call_api
    return call()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/_http.py", line 438, in api_request
    raise exceptions.from_http_response(response)
google.api_core.exceptions.NotFound: 404 GET https://bigquery.googleapis.com/bigquery/v2/projects/oef-stage/queries/820f8106-d727-4194-b4bf-234cd254d360?maxResults=0&location=EU&prettyPrint=false: Not found: Job oef-stage:EU.820f8106-d727-4194-b4bf-234cd254d360

(job ID: 820f8106-d727-4194-b4bf-234cd254d360)

                                                              -----Query Job SQL Follows-----                                                              

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "Bigquery", "target_name": "dev", "node_id": "model.resourceplanner.my_first_dbt_model"} */
   2:
   3:
   4:  create or replace table `oef-stage`.`TestRecoursePlanner`.`my_first_dbt_model`
   5:  
   6:  
   7:  OPTIONS()
   8:  as (
   9:    /*
  10:    Welcome to your first dbt model!
  11:    Did you know that you can also configure models directly within SQL files?
  12:    This will override configurations stated in dbt_project.yml
  13:
  14:    Try changing "table" to "view" below
  15:*/
  16:
  17:
  18:
  19:with source_data as (
  20:
  21:    select 1 as id
  22:    union all
  23:    select null as id
  24:
  25:)
  26:
  27:select *
  28:from source_data
  29:
  30:/*
  31:    Uncomment the line below to remove records with null `id` values
  32:*/
  33:
  34:-- where id is not null
  35:  );
  36:    
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/base.py", line 287, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/base.py", line 389, in run
    return self.execute(compiled_node, manifest)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/run.py", line 248, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 128, in macro
  File "/home/femke/dbt-env/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/home/femke/dbt-env/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 227, in execute
    return self.connections.execute(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 338, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 329, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 181, in exception_handler
    raise RuntimeException(exc_message)
dbt.exceptions.RuntimeException: Runtime Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  404 GET https://bigquery.googleapis.com/bigquery/v2/projects/oef-stage/queries/820f8106-d727-4194-b4bf-234cd254d360?maxResults=0&location=EU&prettyPrint=false: Not found: Job oef-stage:EU.820f8106-d727-4194-b4bf-234cd254d360
  
  (job ID: 820f8106-d727-4194-b4bf-234cd254d360)
2021-05-26 11:50:37.124986 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd337bef9-45d4-4cab-8eac-f0d274e834b6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f09069c6f70>]}
2021-05-26 11:50:37.125196 (Thread-1): 13:50:37 | 1 of 2 ERROR creating table model TestRecoursePlanner.my_first_dbt_model [ERROR in 0.78s]
2021-05-26 11:50:37.125368 (Thread-1): Finished running node model.resourceplanner.my_first_dbt_model
2021-05-26 11:50:37.125801 (Thread-3): Began running node model.resourceplanner.my_second_dbt_model
2021-05-26 11:50:37.125881 (Thread-3): 13:50:37 | 2 of 2 SKIP relation TestRecoursePlanner.my_second_dbt_model......... [SKIP]
2021-05-26 11:50:37.125986 (Thread-3): Finished running node model.resourceplanner.my_second_dbt_model
2021-05-26 11:50:37.126569 (MainThread): Acquiring new bigquery connection "master".
2021-05-26 11:50:37.126716 (MainThread): 13:50:37 | 
2021-05-26 11:50:37.126813 (MainThread): 13:50:37 | Finished running 1 table model, 1 view model in 1.48s.
2021-05-26 11:50:37.126898 (MainThread): Connection 'master' was properly closed.
2021-05-26 11:50:37.126935 (MainThread): Connection 'model.resourceplanner.my_first_dbt_model' was properly closed.
2021-05-26 11:50:37.126966 (MainThread): Connection 'list_oef-stage_TestRecoursePlanner' was properly closed.
2021-05-26 11:50:37.130175 (MainThread): 
2021-05-26 11:50:37.130382 (MainThread): Completed with 1 error and 0 warnings:
2021-05-26 11:50:37.130486 (MainThread): 
2021-05-26 11:50:37.130563 (MainThread): Runtime Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
2021-05-26 11:50:37.130645 (MainThread):   404 GET https://bigquery.googleapis.com/bigquery/v2/projects/oef-stage/queries/820f8106-d727-4194-b4bf-234cd254d360?maxResults=0&location=EU&prettyPrint=false: Not found: Job oef-stage:EU.820f8106-d727-4194-b4bf-234cd254d360
2021-05-26 11:50:37.130722 (MainThread):   
2021-05-26 11:50:37.130797 (MainThread):   (job ID: 820f8106-d727-4194-b4bf-234cd254d360)
2021-05-26 11:50:37.130880 (MainThread): 
Done. PASS=0 WARN=0 ERROR=1 SKIP=1 TOTAL=2
2021-05-26 11:50:37.131036 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f090685fee0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0906a1b700>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f090692cc40>]}
2021-05-26 11:50:37.131159 (MainThread): Flushing usage events
2021-05-26 12:18:02.935348 (MainThread): Running with dbt=0.19.1
2021-05-26 12:18:03.105797 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/home/femke/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-05-26 12:18:03.106487 (MainThread): Tracking: tracking
2021-05-26 12:18:03.116786 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efe2e298e20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efe2fbd1100>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efe2fbd14f0>]}
2021-05-26 12:18:03.129842 (MainThread): Partial parsing not enabled
2021-05-26 12:18:03.134472 (MainThread): Parsing macros/catalog.sql
2021-05-26 12:18:03.142884 (MainThread): Parsing macros/adapters.sql
2021-05-26 12:18:03.163302 (MainThread): Parsing macros/etc.sql
2021-05-26 12:18:03.164698 (MainThread): Parsing macros/materializations/snapshot.sql
2021-05-26 12:18:03.165897 (MainThread): Parsing macros/materializations/copy.sql
2021-05-26 12:18:03.169046 (MainThread): Parsing macros/materializations/table.sql
2021-05-26 12:18:03.175933 (MainThread): Parsing macros/materializations/incremental.sql
2021-05-26 12:18:03.184275 (MainThread): Parsing macros/materializations/view.sql
2021-05-26 12:18:03.186165 (MainThread): Parsing macros/materializations/seed.sql
2021-05-26 12:18:03.188449 (MainThread): Parsing macros/core.sql
2021-05-26 12:18:03.191068 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-05-26 12:18:03.192062 (MainThread): Parsing macros/schema_tests/unique.sql
2021-05-26 12:18:03.193171 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-05-26 12:18:03.194413 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-05-26 12:18:03.196203 (MainThread): Parsing macros/materializations/helpers.sql
2021-05-26 12:18:03.202132 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-05-26 12:18:03.203345 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-05-26 12:18:03.207676 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-05-26 12:18:03.221441 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-05-26 12:18:03.241919 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-05-26 12:18:03.243085 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-05-26 12:18:03.255351 (MainThread): Parsing macros/materializations/table/table.sql
2021-05-26 12:18:03.259879 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-05-26 12:18:03.263248 (MainThread): Parsing macros/materializations/view/view.sql
2021-05-26 12:18:03.267513 (MainThread): Parsing macros/materializations/common/merge.sql
2021-05-26 12:18:03.276689 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-05-26 12:18:03.277821 (MainThread): Parsing macros/etc/query.sql
2021-05-26 12:18:03.278507 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-05-26 12:18:03.279105 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-05-26 12:18:03.280490 (MainThread): Parsing macros/etc/datetime.sql
2021-05-26 12:18:03.286319 (MainThread): Parsing macros/etc/is_incremental.sql
2021-05-26 12:18:03.287421 (MainThread): Parsing macros/adapters/common.sql
2021-05-26 12:18:03.317437 (MainThread): Partial parsing not enabled
2021-05-26 12:18:03.332913 (MainThread): Acquiring new bigquery connection "model.resourceplanner.my_second_dbt_model".
2021-05-26 12:18:03.339475 (MainThread): Acquiring new bigquery connection "model.resourceplanner.my_first_dbt_model".
2021-05-26 12:18:03.382952 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'bfc1fd0b-e7f9-4013-8929-e13ba70378b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efe2d315a00>]}
2021-05-26 12:18:03.385570 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'bfc1fd0b-e7f9-4013-8929-e13ba70378b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efe2d3edf40>]}
2021-05-26 12:18:03.385712 (MainThread): Found 2 models, 4 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-05-26 12:18:03.386281 (MainThread): 
2021-05-26 12:18:03.386511 (MainThread): Acquiring new bigquery connection "master".
2021-05-26 12:18:03.387034 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_oef-stage".
2021-05-26 12:18:03.387150 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-05-26 12:18:03.674265 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_oef-stage_TestRecoursePlanner".
2021-05-26 12:18:03.674420 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2021-05-26 12:18:03.677680 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-05-26 12:18:03.852331 (MainThread): 14:18:03 | Concurrency: 5 threads (target='dev')
2021-05-26 12:18:03.852551 (MainThread): 14:18:03 | 
2021-05-26 12:18:03.854100 (Thread-1): Began running node model.resourceplanner.my_first_dbt_model
2021-05-26 12:18:03.854259 (Thread-1): 14:18:03 | 1 of 2 START table model TestRecoursePlanner.my_first_dbt_model...... [RUN]
2021-05-26 12:18:03.854443 (Thread-1): Acquiring new bigquery connection "model.resourceplanner.my_first_dbt_model".
2021-05-26 12:18:03.854509 (Thread-1): Compiling model.resourceplanner.my_first_dbt_model
2021-05-26 12:18:03.856022 (Thread-1): Writing injected SQL for node "model.resourceplanner.my_first_dbt_model"
2021-05-26 12:18:03.856234 (Thread-1): finished collecting timing info
2021-05-26 12:18:03.889083 (Thread-1): Writing runtime SQL for node "model.resourceplanner.my_first_dbt_model"
2021-05-26 12:18:03.891223 (Thread-1): Opening a new connection, currently in state closed
2021-05-26 12:18:03.894359 (Thread-1): On model.resourceplanner.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "Bigquery", "target_name": "dev", "node_id": "model.resourceplanner.my_first_dbt_model"} */


  create or replace table `oef-stage`.`TestRecoursePlanner`.`my_first_dbt_model`
  
  
  OPTIONS()
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
    
2021-05-26 12:18:04.435249 (Thread-1): Unhandled error while running:
/* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "Bigquery", "target_name": "dev", "node_id": "model.resourceplanner.my_first_dbt_model"} */


  create or replace table `oef-stage`.`TestRecoursePlanner`.`my_first_dbt_model`
  
  
  OPTIONS()
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
    
2021-05-26 12:18:04.435368 (Thread-1): 404 GET https://bigquery.googleapis.com/bigquery/v2/projects/oef-stage/queries/05f8f372-53c7-4dfe-b9c4-6a7a0a5aa2af?maxResults=0&location=EU&prettyPrint=false: Not found: Job oef-stage:EU.05f8f372-53c7-4dfe-b9c4-6a7a0a5aa2af

(job ID: 05f8f372-53c7-4dfe-b9c4-6a7a0a5aa2af)

                                                              -----Query Job SQL Follows-----                                                              

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "Bigquery", "target_name": "dev", "node_id": "model.resourceplanner.my_first_dbt_model"} */
   2:
   3:
   4:  create or replace table `oef-stage`.`TestRecoursePlanner`.`my_first_dbt_model`
   5:  
   6:  
   7:  OPTIONS()
   8:  as (
   9:    /*
  10:    Welcome to your first dbt model!
  11:    Did you know that you can also configure models directly within SQL files?
  12:    This will override configurations stated in dbt_project.yml
  13:
  14:    Try changing "table" to "view" below
  15:*/
  16:
  17:
  18:
  19:with source_data as (
  20:
  21:    select 1 as id
  22:    union all
  23:    select null as id
  24:
  25:)
  26:
  27:select *
  28:from source_data
  29:
  30:/*
  31:    Uncomment the line below to remove records with null `id` values
  32:*/
  33:
  34:-- where id is not null
  35:  );
  36:    
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
2021-05-26 12:18:04.435487 (Thread-1): finished collecting timing info
2021-05-26 12:18:04.435734 (Thread-1): Runtime Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  404 GET https://bigquery.googleapis.com/bigquery/v2/projects/oef-stage/queries/05f8f372-53c7-4dfe-b9c4-6a7a0a5aa2af?maxResults=0&location=EU&prettyPrint=false: Not found: Job oef-stage:EU.05f8f372-53c7-4dfe-b9c4-6a7a0a5aa2af
  
  (job ID: 05f8f372-53c7-4dfe-b9c4-6a7a0a5aa2af)
Traceback (most recent call last):
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 149, in exception_handler
    yield
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 327, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 520, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1146, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/job/base.py", line 631, in result
    return super(_AsyncJob, self).result(timeout=timeout, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/future/polling.py", line 129, in result
    self._blocking_poll(timeout=timeout, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1042, in _blocking_poll
    super(QueryJob, self)._blocking_poll(timeout=timeout, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/future/polling.py", line 107, in _blocking_poll
    retry_(self._done_or_raise)(**kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/future/polling.py", line 85, in _done_or_raise
    if not self.done(**kwargs):
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1022, in done
    self._query_results = self._client._get_query_results(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 1557, in _get_query_results
    resource = self._call_api(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 636, in _call_api
    return call()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/_http.py", line 438, in api_request
    raise exceptions.from_http_response(response)
google.api_core.exceptions.NotFound: 404 GET https://bigquery.googleapis.com/bigquery/v2/projects/oef-stage/queries/05f8f372-53c7-4dfe-b9c4-6a7a0a5aa2af?maxResults=0&location=EU&prettyPrint=false: Not found: Job oef-stage:EU.05f8f372-53c7-4dfe-b9c4-6a7a0a5aa2af

(job ID: 05f8f372-53c7-4dfe-b9c4-6a7a0a5aa2af)

                                                              -----Query Job SQL Follows-----                                                              

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "Bigquery", "target_name": "dev", "node_id": "model.resourceplanner.my_first_dbt_model"} */
   2:
   3:
   4:  create or replace table `oef-stage`.`TestRecoursePlanner`.`my_first_dbt_model`
   5:  
   6:  
   7:  OPTIONS()
   8:  as (
   9:    /*
  10:    Welcome to your first dbt model!
  11:    Did you know that you can also configure models directly within SQL files?
  12:    This will override configurations stated in dbt_project.yml
  13:
  14:    Try changing "table" to "view" below
  15:*/
  16:
  17:
  18:
  19:with source_data as (
  20:
  21:    select 1 as id
  22:    union all
  23:    select null as id
  24:
  25:)
  26:
  27:select *
  28:from source_data
  29:
  30:/*
  31:    Uncomment the line below to remove records with null `id` values
  32:*/
  33:
  34:-- where id is not null
  35:  );
  36:    
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/base.py", line 287, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/base.py", line 389, in run
    return self.execute(compiled_node, manifest)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/run.py", line 248, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 128, in macro
  File "/home/femke/dbt-env/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/home/femke/dbt-env/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 227, in execute
    return self.connections.execute(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 338, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 329, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 181, in exception_handler
    raise RuntimeException(exc_message)
dbt.exceptions.RuntimeException: Runtime Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  404 GET https://bigquery.googleapis.com/bigquery/v2/projects/oef-stage/queries/05f8f372-53c7-4dfe-b9c4-6a7a0a5aa2af?maxResults=0&location=EU&prettyPrint=false: Not found: Job oef-stage:EU.05f8f372-53c7-4dfe-b9c4-6a7a0a5aa2af
  
  (job ID: 05f8f372-53c7-4dfe-b9c4-6a7a0a5aa2af)
2021-05-26 12:18:04.437970 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bfc1fd0b-e7f9-4013-8929-e13ba70378b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efe2d471520>]}
2021-05-26 12:18:04.438250 (Thread-1): 14:18:04 | 1 of 2 ERROR creating table model TestRecoursePlanner.my_first_dbt_model [ERROR in 0.58s]
2021-05-26 12:18:04.438423 (Thread-1): Finished running node model.resourceplanner.my_first_dbt_model
2021-05-26 12:18:04.438831 (Thread-3): Began running node model.resourceplanner.my_second_dbt_model
2021-05-26 12:18:04.438915 (Thread-3): 14:18:04 | 2 of 2 SKIP relation TestRecoursePlanner.my_second_dbt_model......... [SKIP]
2021-05-26 12:18:04.439035 (Thread-3): Finished running node model.resourceplanner.my_second_dbt_model
2021-05-26 12:18:04.439643 (MainThread): Acquiring new bigquery connection "master".
2021-05-26 12:18:04.439793 (MainThread): 14:18:04 | 
2021-05-26 12:18:04.439892 (MainThread): 14:18:04 | Finished running 1 table model, 1 view model in 1.05s.
2021-05-26 12:18:04.439975 (MainThread): Connection 'master' was properly closed.
2021-05-26 12:18:04.440109 (MainThread): Connection 'model.resourceplanner.my_first_dbt_model' was properly closed.
2021-05-26 12:18:04.440153 (MainThread): Connection 'list_oef-stage_TestRecoursePlanner' was properly closed.
2021-05-26 12:18:04.443560 (MainThread): 
2021-05-26 12:18:04.443706 (MainThread): Completed with 1 error and 0 warnings:
2021-05-26 12:18:04.443796 (MainThread): 
2021-05-26 12:18:04.443873 (MainThread): Runtime Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
2021-05-26 12:18:04.443975 (MainThread):   404 GET https://bigquery.googleapis.com/bigquery/v2/projects/oef-stage/queries/05f8f372-53c7-4dfe-b9c4-6a7a0a5aa2af?maxResults=0&location=EU&prettyPrint=false: Not found: Job oef-stage:EU.05f8f372-53c7-4dfe-b9c4-6a7a0a5aa2af
2021-05-26 12:18:04.444052 (MainThread):   
2021-05-26 12:18:04.444126 (MainThread):   (job ID: 05f8f372-53c7-4dfe-b9c4-6a7a0a5aa2af)
2021-05-26 12:18:04.444208 (MainThread): 
Done. PASS=0 WARN=0 ERROR=1 SKIP=1 TOTAL=2
2021-05-26 12:18:04.444353 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efe2d4bc880>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efe2d3c12e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efe2d3c1490>]}
2021-05-26 12:18:04.444473 (MainThread): Flushing usage events
2021-05-26 12:19:07.328421 (MainThread): Running with dbt=0.19.1
2021-05-26 12:19:07.501205 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/home/femke/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-05-26 12:19:07.501865 (MainThread): Tracking: tracking
2021-05-26 12:19:07.512323 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effdfa8dbe0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effe13c21c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effe13c24c0>]}
2021-05-26 12:19:07.527772 (MainThread): Partial parsing not enabled
2021-05-26 12:19:07.528406 (MainThread): Parsing macros/catalog.sql
2021-05-26 12:19:07.536533 (MainThread): Parsing macros/adapters.sql
2021-05-26 12:19:07.556219 (MainThread): Parsing macros/etc.sql
2021-05-26 12:19:07.557613 (MainThread): Parsing macros/materializations/snapshot.sql
2021-05-26 12:19:07.558831 (MainThread): Parsing macros/materializations/copy.sql
2021-05-26 12:19:07.562079 (MainThread): Parsing macros/materializations/table.sql
2021-05-26 12:19:07.569072 (MainThread): Parsing macros/materializations/incremental.sql
2021-05-26 12:19:07.577487 (MainThread): Parsing macros/materializations/view.sql
2021-05-26 12:19:07.579404 (MainThread): Parsing macros/materializations/seed.sql
2021-05-26 12:19:07.581681 (MainThread): Parsing macros/core.sql
2021-05-26 12:19:07.584151 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-05-26 12:19:07.585121 (MainThread): Parsing macros/schema_tests/unique.sql
2021-05-26 12:19:07.586215 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-05-26 12:19:07.587417 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-05-26 12:19:07.589143 (MainThread): Parsing macros/materializations/helpers.sql
2021-05-26 12:19:07.594934 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-05-26 12:19:07.596216 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-05-26 12:19:07.600443 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-05-26 12:19:07.613860 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-05-26 12:19:07.633540 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-05-26 12:19:07.634662 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-05-26 12:19:07.657791 (MainThread): Parsing macros/materializations/table/table.sql
2021-05-26 12:19:07.662323 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-05-26 12:19:07.665819 (MainThread): Parsing macros/materializations/view/view.sql
2021-05-26 12:19:07.670091 (MainThread): Parsing macros/materializations/common/merge.sql
2021-05-26 12:19:07.679561 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-05-26 12:19:07.680643 (MainThread): Parsing macros/etc/query.sql
2021-05-26 12:19:07.681363 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-05-26 12:19:07.681948 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-05-26 12:19:07.683436 (MainThread): Parsing macros/etc/datetime.sql
2021-05-26 12:19:07.689398 (MainThread): Parsing macros/etc/is_incremental.sql
2021-05-26 12:19:07.690520 (MainThread): Parsing macros/adapters/common.sql
2021-05-26 12:19:07.721248 (MainThread): Partial parsing not enabled
2021-05-26 12:19:07.738041 (MainThread): Acquiring new bigquery connection "model.resourceplanner.my_second_dbt_model".
2021-05-26 12:19:07.745170 (MainThread): Acquiring new bigquery connection "model.resourceplanner.my_first_dbt_model".
2021-05-26 12:19:07.789134 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '17702b3d-f68a-4034-8eaa-2efe7e122132', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effdeb0acd0>]}
2021-05-26 12:19:07.791709 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '17702b3d-f68a-4034-8eaa-2efe7e122132', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effdebd9490>]}
2021-05-26 12:19:07.791836 (MainThread): Found 2 models, 4 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-05-26 12:19:07.792396 (MainThread): 
2021-05-26 12:19:07.792620 (MainThread): Acquiring new bigquery connection "master".
2021-05-26 12:19:07.793112 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_oef-stage".
2021-05-26 12:19:07.793226 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-05-26 12:19:08.089372 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_oef-stage_TestRecoursePlanner".
2021-05-26 12:19:08.089524 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2021-05-26 12:19:08.093010 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-05-26 12:19:08.269424 (MainThread): 14:19:08 | Concurrency: 5 threads (target='dev')
2021-05-26 12:19:08.269651 (MainThread): 14:19:08 | 
2021-05-26 12:19:08.271197 (Thread-1): Began running node model.resourceplanner.my_first_dbt_model
2021-05-26 12:19:08.271341 (Thread-1): 14:19:08 | 1 of 2 START table model TestRecoursePlanner.my_first_dbt_model...... [RUN]
2021-05-26 12:19:08.271523 (Thread-1): Acquiring new bigquery connection "model.resourceplanner.my_first_dbt_model".
2021-05-26 12:19:08.271591 (Thread-1): Compiling model.resourceplanner.my_first_dbt_model
2021-05-26 12:19:08.273244 (Thread-1): Writing injected SQL for node "model.resourceplanner.my_first_dbt_model"
2021-05-26 12:19:08.273501 (Thread-1): finished collecting timing info
2021-05-26 12:19:08.317276 (Thread-1): Writing runtime SQL for node "model.resourceplanner.my_first_dbt_model"
2021-05-26 12:19:08.317705 (Thread-1): Opening a new connection, currently in state closed
2021-05-26 12:19:08.326646 (Thread-1): On model.resourceplanner.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "Bigquery", "target_name": "dev", "node_id": "model.resourceplanner.my_first_dbt_model"} */


  create or replace table `oef-stage`.`TestRecoursePlanner`.`my_first_dbt_model`
  
  
  OPTIONS()
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
    
2021-05-26 12:19:08.874420 (Thread-1): Unhandled error while running:
/* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "Bigquery", "target_name": "dev", "node_id": "model.resourceplanner.my_first_dbt_model"} */


  create or replace table `oef-stage`.`TestRecoursePlanner`.`my_first_dbt_model`
  
  
  OPTIONS()
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
    
2021-05-26 12:19:08.874554 (Thread-1): 404 GET https://bigquery.googleapis.com/bigquery/v2/projects/oef-stage/queries/5f18b16b-744b-4b8e-92fb-3bfb330b0242?maxResults=0&location=EU&prettyPrint=false: Not found: Job oef-stage:EU.5f18b16b-744b-4b8e-92fb-3bfb330b0242

(job ID: 5f18b16b-744b-4b8e-92fb-3bfb330b0242)

                                                              -----Query Job SQL Follows-----                                                              

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "Bigquery", "target_name": "dev", "node_id": "model.resourceplanner.my_first_dbt_model"} */
   2:
   3:
   4:  create or replace table `oef-stage`.`TestRecoursePlanner`.`my_first_dbt_model`
   5:  
   6:  
   7:  OPTIONS()
   8:  as (
   9:    /*
  10:    Welcome to your first dbt model!
  11:    Did you know that you can also configure models directly within SQL files?
  12:    This will override configurations stated in dbt_project.yml
  13:
  14:    Try changing "table" to "view" below
  15:*/
  16:
  17:
  18:
  19:with source_data as (
  20:
  21:    select 1 as id
  22:    union all
  23:    select null as id
  24:
  25:)
  26:
  27:select *
  28:from source_data
  29:
  30:/*
  31:    Uncomment the line below to remove records with null `id` values
  32:*/
  33:
  34:-- where id is not null
  35:  );
  36:    
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
2021-05-26 12:19:08.874663 (Thread-1): finished collecting timing info
2021-05-26 12:19:08.874889 (Thread-1): Runtime Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  404 GET https://bigquery.googleapis.com/bigquery/v2/projects/oef-stage/queries/5f18b16b-744b-4b8e-92fb-3bfb330b0242?maxResults=0&location=EU&prettyPrint=false: Not found: Job oef-stage:EU.5f18b16b-744b-4b8e-92fb-3bfb330b0242
  
  (job ID: 5f18b16b-744b-4b8e-92fb-3bfb330b0242)
Traceback (most recent call last):
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 149, in exception_handler
    yield
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 327, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 520, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1146, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/job/base.py", line 631, in result
    return super(_AsyncJob, self).result(timeout=timeout, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/future/polling.py", line 129, in result
    self._blocking_poll(timeout=timeout, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1042, in _blocking_poll
    super(QueryJob, self)._blocking_poll(timeout=timeout, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/future/polling.py", line 107, in _blocking_poll
    retry_(self._done_or_raise)(**kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/future/polling.py", line 85, in _done_or_raise
    if not self.done(**kwargs):
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1022, in done
    self._query_results = self._client._get_query_results(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 1557, in _get_query_results
    resource = self._call_api(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 636, in _call_api
    return call()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/_http.py", line 438, in api_request
    raise exceptions.from_http_response(response)
google.api_core.exceptions.NotFound: 404 GET https://bigquery.googleapis.com/bigquery/v2/projects/oef-stage/queries/5f18b16b-744b-4b8e-92fb-3bfb330b0242?maxResults=0&location=EU&prettyPrint=false: Not found: Job oef-stage:EU.5f18b16b-744b-4b8e-92fb-3bfb330b0242

(job ID: 5f18b16b-744b-4b8e-92fb-3bfb330b0242)

                                                              -----Query Job SQL Follows-----                                                              

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "Bigquery", "target_name": "dev", "node_id": "model.resourceplanner.my_first_dbt_model"} */
   2:
   3:
   4:  create or replace table `oef-stage`.`TestRecoursePlanner`.`my_first_dbt_model`
   5:  
   6:  
   7:  OPTIONS()
   8:  as (
   9:    /*
  10:    Welcome to your first dbt model!
  11:    Did you know that you can also configure models directly within SQL files?
  12:    This will override configurations stated in dbt_project.yml
  13:
  14:    Try changing "table" to "view" below
  15:*/
  16:
  17:
  18:
  19:with source_data as (
  20:
  21:    select 1 as id
  22:    union all
  23:    select null as id
  24:
  25:)
  26:
  27:select *
  28:from source_data
  29:
  30:/*
  31:    Uncomment the line below to remove records with null `id` values
  32:*/
  33:
  34:-- where id is not null
  35:  );
  36:    
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/base.py", line 287, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/base.py", line 389, in run
    return self.execute(compiled_node, manifest)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/run.py", line 248, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 128, in macro
  File "/home/femke/dbt-env/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/home/femke/dbt-env/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 227, in execute
    return self.connections.execute(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 338, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 329, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 181, in exception_handler
    raise RuntimeException(exc_message)
dbt.exceptions.RuntimeException: Runtime Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  404 GET https://bigquery.googleapis.com/bigquery/v2/projects/oef-stage/queries/5f18b16b-744b-4b8e-92fb-3bfb330b0242?maxResults=0&location=EU&prettyPrint=false: Not found: Job oef-stage:EU.5f18b16b-744b-4b8e-92fb-3bfb330b0242
  
  (job ID: 5f18b16b-744b-4b8e-92fb-3bfb330b0242)
2021-05-26 12:19:08.876757 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '17702b3d-f68a-4034-8eaa-2efe7e122132', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effdebf28b0>]}
2021-05-26 12:19:08.876992 (Thread-1): 14:19:08 | 1 of 2 ERROR creating table model TestRecoursePlanner.my_first_dbt_model [ERROR in 0.61s]
2021-05-26 12:19:08.877161 (Thread-1): Finished running node model.resourceplanner.my_first_dbt_model
2021-05-26 12:19:08.877541 (Thread-3): Began running node model.resourceplanner.my_second_dbt_model
2021-05-26 12:19:08.877618 (Thread-3): 14:19:08 | 2 of 2 SKIP relation TestRecoursePlanner.my_second_dbt_model......... [SKIP]
2021-05-26 12:19:08.877719 (Thread-3): Finished running node model.resourceplanner.my_second_dbt_model
2021-05-26 12:19:08.878336 (MainThread): Acquiring new bigquery connection "master".
2021-05-26 12:19:08.878483 (MainThread): 14:19:08 | 
2021-05-26 12:19:08.878579 (MainThread): 14:19:08 | Finished running 1 table model, 1 view model in 1.09s.
2021-05-26 12:19:08.878660 (MainThread): Connection 'master' was properly closed.
2021-05-26 12:19:08.878697 (MainThread): Connection 'model.resourceplanner.my_first_dbt_model' was properly closed.
2021-05-26 12:19:08.878727 (MainThread): Connection 'list_oef-stage_TestRecoursePlanner' was properly closed.
2021-05-26 12:19:08.881431 (MainThread): 
2021-05-26 12:19:08.881544 (MainThread): Completed with 1 error and 0 warnings:
2021-05-26 12:19:08.881650 (MainThread): 
2021-05-26 12:19:08.881734 (MainThread): Runtime Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
2021-05-26 12:19:08.881840 (MainThread):   404 GET https://bigquery.googleapis.com/bigquery/v2/projects/oef-stage/queries/5f18b16b-744b-4b8e-92fb-3bfb330b0242?maxResults=0&location=EU&prettyPrint=false: Not found: Job oef-stage:EU.5f18b16b-744b-4b8e-92fb-3bfb330b0242
2021-05-26 12:19:08.881917 (MainThread):   
2021-05-26 12:19:08.881990 (MainThread):   (job ID: 5f18b16b-744b-4b8e-92fb-3bfb330b0242)
2021-05-26 12:19:08.882072 (MainThread): 
Done. PASS=0 WARN=0 ERROR=1 SKIP=1 TOTAL=2
2021-05-26 12:19:08.882207 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effdebbfac0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effdeaf2d90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effdeaf29d0>]}
2021-05-26 12:19:08.882312 (MainThread): Flushing usage events
2021-05-26 12:25:05.900505 (MainThread): Running with dbt=0.19.1
2021-05-26 12:25:06.068872 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/home/femke/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-05-26 12:25:06.069492 (MainThread): Tracking: tracking
2021-05-26 12:25:06.083248 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f449043ff10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4491d352e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4491d355e0>]}
2021-05-26 12:25:06.093774 (MainThread): Partial parsing not enabled
2021-05-26 12:25:06.094456 (MainThread): Parsing macros/catalog.sql
2021-05-26 12:25:06.103457 (MainThread): Parsing macros/adapters.sql
2021-05-26 12:25:06.123560 (MainThread): Parsing macros/etc.sql
2021-05-26 12:25:06.124986 (MainThread): Parsing macros/materializations/snapshot.sql
2021-05-26 12:25:06.126228 (MainThread): Parsing macros/materializations/copy.sql
2021-05-26 12:25:06.129362 (MainThread): Parsing macros/materializations/table.sql
2021-05-26 12:25:06.136294 (MainThread): Parsing macros/materializations/incremental.sql
2021-05-26 12:25:06.145064 (MainThread): Parsing macros/materializations/view.sql
2021-05-26 12:25:06.147094 (MainThread): Parsing macros/materializations/seed.sql
2021-05-26 12:25:06.149513 (MainThread): Parsing macros/core.sql
2021-05-26 12:25:06.152119 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-05-26 12:25:06.153135 (MainThread): Parsing macros/schema_tests/unique.sql
2021-05-26 12:25:06.154332 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-05-26 12:25:06.155572 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-05-26 12:25:06.157437 (MainThread): Parsing macros/materializations/helpers.sql
2021-05-26 12:25:06.163403 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-05-26 12:25:06.164681 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-05-26 12:25:06.169006 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-05-26 12:25:06.183248 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-05-26 12:25:06.203605 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-05-26 12:25:06.204767 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-05-26 12:25:06.217360 (MainThread): Parsing macros/materializations/table/table.sql
2021-05-26 12:25:06.221889 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-05-26 12:25:06.225265 (MainThread): Parsing macros/materializations/view/view.sql
2021-05-26 12:25:06.229426 (MainThread): Parsing macros/materializations/common/merge.sql
2021-05-26 12:25:06.238652 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-05-26 12:25:06.239761 (MainThread): Parsing macros/etc/query.sql
2021-05-26 12:25:06.240455 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-05-26 12:25:06.241096 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-05-26 12:25:06.242536 (MainThread): Parsing macros/etc/datetime.sql
2021-05-26 12:25:06.248437 (MainThread): Parsing macros/etc/is_incremental.sql
2021-05-26 12:25:06.249566 (MainThread): Parsing macros/adapters/common.sql
2021-05-26 12:25:06.281671 (MainThread): Partial parsing not enabled
2021-05-26 12:25:06.297732 (MainThread): Acquiring new bigquery connection "model.resourceplanner.my_second_dbt_model".
2021-05-26 12:25:06.304272 (MainThread): Acquiring new bigquery connection "model.resourceplanner.my_first_dbt_model".
2021-05-26 12:25:06.350322 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '8788684a-83e6-4213-8d04-cc8d07b2664c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f448f43d9d0>]}
2021-05-26 12:25:06.352876 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '8788684a-83e6-4213-8d04-cc8d07b2664c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f448f511670>]}
2021-05-26 12:25:06.353006 (MainThread): Found 2 models, 4 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-05-26 12:25:06.353640 (MainThread): 
2021-05-26 12:25:06.353852 (MainThread): Acquiring new bigquery connection "master".
2021-05-26 12:25:06.354380 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_oef-stage".
2021-05-26 12:25:06.354497 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-05-26 12:25:06.646618 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_oef-stage_TestRecoursePlanner".
2021-05-26 12:25:06.646770 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2021-05-26 12:25:06.649890 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-05-26 12:25:06.826742 (MainThread): 14:25:06 | Concurrency: 5 threads (target='dev')
2021-05-26 12:25:06.826967 (MainThread): 14:25:06 | 
2021-05-26 12:25:06.828530 (Thread-1): Began running node model.resourceplanner.my_first_dbt_model
2021-05-26 12:25:06.828674 (Thread-1): 14:25:06 | 1 of 2 START table model TestRecoursePlanner.my_first_dbt_model...... [RUN]
2021-05-26 12:25:06.828858 (Thread-1): Acquiring new bigquery connection "model.resourceplanner.my_first_dbt_model".
2021-05-26 12:25:06.828928 (Thread-1): Compiling model.resourceplanner.my_first_dbt_model
2021-05-26 12:25:06.830850 (Thread-1): Writing injected SQL for node "model.resourceplanner.my_first_dbt_model"
2021-05-26 12:25:06.831265 (Thread-1): finished collecting timing info
2021-05-26 12:25:06.883581 (Thread-1): Writing runtime SQL for node "model.resourceplanner.my_first_dbt_model"
2021-05-26 12:25:06.883985 (Thread-1): Opening a new connection, currently in state closed
2021-05-26 12:25:06.887116 (Thread-1): On model.resourceplanner.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "Bigquery", "target_name": "dev", "node_id": "model.resourceplanner.my_first_dbt_model"} */


  create or replace table `oef-stage`.`TestRecoursePlanner`.`my_first_dbt_model`
  
  
  OPTIONS()
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
    
2021-05-26 12:25:09.347621 (Thread-1): finished collecting timing info
2021-05-26 12:25:09.347927 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8788684a-83e6-4213-8d04-cc8d07b2664c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f448f525370>]}
2021-05-26 12:25:09.348122 (Thread-1): 14:25:09 | 1 of 2 OK created table model TestRecoursePlanner.my_first_dbt_model. [CREATE TABLE (2.0 rows, 0.0 Bytes processed) in 2.52s]
2021-05-26 12:25:09.348295 (Thread-1): Finished running node model.resourceplanner.my_first_dbt_model
2021-05-26 12:25:09.348673 (Thread-3): Began running node model.resourceplanner.my_second_dbt_model
2021-05-26 12:25:09.348824 (Thread-3): 14:25:09 | 2 of 2 START view model TestRecoursePlanner.my_second_dbt_model...... [RUN]
2021-05-26 12:25:09.349034 (Thread-3): Acquiring new bigquery connection "model.resourceplanner.my_second_dbt_model".
2021-05-26 12:25:09.349097 (Thread-3): Compiling model.resourceplanner.my_second_dbt_model
2021-05-26 12:25:09.350433 (Thread-3): Writing injected SQL for node "model.resourceplanner.my_second_dbt_model"
2021-05-26 12:25:09.350608 (Thread-3): finished collecting timing info
2021-05-26 12:25:09.360798 (Thread-3): unclosed <socket.socket fd=5, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.0.2.15', 45514), raddr=('172.217.168.202', 443)>
2021-05-26 12:25:09.361018 (Thread-3): unclosed <socket.socket fd=6, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.0.2.15', 49820), raddr=('172.217.168.234', 443)>
2021-05-26 12:25:09.368305 (Thread-3): Writing runtime SQL for node "model.resourceplanner.my_second_dbt_model"
2021-05-26 12:25:09.368558 (Thread-3): Opening a new connection, currently in state init
2021-05-26 12:25:09.371833 (Thread-3): On model.resourceplanner.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "Bigquery", "target_name": "dev", "node_id": "model.resourceplanner.my_second_dbt_model"} */


  create or replace view `oef-stage`.`TestRecoursePlanner`.`my_second_dbt_model`
  OPTIONS()
  as -- Use the `ref` function to select from other models

select *
from `oef-stage`.`TestRecoursePlanner`.`my_first_dbt_model`
where id = 1;


2021-05-26 12:25:10.580380 (Thread-3): finished collecting timing info
2021-05-26 12:25:10.580668 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8788684a-83e6-4213-8d04-cc8d07b2664c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f448f4d4e80>]}
2021-05-26 12:25:10.580861 (Thread-3): 14:25:10 | 2 of 2 OK created view model TestRecoursePlanner.my_second_dbt_model. [OK in 1.23s]
2021-05-26 12:25:10.581029 (Thread-3): Finished running node model.resourceplanner.my_second_dbt_model
2021-05-26 12:25:10.581846 (MainThread): Acquiring new bigquery connection "master".
2021-05-26 12:25:10.581998 (MainThread): 14:25:10 | 
2021-05-26 12:25:10.582101 (MainThread): 14:25:10 | Finished running 1 table model, 1 view model in 4.23s.
2021-05-26 12:25:10.582187 (MainThread): Connection 'master' was properly closed.
2021-05-26 12:25:10.582229 (MainThread): Connection 'model.resourceplanner.my_first_dbt_model' was properly closed.
2021-05-26 12:25:10.582260 (MainThread): Connection 'list_oef-stage_TestRecoursePlanner' was properly closed.
2021-05-26 12:25:10.582290 (MainThread): Connection 'model.resourceplanner.my_second_dbt_model' was properly closed.
2021-05-26 12:25:10.611289 (MainThread): 
2021-05-26 12:25:10.611473 (MainThread): Completed successfully
2021-05-26 12:25:10.611574 (MainThread): 
Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
2021-05-26 12:25:10.613192 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f448f5e28b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f448f5e68b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f448f5e5070>]}
2021-05-26 12:25:10.613340 (MainThread): Flushing usage events
2021-05-27 13:02:47.531094 (MainThread): Running with dbt=0.19.1
2021-05-27 13:02:47.715243 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/home/femke/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-05-27 13:02:47.715910 (MainThread): Tracking: tracking
2021-05-27 13:02:47.729757 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7ae04dfc40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7ae1e140d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7ae1e14520>]}
2021-05-27 13:02:47.740248 (MainThread): Partial parsing not enabled
2021-05-27 13:02:47.740949 (MainThread): Parsing macros/catalog.sql
2021-05-27 13:02:47.749621 (MainThread): Parsing macros/adapters.sql
2021-05-27 13:02:47.772834 (MainThread): Parsing macros/etc.sql
2021-05-27 13:02:47.774518 (MainThread): Parsing macros/materializations/snapshot.sql
2021-05-27 13:02:47.775845 (MainThread): Parsing macros/materializations/copy.sql
2021-05-27 13:02:47.778980 (MainThread): Parsing macros/materializations/table.sql
2021-05-27 13:02:47.786056 (MainThread): Parsing macros/materializations/incremental.sql
2021-05-27 13:02:47.794711 (MainThread): Parsing macros/materializations/view.sql
2021-05-27 13:02:47.805437 (MainThread): Parsing macros/materializations/seed.sql
2021-05-27 13:02:47.807918 (MainThread): Parsing macros/core.sql
2021-05-27 13:02:47.810497 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-05-27 13:02:47.811492 (MainThread): Parsing macros/schema_tests/unique.sql
2021-05-27 13:02:47.812630 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-05-27 13:02:47.814008 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-05-27 13:02:47.815941 (MainThread): Parsing macros/materializations/helpers.sql
2021-05-27 13:02:47.821932 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-05-27 13:02:47.823215 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-05-27 13:02:47.827679 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-05-27 13:02:47.843199 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-05-27 13:02:47.863965 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-05-27 13:02:47.865212 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-05-27 13:02:47.877835 (MainThread): Parsing macros/materializations/table/table.sql
2021-05-27 13:02:47.882427 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-05-27 13:02:47.886021 (MainThread): Parsing macros/materializations/view/view.sql
2021-05-27 13:02:47.890207 (MainThread): Parsing macros/materializations/common/merge.sql
2021-05-27 13:02:47.899407 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-05-27 13:02:47.900499 (MainThread): Parsing macros/etc/query.sql
2021-05-27 13:02:47.901161 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-05-27 13:02:47.901810 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-05-27 13:02:47.903230 (MainThread): Parsing macros/etc/datetime.sql
2021-05-27 13:02:47.909456 (MainThread): Parsing macros/etc/is_incremental.sql
2021-05-27 13:02:47.910602 (MainThread): Parsing macros/adapters/common.sql
2021-05-27 13:02:47.942477 (MainThread): Partial parsing not enabled
2021-05-27 13:02:47.959063 (MainThread): Acquiring new bigquery connection "model.resourceplanner.my_second_dbt_model".
2021-05-27 13:02:47.966216 (MainThread): Acquiring new bigquery connection "model.resourceplanner.my_first_dbt_model".
2021-05-27 13:02:48.011836 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '76c3eaf5-d45d-4a36-a388-cdd17cba04bc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7adf55c6d0>]}
2021-05-27 13:02:48.014452 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '76c3eaf5-d45d-4a36-a388-cdd17cba04bc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7adf6375b0>]}
2021-05-27 13:02:48.014669 (MainThread): Found 2 models, 4 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-05-27 13:02:48.015303 (MainThread): 
2021-05-27 13:02:48.015570 (MainThread): Acquiring new bigquery connection "master".
2021-05-27 13:02:48.016100 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_oef-stage".
2021-05-27 13:02:48.016249 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-05-27 13:02:48.427465 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_oef-stage_TestRecoursePlanner".
2021-05-27 13:02:48.427658 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2021-05-27 13:02:48.430763 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-05-27 13:02:48.628679 (MainThread): 15:02:48 | Concurrency: 5 threads (target='dev')
2021-05-27 13:02:48.628922 (MainThread): 15:02:48 | 
2021-05-27 13:02:48.630599 (Thread-1): Began running node model.resourceplanner.my_first_dbt_model
2021-05-27 13:02:48.630749 (Thread-1): 15:02:48 | 1 of 2 START table model TestRecoursePlanner.my_first_dbt_model...... [RUN]
2021-05-27 13:02:48.630939 (Thread-1): Acquiring new bigquery connection "model.resourceplanner.my_first_dbt_model".
2021-05-27 13:02:48.631009 (Thread-1): Compiling model.resourceplanner.my_first_dbt_model
2021-05-27 13:02:48.632793 (Thread-1): Writing injected SQL for node "model.resourceplanner.my_first_dbt_model"
2021-05-27 13:02:48.633173 (Thread-1): finished collecting timing info
2021-05-27 13:02:48.655038 (Thread-1): Opening a new connection, currently in state closed
2021-05-27 13:02:48.661060 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-05-27 13:02:48.861364 (Thread-1): Writing runtime SQL for node "model.resourceplanner.my_first_dbt_model"
2021-05-27 13:02:48.861803 (Thread-1): On model.resourceplanner.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "Bigquery", "target_name": "dev", "node_id": "model.resourceplanner.my_first_dbt_model"} */


  create or replace table `oef-stage`.`TestRecoursePlanner`.`my_first_dbt_model`
  
  
  OPTIONS()
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from MainData
/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
    
2021-05-27 13:02:49.105612 (Thread-1): Retry attempt 1 of 1 after error: BadRequest('GET https://bigquery.googleapis.com/bigquery/v2/projects/oef-stage/queries/3dd5a9b1-0a4d-4f5d-9ef9-a674aee6a0c9?maxResults=0&location=europe-west1&prettyPrint=false: Table name "MainData" missing dataset while no default dataset is set in the request.')
2021-05-27 13:02:50.325384 (Thread-1): finished collecting timing info
2021-05-27 13:02:50.325752 (Thread-1): Database Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  Table name "MainData" missing dataset while no default dataset is set in the request.
  compiled SQL at target/run/resourceplanner/models/example/my_first_dbt_model.sql
Traceback (most recent call last):
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 149, in exception_handler
    yield
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 327, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 520, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1146, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/job/base.py", line 631, in result
    return super(_AsyncJob, self).result(timeout=timeout, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/future/polling.py", line 129, in result
    self._blocking_poll(timeout=timeout, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1042, in _blocking_poll
    super(QueryJob, self)._blocking_poll(timeout=timeout, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/future/polling.py", line 107, in _blocking_poll
    retry_(self._done_or_raise)(**kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/future/polling.py", line 85, in _done_or_raise
    if not self.done(**kwargs):
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1022, in done
    self._query_results = self._client._get_query_results(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 1557, in _get_query_results
    resource = self._call_api(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 636, in _call_api
    return call()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/_http.py", line 438, in api_request
    raise exceptions.from_http_response(response)
google.api_core.exceptions.BadRequest: 400 GET https://bigquery.googleapis.com/bigquery/v2/projects/oef-stage/queries/dba04e62-0be5-4c86-835e-963803087325?maxResults=0&location=europe-west1&prettyPrint=false: Table name "MainData" missing dataset while no default dataset is set in the request.

(job ID: dba04e62-0be5-4c86-835e-963803087325)

                                                              -----Query Job SQL Follows-----                                                              

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "Bigquery", "target_name": "dev", "node_id": "model.resourceplanner.my_first_dbt_model"} */
   2:
   3:
   4:  create or replace table `oef-stage`.`TestRecoursePlanner`.`my_first_dbt_model`
   5:  
   6:  
   7:  OPTIONS()
   8:  as (
   9:    /*
  10:    Welcome to your first dbt model!
  11:    Did you know that you can also configure models directly within SQL files?
  12:    This will override configurations stated in dbt_project.yml
  13:
  14:    Try changing "table" to "view" below
  15:*/
  16:
  17:
  18:
  19:with source_data as (
  20:
  21:    select 1 as id
  22:    union all
  23:    select null as id
  24:
  25:)
  26:
  27:select *
  28:from MainData
  29:/*
  30:    Uncomment the line below to remove records with null `id` values
  31:*/
  32:
  33:-- where id is not null
  34:  );
  35:    
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/base.py", line 287, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/base.py", line 389, in run
    return self.execute(compiled_node, manifest)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/run.py", line 248, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 128, in macro
  File "/home/femke/dbt-env/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/home/femke/dbt-env/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 227, in execute
    return self.connections.execute(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 338, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 329, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 153, in exception_handler
    self.handle_error(e, message)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 141, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  Table name "MainData" missing dataset while no default dataset is set in the request.
  compiled SQL at target/run/resourceplanner/models/example/my_first_dbt_model.sql
2021-05-27 13:02:50.327493 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '76c3eaf5-d45d-4a36-a388-cdd17cba04bc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7adf60da60>]}
2021-05-27 13:02:50.327719 (Thread-1): 15:02:50 | 1 of 2 ERROR creating table model TestRecoursePlanner.my_first_dbt_model [ERROR in 1.70s]
2021-05-27 13:02:50.327908 (Thread-1): Finished running node model.resourceplanner.my_first_dbt_model
2021-05-27 13:02:50.328322 (Thread-3): Began running node model.resourceplanner.my_second_dbt_model
2021-05-27 13:02:50.328399 (Thread-3): 15:02:50 | 2 of 2 SKIP relation TestRecoursePlanner.my_second_dbt_model......... [SKIP]
2021-05-27 13:02:50.328505 (Thread-3): Finished running node model.resourceplanner.my_second_dbt_model
2021-05-27 13:02:50.329142 (MainThread): Acquiring new bigquery connection "master".
2021-05-27 13:02:50.329326 (MainThread): 15:02:50 | 
2021-05-27 13:02:50.329430 (MainThread): 15:02:50 | Finished running 1 table model, 1 view model in 2.31s.
2021-05-27 13:02:50.329520 (MainThread): Connection 'master' was properly closed.
2021-05-27 13:02:50.329559 (MainThread): Connection 'model.resourceplanner.my_first_dbt_model' was properly closed.
2021-05-27 13:02:50.329589 (MainThread): Connection 'list_oef-stage_TestRecoursePlanner' was properly closed.
2021-05-27 13:02:50.333062 (MainThread): 
2021-05-27 13:02:50.333257 (MainThread): Completed with 1 error and 0 warnings:
2021-05-27 13:02:50.333406 (MainThread): 
2021-05-27 13:02:50.333495 (MainThread): Database Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
2021-05-27 13:02:50.333579 (MainThread):   Table name "MainData" missing dataset while no default dataset is set in the request.
2021-05-27 13:02:50.333658 (MainThread):   compiled SQL at target/run/resourceplanner/models/example/my_first_dbt_model.sql
2021-05-27 13:02:50.333769 (MainThread): 
Done. PASS=0 WARN=0 ERROR=1 SKIP=1 TOTAL=2
2021-05-27 13:02:50.333927 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7adf700fd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7adf611970>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7adf5ab040>]}
2021-05-27 13:02:50.334051 (MainThread): Flushing usage events
2021-05-27 13:04:01.648826 (MainThread): Running with dbt=0.19.1
2021-05-27 13:04:01.842733 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/home/femke/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-05-27 13:04:01.843587 (MainThread): Tracking: tracking
2021-05-27 13:04:01.850035 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9ca0ed3af0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9ca27c81c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9ca27c8610>]}
2021-05-27 13:04:01.869419 (MainThread): Partial parsing not enabled
2021-05-27 13:04:01.870097 (MainThread): Parsing macros/catalog.sql
2021-05-27 13:04:01.882978 (MainThread): Parsing macros/adapters.sql
2021-05-27 13:04:01.899876 (MainThread): Parsing macros/etc.sql
2021-05-27 13:04:01.901352 (MainThread): Parsing macros/materializations/snapshot.sql
2021-05-27 13:04:01.902564 (MainThread): Parsing macros/materializations/copy.sql
2021-05-27 13:04:01.905730 (MainThread): Parsing macros/materializations/table.sql
2021-05-27 13:04:01.912784 (MainThread): Parsing macros/materializations/incremental.sql
2021-05-27 13:04:01.921382 (MainThread): Parsing macros/materializations/view.sql
2021-05-27 13:04:01.923303 (MainThread): Parsing macros/materializations/seed.sql
2021-05-27 13:04:01.925617 (MainThread): Parsing macros/core.sql
2021-05-27 13:04:01.928322 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-05-27 13:04:01.929356 (MainThread): Parsing macros/schema_tests/unique.sql
2021-05-27 13:04:01.930526 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-05-27 13:04:01.931785 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-05-27 13:04:01.933626 (MainThread): Parsing macros/materializations/helpers.sql
2021-05-27 13:04:01.939511 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-05-27 13:04:01.940757 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-05-27 13:04:01.945111 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-05-27 13:04:01.959146 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-05-27 13:04:01.979515 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-05-27 13:04:01.980726 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-05-27 13:04:01.993203 (MainThread): Parsing macros/materializations/table/table.sql
2021-05-27 13:04:01.997872 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-05-27 13:04:02.001277 (MainThread): Parsing macros/materializations/view/view.sql
2021-05-27 13:04:02.005629 (MainThread): Parsing macros/materializations/common/merge.sql
2021-05-27 13:04:02.014927 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-05-27 13:04:02.016029 (MainThread): Parsing macros/etc/query.sql
2021-05-27 13:04:02.016729 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-05-27 13:04:02.017366 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-05-27 13:04:02.018762 (MainThread): Parsing macros/etc/datetime.sql
2021-05-27 13:04:02.024656 (MainThread): Parsing macros/etc/is_incremental.sql
2021-05-27 13:04:02.025826 (MainThread): Parsing macros/adapters/common.sql
2021-05-27 13:04:02.056709 (MainThread): Partial parsing not enabled
2021-05-27 13:04:02.072685 (MainThread): Acquiring new bigquery connection "model.resourceplanner.my_second_dbt_model".
2021-05-27 13:04:02.079588 (MainThread): Acquiring new bigquery connection "model.resourceplanner.my_first_dbt_model".
2021-05-27 13:04:02.124142 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '4981da81-fcdb-4cc5-b4f1-7b222eee378d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9c9fed16d0>]}
2021-05-27 13:04:02.126735 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '4981da81-fcdb-4cc5-b4f1-7b222eee378d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9c9ffa4670>]}
2021-05-27 13:04:02.126866 (MainThread): Found 2 models, 4 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-05-27 13:04:02.127509 (MainThread): 
2021-05-27 13:04:02.127729 (MainThread): Acquiring new bigquery connection "master".
2021-05-27 13:04:02.128280 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_oef-stage".
2021-05-27 13:04:02.128404 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-05-27 13:04:02.400940 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_oef-stage_TestRecoursePlanner".
2021-05-27 13:04:02.401107 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2021-05-27 13:04:02.404242 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-05-27 13:04:02.610357 (MainThread): 15:04:02 | Concurrency: 5 threads (target='dev')
2021-05-27 13:04:02.610618 (MainThread): 15:04:02 | 
2021-05-27 13:04:02.612313 (Thread-1): Began running node model.resourceplanner.my_first_dbt_model
2021-05-27 13:04:02.612467 (Thread-1): 15:04:02 | 1 of 2 START table model TestRecoursePlanner.my_first_dbt_model...... [RUN]
2021-05-27 13:04:02.612656 (Thread-1): Acquiring new bigquery connection "model.resourceplanner.my_first_dbt_model".
2021-05-27 13:04:02.612730 (Thread-1): Compiling model.resourceplanner.my_first_dbt_model
2021-05-27 13:04:02.614812 (Thread-1): Writing injected SQL for node "model.resourceplanner.my_first_dbt_model"
2021-05-27 13:04:02.615170 (Thread-1): finished collecting timing info
2021-05-27 13:04:02.631032 (Thread-1): Opening a new connection, currently in state closed
2021-05-27 13:04:02.634636 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-05-27 13:04:02.831973 (Thread-1): Writing runtime SQL for node "model.resourceplanner.my_first_dbt_model"
2021-05-27 13:04:02.832391 (Thread-1): On model.resourceplanner.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "Bigquery", "target_name": "dev", "node_id": "model.resourceplanner.my_first_dbt_model"} */


  create or replace table `oef-stage`.`TestRecoursePlanner`.`my_first_dbt_model`
  
  
  OPTIONS()
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from oef-stage:TestRecoursePlanner.MainData
/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
    
2021-05-27 13:04:03.045848 (Thread-1): Retry attempt 1 of 1 after error: BadRequest('GET https://bigquery.googleapis.com/bigquery/v2/projects/oef-stage/queries/f4dd2dfb-b2be-404a-a841-03594cc9be79?maxResults=0&location=europe-west1&prettyPrint=false: Syntax error: Expected ")" but got ":" at [28:15]')
2021-05-27 13:04:03.290978 (Thread-1): finished collecting timing info
2021-05-27 13:04:03.291322 (Thread-1): Database Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  Syntax error: Expected ")" but got ":" at [28:15]
  compiled SQL at target/run/resourceplanner/models/example/my_first_dbt_model.sql
Traceback (most recent call last):
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 149, in exception_handler
    yield
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 327, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 520, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1146, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/job/base.py", line 631, in result
    return super(_AsyncJob, self).result(timeout=timeout, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/future/polling.py", line 129, in result
    self._blocking_poll(timeout=timeout, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1042, in _blocking_poll
    super(QueryJob, self)._blocking_poll(timeout=timeout, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/future/polling.py", line 107, in _blocking_poll
    retry_(self._done_or_raise)(**kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/future/polling.py", line 85, in _done_or_raise
    if not self.done(**kwargs):
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1022, in done
    self._query_results = self._client._get_query_results(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 1557, in _get_query_results
    resource = self._call_api(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 636, in _call_api
    return call()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/_http.py", line 438, in api_request
    raise exceptions.from_http_response(response)
google.api_core.exceptions.BadRequest: 400 GET https://bigquery.googleapis.com/bigquery/v2/projects/oef-stage/queries/027dbea7-dc2a-4208-b4f5-2e70d133ce2b?maxResults=0&location=europe-west1&prettyPrint=false: Syntax error: Expected ")" but got ":" at [28:15]

(job ID: 027dbea7-dc2a-4208-b4f5-2e70d133ce2b)

                                                              -----Query Job SQL Follows-----                                                              

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "Bigquery", "target_name": "dev", "node_id": "model.resourceplanner.my_first_dbt_model"} */
   2:
   3:
   4:  create or replace table `oef-stage`.`TestRecoursePlanner`.`my_first_dbt_model`
   5:  
   6:  
   7:  OPTIONS()
   8:  as (
   9:    /*
  10:    Welcome to your first dbt model!
  11:    Did you know that you can also configure models directly within SQL files?
  12:    This will override configurations stated in dbt_project.yml
  13:
  14:    Try changing "table" to "view" below
  15:*/
  16:
  17:
  18:
  19:with source_data as (
  20:
  21:    select 1 as id
  22:    union all
  23:    select null as id
  24:
  25:)
  26:
  27:select *
  28:from oef-stage:TestRecoursePlanner.MainData
  29:/*
  30:    Uncomment the line below to remove records with null `id` values
  31:*/
  32:
  33:-- where id is not null
  34:  );
  35:    
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/base.py", line 287, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/base.py", line 389, in run
    return self.execute(compiled_node, manifest)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/run.py", line 248, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 128, in macro
  File "/home/femke/dbt-env/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/home/femke/dbt-env/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 227, in execute
    return self.connections.execute(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 338, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 329, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 153, in exception_handler
    self.handle_error(e, message)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 141, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  Syntax error: Expected ")" but got ":" at [28:15]
  compiled SQL at target/run/resourceplanner/models/example/my_first_dbt_model.sql
2021-05-27 13:04:03.292962 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4981da81-fcdb-4cc5-b4f1-7b222eee378d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9c9ff193a0>]}
2021-05-27 13:04:03.293250 (Thread-1): 15:04:03 | 1 of 2 ERROR creating table model TestRecoursePlanner.my_first_dbt_model [ERROR in 0.68s]
2021-05-27 13:04:03.293445 (Thread-1): Finished running node model.resourceplanner.my_first_dbt_model
2021-05-27 13:04:03.293856 (Thread-3): Began running node model.resourceplanner.my_second_dbt_model
2021-05-27 13:04:03.293936 (Thread-3): 15:04:03 | 2 of 2 SKIP relation TestRecoursePlanner.my_second_dbt_model......... [SKIP]
2021-05-27 13:04:03.294042 (Thread-3): Finished running node model.resourceplanner.my_second_dbt_model
2021-05-27 13:04:03.294710 (MainThread): Acquiring new bigquery connection "master".
2021-05-27 13:04:03.294865 (MainThread): 15:04:03 | 
2021-05-27 13:04:03.294966 (MainThread): 15:04:03 | Finished running 1 table model, 1 view model in 1.17s.
2021-05-27 13:04:03.295055 (MainThread): Connection 'master' was properly closed.
2021-05-27 13:04:03.295095 (MainThread): Connection 'model.resourceplanner.my_first_dbt_model' was properly closed.
2021-05-27 13:04:03.295126 (MainThread): Connection 'list_oef-stage_TestRecoursePlanner' was properly closed.
2021-05-27 13:04:03.298102 (MainThread): 
2021-05-27 13:04:03.298220 (MainThread): Completed with 1 error and 0 warnings:
2021-05-27 13:04:03.298383 (MainThread): 
2021-05-27 13:04:03.298465 (MainThread): Database Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
2021-05-27 13:04:03.298549 (MainThread):   Syntax error: Expected ")" but got ":" at [28:15]
2021-05-27 13:04:03.298628 (MainThread):   compiled SQL at target/run/resourceplanner/models/example/my_first_dbt_model.sql
2021-05-27 13:04:03.298716 (MainThread): 
Done. PASS=0 WARN=0 ERROR=1 SKIP=1 TOTAL=2
2021-05-27 13:04:03.298863 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9ca00778b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9c9febae50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9c9ff86f70>]}
2021-05-27 13:04:03.298999 (MainThread): Flushing usage events
2021-05-27 13:06:16.249963 (MainThread): Running with dbt=0.19.1
2021-05-27 13:06:16.425008 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/home/femke/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-05-27 13:06:16.425615 (MainThread): Tracking: tracking
2021-05-27 13:06:16.435422 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb78a29cc70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb78bc11130>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb78bc11550>]}
2021-05-27 13:06:16.449928 (MainThread): Partial parsing not enabled
2021-05-27 13:06:16.450617 (MainThread): Parsing macros/catalog.sql
2021-05-27 13:06:16.459411 (MainThread): Parsing macros/adapters.sql
2021-05-27 13:06:16.479293 (MainThread): Parsing macros/etc.sql
2021-05-27 13:06:16.480763 (MainThread): Parsing macros/materializations/snapshot.sql
2021-05-27 13:06:16.481996 (MainThread): Parsing macros/materializations/copy.sql
2021-05-27 13:06:16.485061 (MainThread): Parsing macros/materializations/table.sql
2021-05-27 13:06:16.491891 (MainThread): Parsing macros/materializations/incremental.sql
2021-05-27 13:06:16.500523 (MainThread): Parsing macros/materializations/view.sql
2021-05-27 13:06:16.502477 (MainThread): Parsing macros/materializations/seed.sql
2021-05-27 13:06:16.504774 (MainThread): Parsing macros/core.sql
2021-05-27 13:06:16.507405 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-05-27 13:06:16.508405 (MainThread): Parsing macros/schema_tests/unique.sql
2021-05-27 13:06:16.509532 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-05-27 13:06:16.510789 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-05-27 13:06:16.512593 (MainThread): Parsing macros/materializations/helpers.sql
2021-05-27 13:06:16.518556 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-05-27 13:06:16.519776 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-05-27 13:06:16.524139 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-05-27 13:06:16.538014 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-05-27 13:06:16.561863 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-05-27 13:06:16.563126 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-05-27 13:06:16.575781 (MainThread): Parsing macros/materializations/table/table.sql
2021-05-27 13:06:16.580257 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-05-27 13:06:16.583537 (MainThread): Parsing macros/materializations/view/view.sql
2021-05-27 13:06:16.594654 (MainThread): Parsing macros/materializations/common/merge.sql
2021-05-27 13:06:16.604197 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-05-27 13:06:16.605436 (MainThread): Parsing macros/etc/query.sql
2021-05-27 13:06:16.606201 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-05-27 13:06:16.606847 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-05-27 13:06:16.608220 (MainThread): Parsing macros/etc/datetime.sql
2021-05-27 13:06:16.614198 (MainThread): Parsing macros/etc/is_incremental.sql
2021-05-27 13:06:16.615512 (MainThread): Parsing macros/adapters/common.sql
2021-05-27 13:06:16.646414 (MainThread): Partial parsing not enabled
2021-05-27 13:06:16.662197 (MainThread): Acquiring new bigquery connection "model.resourceplanner.my_second_dbt_model".
2021-05-27 13:06:16.668829 (MainThread): Acquiring new bigquery connection "model.resourceplanner.my_first_dbt_model".
2021-05-27 13:06:16.712899 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '03d88428-fca7-4297-8399-3e4edb69be5a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb7893188e0>]}
2021-05-27 13:06:16.715531 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '03d88428-fca7-4297-8399-3e4edb69be5a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb7893e8520>]}
2021-05-27 13:06:16.715679 (MainThread): Found 2 models, 4 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-05-27 13:06:16.716305 (MainThread): 
2021-05-27 13:06:16.716532 (MainThread): Acquiring new bigquery connection "master".
2021-05-27 13:06:16.717055 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_oef-stage".
2021-05-27 13:06:16.717201 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-05-27 13:06:17.040325 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_oef-stage_TestRecoursePlanner".
2021-05-27 13:06:17.040487 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2021-05-27 13:06:17.043771 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-05-27 13:06:17.225783 (MainThread): 15:06:17 | Concurrency: 5 threads (target='dev')
2021-05-27 13:06:17.226067 (MainThread): 15:06:17 | 
2021-05-27 13:06:17.227679 (Thread-1): Began running node model.resourceplanner.my_first_dbt_model
2021-05-27 13:06:17.227832 (Thread-1): 15:06:17 | 1 of 2 START table model TestRecoursePlanner.my_first_dbt_model...... [RUN]
2021-05-27 13:06:17.228046 (Thread-1): Acquiring new bigquery connection "model.resourceplanner.my_first_dbt_model".
2021-05-27 13:06:17.228121 (Thread-1): Compiling model.resourceplanner.my_first_dbt_model
2021-05-27 13:06:17.229722 (Thread-1): Writing injected SQL for node "model.resourceplanner.my_first_dbt_model"
2021-05-27 13:06:17.229921 (Thread-1): finished collecting timing info
2021-05-27 13:06:17.245209 (Thread-1): Opening a new connection, currently in state closed
2021-05-27 13:06:17.248520 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-05-27 13:06:17.429229 (Thread-1): Writing runtime SQL for node "model.resourceplanner.my_first_dbt_model"
2021-05-27 13:06:17.429667 (Thread-1): On model.resourceplanner.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "Bigquery", "target_name": "dev", "node_id": "model.resourceplanner.my_first_dbt_model"} */


  create or replace table `oef-stage`.`TestRecoursePlanner`.`my_first_dbt_model`
  
  
  OPTIONS()
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from oef-stage.TestRecoursePlanner.MainData
/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
    
2021-05-27 13:06:22.136548 (Thread-1): finished collecting timing info
2021-05-27 13:06:22.137090 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '03d88428-fca7-4297-8399-3e4edb69be5a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb7894003d0>]}
2021-05-27 13:06:22.137302 (Thread-1): 15:06:22 | 1 of 2 OK created table model TestRecoursePlanner.my_first_dbt_model. [CREATE TABLE (14.0 rows, 3.4 KB processed) in 4.91s]
2021-05-27 13:06:22.137478 (Thread-1): Finished running node model.resourceplanner.my_first_dbt_model
2021-05-27 13:06:22.138313 (Thread-3): Began running node model.resourceplanner.my_second_dbt_model
2021-05-27 13:06:22.138586 (Thread-3): 15:06:22 | 2 of 2 START view model TestRecoursePlanner.my_second_dbt_model...... [RUN]
2021-05-27 13:06:22.138936 (Thread-3): Acquiring new bigquery connection "model.resourceplanner.my_second_dbt_model".
2021-05-27 13:06:22.139013 (Thread-3): Compiling model.resourceplanner.my_second_dbt_model
2021-05-27 13:06:22.140577 (Thread-3): Writing injected SQL for node "model.resourceplanner.my_second_dbt_model"
2021-05-27 13:06:22.140872 (Thread-3): finished collecting timing info
2021-05-27 13:06:22.148569 (Thread-3): unclosed <socket.socket fd=5, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.0.2.15', 43530), raddr=('142.250.179.138', 443)>
2021-05-27 13:06:22.151531 (Thread-3): unclosed <socket.socket fd=6, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.0.2.15', 45276), raddr=('172.217.17.42', 443)>
2021-05-27 13:06:22.156211 (Thread-3): Writing runtime SQL for node "model.resourceplanner.my_second_dbt_model"
2021-05-27 13:06:22.156578 (Thread-3): Opening a new connection, currently in state init
2021-05-27 13:06:22.159653 (Thread-3): On model.resourceplanner.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "Bigquery", "target_name": "dev", "node_id": "model.resourceplanner.my_second_dbt_model"} */


  create or replace view `oef-stage`.`TestRecoursePlanner`.`my_second_dbt_model`
  OPTIONS()
  as -- Use the `ref` function to select from other models

select *
from `oef-stage`.`TestRecoursePlanner`.`my_first_dbt_model`
where id = 1;


2021-05-27 13:06:23.042346 (Thread-3): Retry attempt 1 of 1 after error: BadRequest('GET https://bigquery.googleapis.com/bigquery/v2/projects/oef-stage/queries/1bcff726-8cf7-4fea-90ff-e86657173a6b?maxResults=0&location=europe-west1&prettyPrint=false: No matching signature for operator = for argument types: STRING, INT64. Supported signature: ANY = ANY at [10:7]')
2021-05-27 13:06:24.931972 (Thread-3): finished collecting timing info
2021-05-27 13:06:24.932315 (Thread-3): Database Error in model my_second_dbt_model (models/example/my_second_dbt_model.sql)
  No matching signature for operator = for argument types: STRING, INT64. Supported signature: ANY = ANY at [10:7]
  compiled SQL at target/run/resourceplanner/models/example/my_second_dbt_model.sql
Traceback (most recent call last):
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 149, in exception_handler
    yield
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 327, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 520, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1146, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/job/base.py", line 631, in result
    return super(_AsyncJob, self).result(timeout=timeout, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/future/polling.py", line 129, in result
    self._blocking_poll(timeout=timeout, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1042, in _blocking_poll
    super(QueryJob, self)._blocking_poll(timeout=timeout, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/future/polling.py", line 107, in _blocking_poll
    retry_(self._done_or_raise)(**kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/future/polling.py", line 85, in _done_or_raise
    if not self.done(**kwargs):
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1022, in done
    self._query_results = self._client._get_query_results(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 1557, in _get_query_results
    resource = self._call_api(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 636, in _call_api
    return call()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/_http.py", line 438, in api_request
    raise exceptions.from_http_response(response)
google.api_core.exceptions.BadRequest: 400 GET https://bigquery.googleapis.com/bigquery/v2/projects/oef-stage/queries/d8d45400-9a05-4587-89bf-35721a3cf6b6?maxResults=0&location=europe-west1&prettyPrint=false: No matching signature for operator = for argument types: STRING, INT64. Supported signature: ANY = ANY at [10:7]

(job ID: d8d45400-9a05-4587-89bf-35721a3cf6b6)

                                                              -----Query Job SQL Follows-----                                                               

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "Bigquery", "target_name": "dev", "node_id": "model.resourceplanner.my_second_dbt_model"} */
   2:
   3:
   4:  create or replace view `oef-stage`.`TestRecoursePlanner`.`my_second_dbt_model`
   5:  OPTIONS()
   6:  as -- Use the `ref` function to select from other models
   7:
   8:select *
   9:from `oef-stage`.`TestRecoursePlanner`.`my_first_dbt_model`
  10:where id = 1;
  11:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/base.py", line 287, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/base.py", line 389, in run
    return self.execute(compiled_node, manifest)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/run.py", line 248, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 22, in macro
  File "/home/femke/dbt-env/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 65, in macro
  File "/home/femke/dbt-env/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/home/femke/dbt-env/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 227, in execute
    return self.connections.execute(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 338, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 329, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 153, in exception_handler
    self.handle_error(e, message)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 141, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in model my_second_dbt_model (models/example/my_second_dbt_model.sql)
  No matching signature for operator = for argument types: STRING, INT64. Supported signature: ANY = ANY at [10:7]
  compiled SQL at target/run/resourceplanner/models/example/my_second_dbt_model.sql
2021-05-27 13:06:24.934092 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '03d88428-fca7-4297-8399-3e4edb69be5a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb7893a6cd0>]}
2021-05-27 13:06:24.934318 (Thread-3): 15:06:24 | 2 of 2 ERROR creating view model TestRecoursePlanner.my_second_dbt_model [ERROR in 2.80s]
2021-05-27 13:06:24.934500 (Thread-3): Finished running node model.resourceplanner.my_second_dbt_model
2021-05-27 13:06:24.935353 (MainThread): Acquiring new bigquery connection "master".
2021-05-27 13:06:24.935508 (MainThread): 15:06:24 | 
2021-05-27 13:06:24.935611 (MainThread): 15:06:24 | Finished running 1 table model, 1 view model in 8.22s.
2021-05-27 13:06:24.935697 (MainThread): Connection 'master' was properly closed.
2021-05-27 13:06:24.935737 (MainThread): Connection 'model.resourceplanner.my_first_dbt_model' was properly closed.
2021-05-27 13:06:24.935768 (MainThread): Connection 'list_oef-stage_TestRecoursePlanner' was properly closed.
2021-05-27 13:06:24.935824 (MainThread): Connection 'model.resourceplanner.my_second_dbt_model' was properly closed.
2021-05-27 13:06:24.938674 (MainThread): 
2021-05-27 13:06:24.938813 (MainThread): Completed with 1 error and 0 warnings:
2021-05-27 13:06:24.938907 (MainThread): 
2021-05-27 13:06:24.938987 (MainThread): Database Error in model my_second_dbt_model (models/example/my_second_dbt_model.sql)
2021-05-27 13:06:24.939071 (MainThread):   No matching signature for operator = for argument types: STRING, INT64. Supported signature: ANY = ANY at [10:7]
2021-05-27 13:06:24.939155 (MainThread):   compiled SQL at target/run/resourceplanner/models/example/my_second_dbt_model.sql
2021-05-27 13:06:24.939247 (MainThread): 
Done. PASS=1 WARN=0 ERROR=1 SKIP=0 TOTAL=2
2021-05-27 13:06:24.939393 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb7893e6b20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb789301df0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb7894c0910>]}
2021-05-27 13:06:24.939512 (MainThread): Flushing usage events
2021-05-27 13:15:06.961924 (MainThread): Running with dbt=0.19.1
2021-05-27 13:15:07.137286 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/home/femke/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-05-27 13:15:07.137967 (MainThread): Tracking: tracking
2021-05-27 13:15:07.149358 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fade405af40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fade5951160>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fade5951610>]}
2021-05-27 13:15:07.168771 (MainThread): Partial parsing not enabled
2021-05-27 13:15:07.173488 (MainThread): Parsing macros/catalog.sql
2021-05-27 13:15:07.183961 (MainThread): Parsing macros/adapters.sql
2021-05-27 13:15:07.202682 (MainThread): Parsing macros/etc.sql
2021-05-27 13:15:07.205511 (MainThread): Parsing macros/materializations/snapshot.sql
2021-05-27 13:15:07.206786 (MainThread): Parsing macros/materializations/copy.sql
2021-05-27 13:15:07.209921 (MainThread): Parsing macros/materializations/table.sql
2021-05-27 13:15:07.218050 (MainThread): Parsing macros/materializations/incremental.sql
2021-05-27 13:15:07.226560 (MainThread): Parsing macros/materializations/view.sql
2021-05-27 13:15:07.228438 (MainThread): Parsing macros/materializations/seed.sql
2021-05-27 13:15:07.231847 (MainThread): Parsing macros/core.sql
2021-05-27 13:15:07.234558 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-05-27 13:15:07.235575 (MainThread): Parsing macros/schema_tests/unique.sql
2021-05-27 13:15:07.236711 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-05-27 13:15:07.238007 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-05-27 13:15:07.239796 (MainThread): Parsing macros/materializations/helpers.sql
2021-05-27 13:15:07.247155 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-05-27 13:15:07.248432 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-05-27 13:15:07.252668 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-05-27 13:15:07.268081 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-05-27 13:15:07.290842 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-05-27 13:15:07.292066 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-05-27 13:15:07.305454 (MainThread): Parsing macros/materializations/table/table.sql
2021-05-27 13:15:07.310068 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-05-27 13:15:07.314669 (MainThread): Parsing macros/materializations/view/view.sql
2021-05-27 13:15:07.318918 (MainThread): Parsing macros/materializations/common/merge.sql
2021-05-27 13:15:07.327924 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-05-27 13:15:07.329040 (MainThread): Parsing macros/etc/query.sql
2021-05-27 13:15:07.329786 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-05-27 13:15:07.330402 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-05-27 13:15:07.331764 (MainThread): Parsing macros/etc/datetime.sql
2021-05-27 13:15:07.337658 (MainThread): Parsing macros/etc/is_incremental.sql
2021-05-27 13:15:07.338805 (MainThread): Parsing macros/adapters/common.sql
2021-05-27 13:15:07.370138 (MainThread): Partial parsing not enabled
2021-05-27 13:15:07.386130 (MainThread): Acquiring new bigquery connection "model.resourceplanner.my_second_dbt_model".
2021-05-27 13:15:07.392879 (MainThread): Acquiring new bigquery connection "model.resourceplanner.my_first_dbt_model".
2021-05-27 13:15:07.437157 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'aacf2f0a-5de9-42a7-a9d5-f2fa820842a3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fade3059a00>]}
2021-05-27 13:15:07.439931 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'aacf2f0a-5de9-42a7-a9d5-f2fa820842a3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fade312c520>]}
2021-05-27 13:15:07.440075 (MainThread): Found 2 models, 4 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-05-27 13:15:07.440682 (MainThread): 
2021-05-27 13:15:07.440928 (MainThread): Acquiring new bigquery connection "master".
2021-05-27 13:15:07.441473 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_oef-stage".
2021-05-27 13:15:07.441591 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-05-27 13:15:07.827689 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_oef-stage_TestRecoursePlanner".
2021-05-27 13:15:07.827901 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2021-05-27 13:15:07.831120 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-05-27 13:15:08.040033 (MainThread): 15:15:08 | Concurrency: 5 threads (target='dev')
2021-05-27 13:15:08.040272 (MainThread): 15:15:08 | 
2021-05-27 13:15:08.041939 (Thread-1): Began running node model.resourceplanner.my_first_dbt_model
2021-05-27 13:15:08.042091 (Thread-1): 15:15:08 | 1 of 2 START table model TestRecoursePlanner.my_first_dbt_model...... [RUN]
2021-05-27 13:15:08.042281 (Thread-1): Acquiring new bigquery connection "model.resourceplanner.my_first_dbt_model".
2021-05-27 13:15:08.042352 (Thread-1): Compiling model.resourceplanner.my_first_dbt_model
2021-05-27 13:15:08.043947 (Thread-1): Writing injected SQL for node "model.resourceplanner.my_first_dbt_model"
2021-05-27 13:15:08.044157 (Thread-1): finished collecting timing info
2021-05-27 13:15:08.059170 (Thread-1): Opening a new connection, currently in state closed
2021-05-27 13:15:08.062420 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-05-27 13:15:08.301740 (Thread-1): Writing runtime SQL for node "model.resourceplanner.my_first_dbt_model"
2021-05-27 13:15:08.302204 (Thread-1): On model.resourceplanner.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "Bigquery", "target_name": "dev", "node_id": "model.resourceplanner.my_first_dbt_model"} */


  create or replace table `oef-stage`.`TestRecoursePlanner`.`my_first_dbt_model`
  
  
  OPTIONS()
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from oef-stage.TestRecoursePlanner.MainData
/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
    
2021-05-27 13:15:12.803438 (Thread-1): finished collecting timing info
2021-05-27 13:15:12.803738 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'aacf2f0a-5de9-42a7-a9d5-f2fa820842a3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fade315a940>]}
2021-05-27 13:15:12.803960 (Thread-1): 15:15:12 | 1 of 2 OK created table model TestRecoursePlanner.my_first_dbt_model. [CREATE TABLE (14.0 rows, 3.4 KB processed) in 4.76s]
2021-05-27 13:15:12.804156 (Thread-1): Finished running node model.resourceplanner.my_first_dbt_model
2021-05-27 13:15:12.804531 (Thread-3): Began running node model.resourceplanner.my_second_dbt_model
2021-05-27 13:15:12.804651 (Thread-3): 15:15:12 | 2 of 2 START view model TestRecoursePlanner.my_second_dbt_model...... [RUN]
2021-05-27 13:15:12.804848 (Thread-3): Acquiring new bigquery connection "model.resourceplanner.my_second_dbt_model".
2021-05-27 13:15:12.804911 (Thread-3): Compiling model.resourceplanner.my_second_dbt_model
2021-05-27 13:15:12.806235 (Thread-3): Writing injected SQL for node "model.resourceplanner.my_second_dbt_model"
2021-05-27 13:15:12.806466 (Thread-3): finished collecting timing info
2021-05-27 13:15:12.814017 (Thread-3): unclosed <socket.socket fd=5, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.0.2.15', 58278), raddr=('142.250.179.202', 443)>
2021-05-27 13:15:12.814180 (Thread-3): unclosed <socket.socket fd=6, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.0.2.15', 45884), raddr=('172.217.168.202', 443)>
2021-05-27 13:15:12.821063 (Thread-3): Writing runtime SQL for node "model.resourceplanner.my_second_dbt_model"
2021-05-27 13:15:12.821470 (Thread-3): Opening a new connection, currently in state init
2021-05-27 13:15:12.824559 (Thread-3): On model.resourceplanner.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "Bigquery", "target_name": "dev", "node_id": "model.resourceplanner.my_second_dbt_model"} */


  create or replace view `oef-stage`.`TestRecoursePlanner`.`my_second_dbt_model`
  OPTIONS()
  as -- Use the `ref` function to select from other models

select *
from `oef-stage`.`TestRecoursePlanner`.`my_first_dbt_model`;


2021-05-27 13:15:14.006965 (Thread-3): finished collecting timing info
2021-05-27 13:15:14.007256 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'aacf2f0a-5de9-42a7-a9d5-f2fa820842a3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fade31514f0>]}
2021-05-27 13:15:14.007456 (Thread-3): 15:15:14 | 2 of 2 OK created view model TestRecoursePlanner.my_second_dbt_model. [OK in 1.20s]
2021-05-27 13:15:14.007628 (Thread-3): Finished running node model.resourceplanner.my_second_dbt_model
2021-05-27 13:15:14.008408 (MainThread): Acquiring new bigquery connection "master".
2021-05-27 13:15:14.008559 (MainThread): 15:15:14 | 
2021-05-27 13:15:14.008660 (MainThread): 15:15:14 | Finished running 1 table model, 1 view model in 6.57s.
2021-05-27 13:15:14.008746 (MainThread): Connection 'master' was properly closed.
2021-05-27 13:15:14.008848 (MainThread): Connection 'model.resourceplanner.my_first_dbt_model' was properly closed.
2021-05-27 13:15:14.008883 (MainThread): Connection 'list_oef-stage_TestRecoursePlanner' was properly closed.
2021-05-27 13:15:14.008912 (MainThread): Connection 'model.resourceplanner.my_second_dbt_model' was properly closed.
2021-05-27 13:15:14.011969 (MainThread): 
2021-05-27 13:15:14.012157 (MainThread): Completed successfully
2021-05-27 13:15:14.012257 (MainThread): 
Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
2021-05-27 13:15:14.012413 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fade3042b20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fade3202be0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fade58e2250>]}
2021-05-27 13:15:14.012536 (MainThread): Flushing usage events
2021-05-27 13:34:09.229510 (MainThread): Running with dbt=0.19.1
2021-05-27 13:34:09.407664 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/home/femke/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-05-27 13:34:09.408305 (MainThread): Tracking: tracking
2021-05-27 13:34:09.418680 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9645610ac0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9646f84190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9646f845e0>]}
2021-05-27 13:34:09.429374 (MainThread): Partial parsing not enabled
2021-05-27 13:34:09.434262 (MainThread): Parsing macros/catalog.sql
2021-05-27 13:34:09.443633 (MainThread): Parsing macros/adapters.sql
2021-05-27 13:34:09.463835 (MainThread): Parsing macros/etc.sql
2021-05-27 13:34:09.465226 (MainThread): Parsing macros/materializations/snapshot.sql
2021-05-27 13:34:09.466440 (MainThread): Parsing macros/materializations/copy.sql
2021-05-27 13:34:09.469510 (MainThread): Parsing macros/materializations/table.sql
2021-05-27 13:34:09.476680 (MainThread): Parsing macros/materializations/incremental.sql
2021-05-27 13:34:09.485315 (MainThread): Parsing macros/materializations/view.sql
2021-05-27 13:34:09.487279 (MainThread): Parsing macros/materializations/seed.sql
2021-05-27 13:34:09.489546 (MainThread): Parsing macros/core.sql
2021-05-27 13:34:09.492298 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-05-27 13:34:09.493301 (MainThread): Parsing macros/schema_tests/unique.sql
2021-05-27 13:34:09.494447 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-05-27 13:34:09.495689 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-05-27 13:34:09.497456 (MainThread): Parsing macros/materializations/helpers.sql
2021-05-27 13:34:09.503493 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-05-27 13:34:09.504845 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-05-27 13:34:09.509246 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-05-27 13:34:09.525293 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-05-27 13:34:09.545757 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-05-27 13:34:09.547004 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-05-27 13:34:09.559209 (MainThread): Parsing macros/materializations/table/table.sql
2021-05-27 13:34:09.563840 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-05-27 13:34:09.567294 (MainThread): Parsing macros/materializations/view/view.sql
2021-05-27 13:34:09.571607 (MainThread): Parsing macros/materializations/common/merge.sql
2021-05-27 13:34:09.580940 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-05-27 13:34:09.582177 (MainThread): Parsing macros/etc/query.sql
2021-05-27 13:34:09.582907 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-05-27 13:34:09.583545 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-05-27 13:34:09.584949 (MainThread): Parsing macros/etc/datetime.sql
2021-05-27 13:34:09.591012 (MainThread): Parsing macros/etc/is_incremental.sql
2021-05-27 13:34:09.592390 (MainThread): Parsing macros/adapters/common.sql
2021-05-27 13:34:09.625003 (MainThread): Partial parsing not enabled
2021-05-27 13:34:09.641138 (MainThread): Acquiring new bigquery connection "model.resourceplanner.my_second_dbt_model".
2021-05-27 13:34:09.648343 (MainThread): Acquiring new bigquery connection "model.resourceplanner.my_first_dbt_model".
2021-05-27 13:34:09.698717 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b1ab3678-1500-4e94-9bb0-f3e99550e27a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f964468dd00>]}
2021-05-27 13:34:09.701313 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'b1ab3678-1500-4e94-9bb0-f3e99550e27a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f964476a640>]}
2021-05-27 13:34:09.701443 (MainThread): Found 2 models, 4 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-05-27 13:34:09.702114 (MainThread): 
2021-05-27 13:34:09.702346 (MainThread): Acquiring new bigquery connection "master".
2021-05-27 13:34:09.702964 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_oef-stage".
2021-05-27 13:34:09.703091 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-05-27 13:34:10.109941 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_oef-stage_TestRecoursePlanner".
2021-05-27 13:34:10.110123 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2021-05-27 13:34:10.113420 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-05-27 13:34:10.291187 (MainThread): 15:34:10 | Concurrency: 5 threads (target='dev')
2021-05-27 13:34:10.291656 (MainThread): 15:34:10 | 
2021-05-27 13:34:10.293333 (Thread-1): Began running node model.resourceplanner.my_first_dbt_model
2021-05-27 13:34:10.293486 (Thread-1): 15:34:10 | 1 of 2 START table model TestRecoursePlanner.my_first_dbt_model...... [RUN]
2021-05-27 13:34:10.293683 (Thread-1): Acquiring new bigquery connection "model.resourceplanner.my_first_dbt_model".
2021-05-27 13:34:10.293756 (Thread-1): Compiling model.resourceplanner.my_first_dbt_model
2021-05-27 13:34:10.295646 (Thread-1): Writing injected SQL for node "model.resourceplanner.my_first_dbt_model"
2021-05-27 13:34:10.295903 (Thread-1): finished collecting timing info
2021-05-27 13:34:10.312504 (Thread-1): Opening a new connection, currently in state closed
2021-05-27 13:34:10.315994 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-05-27 13:34:10.504458 (Thread-1): Writing runtime SQL for node "model.resourceplanner.my_first_dbt_model"
2021-05-27 13:34:10.504957 (Thread-1): On model.resourceplanner.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "Bigquery", "target_name": "dev", "node_id": "model.resourceplanner.my_first_dbt_model"} */


  create or replace table `oef-stage`.`TestRecoursePlanner`.`my_first_dbt_model`
  
  
  OPTIONS()
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select M.ID, E.EmployeeID, CU.CustomerID,CO.CompanyID
from oef-stage.TestRecoursePlanner.MainData M
INNER JOIN Employee E
ON M.Employee = E.Employee
INNER JOIN Customer CU
ON M.Customer = CU.Customername
INNER JOIN Company CO
ON M.Company = CO.Companyname

/*
    Uncomment the line below to remove records with null `id` values
*/
  );
    
2021-05-27 13:34:10.696046 (Thread-1): Retry attempt 1 of 1 after error: BadRequest('GET https://bigquery.googleapis.com/bigquery/v2/projects/oef-stage/queries/0a8df889-0123-4e56-b74c-ee44c5432aca?maxResults=0&location=europe-west1&prettyPrint=false: Table name "Company" missing dataset while no default dataset is set in the request.')
2021-05-27 13:34:11.891764 (Thread-1): finished collecting timing info
2021-05-27 13:34:11.892106 (Thread-1): Database Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  Table name "Company" missing dataset while no default dataset is set in the request.
  compiled SQL at target/run/resourceplanner/models/example/my_first_dbt_model.sql
Traceback (most recent call last):
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 149, in exception_handler
    yield
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 327, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 520, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1146, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/job/base.py", line 631, in result
    return super(_AsyncJob, self).result(timeout=timeout, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/future/polling.py", line 129, in result
    self._blocking_poll(timeout=timeout, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1042, in _blocking_poll
    super(QueryJob, self)._blocking_poll(timeout=timeout, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/future/polling.py", line 107, in _blocking_poll
    retry_(self._done_or_raise)(**kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/future/polling.py", line 85, in _done_or_raise
    if not self.done(**kwargs):
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1022, in done
    self._query_results = self._client._get_query_results(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 1557, in _get_query_results
    resource = self._call_api(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 636, in _call_api
    return call()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/_http.py", line 438, in api_request
    raise exceptions.from_http_response(response)
google.api_core.exceptions.BadRequest: 400 GET https://bigquery.googleapis.com/bigquery/v2/projects/oef-stage/queries/6d93a427-88c9-452b-9e46-f92c5cfed72d?maxResults=0&location=europe-west1&prettyPrint=false: Table name "Company" missing dataset while no default dataset is set in the request.

(job ID: 6d93a427-88c9-452b-9e46-f92c5cfed72d)

                                                              -----Query Job SQL Follows-----                                                              

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "Bigquery", "target_name": "dev", "node_id": "model.resourceplanner.my_first_dbt_model"} */
   2:
   3:
   4:  create or replace table `oef-stage`.`TestRecoursePlanner`.`my_first_dbt_model`
   5:  
   6:  
   7:  OPTIONS()
   8:  as (
   9:    /*
  10:    Welcome to your first dbt model!
  11:    Did you know that you can also configure models directly within SQL files?
  12:    This will override configurations stated in dbt_project.yml
  13:
  14:    Try changing "table" to "view" below
  15:*/
  16:
  17:
  18:
  19:with source_data as (
  20:
  21:    select 1 as id
  22:    union all
  23:    select null as id
  24:
  25:)
  26:
  27:select M.ID, E.EmployeeID, CU.CustomerID,CO.CompanyID
  28:from oef-stage.TestRecoursePlanner.MainData M
  29:INNER JOIN Employee E
  30:ON M.Employee = E.Employee
  31:INNER JOIN Customer CU
  32:ON M.Customer = CU.Customername
  33:INNER JOIN Company CO
  34:ON M.Company = CO.Companyname
  35:
  36:/*
  37:    Uncomment the line below to remove records with null `id` values
  38:*/
  39:  );
  40:    
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/base.py", line 287, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/base.py", line 389, in run
    return self.execute(compiled_node, manifest)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/run.py", line 248, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 128, in macro
  File "/home/femke/dbt-env/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/home/femke/dbt-env/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 227, in execute
    return self.connections.execute(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 338, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 329, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 153, in exception_handler
    self.handle_error(e, message)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 141, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  Table name "Company" missing dataset while no default dataset is set in the request.
  compiled SQL at target/run/resourceplanner/models/example/my_first_dbt_model.sql
2021-05-27 13:34:11.893792 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b1ab3678-1500-4e94-9bb0-f3e99550e27a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f96446d6310>]}
2021-05-27 13:34:11.894021 (Thread-1): 15:34:11 | 1 of 2 ERROR creating table model TestRecoursePlanner.my_first_dbt_model [ERROR in 1.60s]
2021-05-27 13:34:11.894260 (Thread-1): Finished running node model.resourceplanner.my_first_dbt_model
2021-05-27 13:34:11.894674 (Thread-3): Began running node model.resourceplanner.my_second_dbt_model
2021-05-27 13:34:11.894753 (Thread-3): 15:34:11 | 2 of 2 SKIP relation TestRecoursePlanner.my_second_dbt_model......... [SKIP]
2021-05-27 13:34:11.894859 (Thread-3): Finished running node model.resourceplanner.my_second_dbt_model
2021-05-27 13:34:11.895469 (MainThread): Acquiring new bigquery connection "master".
2021-05-27 13:34:11.895626 (MainThread): 15:34:11 | 
2021-05-27 13:34:11.895729 (MainThread): 15:34:11 | Finished running 1 table model, 1 view model in 2.19s.
2021-05-27 13:34:11.895816 (MainThread): Connection 'master' was properly closed.
2021-05-27 13:34:11.895856 (MainThread): Connection 'list_oef-stage' was properly closed.
2021-05-27 13:34:11.895886 (MainThread): Connection 'model.resourceplanner.my_first_dbt_model' was properly closed.
2021-05-27 13:34:11.899101 (MainThread): 
2021-05-27 13:34:11.899290 (MainThread): Completed with 1 error and 0 warnings:
2021-05-27 13:34:11.899386 (MainThread): 
2021-05-27 13:34:11.899467 (MainThread): Database Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
2021-05-27 13:34:11.899552 (MainThread):   Table name "Company" missing dataset while no default dataset is set in the request.
2021-05-27 13:34:11.899633 (MainThread):   compiled SQL at target/run/resourceplanner/models/example/my_first_dbt_model.sql
2021-05-27 13:34:11.899721 (MainThread): 
Done. PASS=0 WARN=0 ERROR=1 SKIP=1 TOTAL=2
2021-05-27 13:34:11.899876 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9644680eb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f96447383a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f96447385e0>]}
2021-05-27 13:34:11.900168 (MainThread): Flushing usage events
2021-05-27 13:34:41.134881 (MainThread): Running with dbt=0.19.1
2021-05-27 13:34:41.312270 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/home/femke/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-05-27 13:34:41.312918 (MainThread): Tracking: tracking
2021-05-27 13:34:41.323298 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4e5a754e20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4e5c088130>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4e5c0884f0>]}
2021-05-27 13:34:41.333915 (MainThread): Partial parsing not enabled
2021-05-27 13:34:41.338660 (MainThread): Parsing macros/catalog.sql
2021-05-27 13:34:41.347089 (MainThread): Parsing macros/adapters.sql
2021-05-27 13:34:41.368321 (MainThread): Parsing macros/etc.sql
2021-05-27 13:34:41.369728 (MainThread): Parsing macros/materializations/snapshot.sql
2021-05-27 13:34:41.370943 (MainThread): Parsing macros/materializations/copy.sql
2021-05-27 13:34:41.373999 (MainThread): Parsing macros/materializations/table.sql
2021-05-27 13:34:41.381219 (MainThread): Parsing macros/materializations/incremental.sql
2021-05-27 13:34:41.389759 (MainThread): Parsing macros/materializations/view.sql
2021-05-27 13:34:41.391705 (MainThread): Parsing macros/materializations/seed.sql
2021-05-27 13:34:41.394060 (MainThread): Parsing macros/core.sql
2021-05-27 13:34:41.396646 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-05-27 13:34:41.397712 (MainThread): Parsing macros/schema_tests/unique.sql
2021-05-27 13:34:41.398817 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-05-27 13:34:41.400050 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-05-27 13:34:41.401964 (MainThread): Parsing macros/materializations/helpers.sql
2021-05-27 13:34:41.408330 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-05-27 13:34:41.409637 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-05-27 13:34:41.414028 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-05-27 13:34:41.428496 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-05-27 13:34:41.449586 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-05-27 13:34:41.450845 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-05-27 13:34:41.463281 (MainThread): Parsing macros/materializations/table/table.sql
2021-05-27 13:34:41.467868 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-05-27 13:34:41.471488 (MainThread): Parsing macros/materializations/view/view.sql
2021-05-27 13:34:41.475782 (MainThread): Parsing macros/materializations/common/merge.sql
2021-05-27 13:34:41.485262 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-05-27 13:34:41.486433 (MainThread): Parsing macros/etc/query.sql
2021-05-27 13:34:41.487139 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-05-27 13:34:41.487761 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-05-27 13:34:41.489136 (MainThread): Parsing macros/etc/datetime.sql
2021-05-27 13:34:41.495134 (MainThread): Parsing macros/etc/is_incremental.sql
2021-05-27 13:34:41.496228 (MainThread): Parsing macros/adapters/common.sql
2021-05-27 13:34:41.528409 (MainThread): Partial parsing not enabled
2021-05-27 13:34:41.545250 (MainThread): Acquiring new bigquery connection "model.resourceplanner.my_second_dbt_model".
2021-05-27 13:34:41.552299 (MainThread): Acquiring new bigquery connection "model.resourceplanner.my_first_dbt_model".
2021-05-27 13:34:41.598662 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '4dadd97c-ec68-440b-aa31-f7bde1e56eb5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4e597cfbe0>]}
2021-05-27 13:34:41.603104 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '4dadd97c-ec68-440b-aa31-f7bde1e56eb5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4e59891f40>]}
2021-05-27 13:34:41.603370 (MainThread): Found 2 models, 4 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-05-27 13:34:41.604116 (MainThread): 
2021-05-27 13:34:41.604430 (MainThread): Acquiring new bigquery connection "master".
2021-05-27 13:34:41.605068 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_oef-stage".
2021-05-27 13:34:41.605191 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-05-27 13:34:41.881890 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_oef-stage_TestRecoursePlanner".
2021-05-27 13:34:41.882054 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2021-05-27 13:34:41.885223 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-05-27 13:34:42.065345 (MainThread): 15:34:42 | Concurrency: 5 threads (target='dev')
2021-05-27 13:34:42.065583 (MainThread): 15:34:42 | 
2021-05-27 13:34:42.067428 (Thread-1): Began running node model.resourceplanner.my_first_dbt_model
2021-05-27 13:34:42.067702 (Thread-1): 15:34:42 | 1 of 2 START table model TestRecoursePlanner.my_first_dbt_model...... [RUN]
2021-05-27 13:34:42.068019 (Thread-1): Acquiring new bigquery connection "model.resourceplanner.my_first_dbt_model".
2021-05-27 13:34:42.068108 (Thread-1): Compiling model.resourceplanner.my_first_dbt_model
2021-05-27 13:34:42.069910 (Thread-1): Writing injected SQL for node "model.resourceplanner.my_first_dbt_model"
2021-05-27 13:34:42.070147 (Thread-1): finished collecting timing info
2021-05-27 13:34:42.085558 (Thread-1): Opening a new connection, currently in state closed
2021-05-27 13:34:42.088885 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-05-27 13:34:42.277764 (Thread-1): Writing runtime SQL for node "model.resourceplanner.my_first_dbt_model"
2021-05-27 13:34:42.278289 (Thread-1): On model.resourceplanner.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "Bigquery", "target_name": "dev", "node_id": "model.resourceplanner.my_first_dbt_model"} */


  create or replace table `oef-stage`.`TestRecoursePlanner`.`my_first_dbt_model`
  
  
  OPTIONS()
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select M.ID, E.EmployeeID, CU.CustomerID,CO.CompanyID
from oef-stage.TestRecoursePlanner.MainData M
INNER JOIN oef-stage.TestRecoursePlanner.Employee E
ON M.Employee = E.Employee
INNER JOIN oef-stage.TestRecoursePlanner.Customer CU
ON M.Customer = CU.Customername
INNER JOIN oef-stage.TestRecoursePlanner.Company CO
ON M.Company = CO.Companyname

/*
    Uncomment the line below to remove records with null `id` values
*/
  );
    
2021-05-27 13:34:42.569730 (Thread-1): Retry attempt 1 of 1 after error: BadRequest('GET https://bigquery.googleapis.com/bigquery/v2/projects/oef-stage/queries/f80e2bbc-2364-4809-820b-ff956da66c84?maxResults=0&location=europe-west1&prettyPrint=false: Name Employee not found inside E at [30:19]')
2021-05-27 13:34:44.584536 (Thread-1): finished collecting timing info
2021-05-27 13:34:44.584886 (Thread-1): Database Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  Name Employee not found inside E at [30:19]
  compiled SQL at target/run/resourceplanner/models/example/my_first_dbt_model.sql
Traceback (most recent call last):
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 149, in exception_handler
    yield
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 327, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 520, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1146, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/job/base.py", line 631, in result
    return super(_AsyncJob, self).result(timeout=timeout, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/future/polling.py", line 129, in result
    self._blocking_poll(timeout=timeout, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1042, in _blocking_poll
    super(QueryJob, self)._blocking_poll(timeout=timeout, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/future/polling.py", line 107, in _blocking_poll
    retry_(self._done_or_raise)(**kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/future/polling.py", line 85, in _done_or_raise
    if not self.done(**kwargs):
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1022, in done
    self._query_results = self._client._get_query_results(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 1557, in _get_query_results
    resource = self._call_api(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 636, in _call_api
    return call()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/_http.py", line 438, in api_request
    raise exceptions.from_http_response(response)
google.api_core.exceptions.BadRequest: 400 GET https://bigquery.googleapis.com/bigquery/v2/projects/oef-stage/queries/cdb6471d-d1cc-4619-b447-b9378a288a46?maxResults=0&location=europe-west1&prettyPrint=false: Name Employee not found inside E at [30:19]

(job ID: cdb6471d-d1cc-4619-b447-b9378a288a46)

                                                              -----Query Job SQL Follows-----                                                              

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "Bigquery", "target_name": "dev", "node_id": "model.resourceplanner.my_first_dbt_model"} */
   2:
   3:
   4:  create or replace table `oef-stage`.`TestRecoursePlanner`.`my_first_dbt_model`
   5:  
   6:  
   7:  OPTIONS()
   8:  as (
   9:    /*
  10:    Welcome to your first dbt model!
  11:    Did you know that you can also configure models directly within SQL files?
  12:    This will override configurations stated in dbt_project.yml
  13:
  14:    Try changing "table" to "view" below
  15:*/
  16:
  17:
  18:
  19:with source_data as (
  20:
  21:    select 1 as id
  22:    union all
  23:    select null as id
  24:
  25:)
  26:
  27:select M.ID, E.EmployeeID, CU.CustomerID,CO.CompanyID
  28:from oef-stage.TestRecoursePlanner.MainData M
  29:INNER JOIN oef-stage.TestRecoursePlanner.Employee E
  30:ON M.Employee = E.Employee
  31:INNER JOIN oef-stage.TestRecoursePlanner.Customer CU
  32:ON M.Customer = CU.Customername
  33:INNER JOIN oef-stage.TestRecoursePlanner.Company CO
  34:ON M.Company = CO.Companyname
  35:
  36:/*
  37:    Uncomment the line below to remove records with null `id` values
  38:*/
  39:  );
  40:    
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/base.py", line 287, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/base.py", line 389, in run
    return self.execute(compiled_node, manifest)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/run.py", line 248, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 128, in macro
  File "/home/femke/dbt-env/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/home/femke/dbt-env/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 227, in execute
    return self.connections.execute(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 338, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 329, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 153, in exception_handler
    self.handle_error(e, message)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 141, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  Name Employee not found inside E at [30:19]
  compiled SQL at target/run/resourceplanner/models/example/my_first_dbt_model.sql
2021-05-27 13:34:44.586724 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4dadd97c-ec68-440b-aa31-f7bde1e56eb5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4e59883b80>]}
2021-05-27 13:34:44.586980 (Thread-1): 15:34:44 | 1 of 2 ERROR creating table model TestRecoursePlanner.my_first_dbt_model [ERROR in 2.52s]
2021-05-27 13:34:44.587163 (Thread-1): Finished running node model.resourceplanner.my_first_dbt_model
2021-05-27 13:34:44.587581 (Thread-3): Began running node model.resourceplanner.my_second_dbt_model
2021-05-27 13:34:44.587662 (Thread-3): 15:34:44 | 2 of 2 SKIP relation TestRecoursePlanner.my_second_dbt_model......... [SKIP]
2021-05-27 13:34:44.587767 (Thread-3): Finished running node model.resourceplanner.my_second_dbt_model
2021-05-27 13:34:44.588441 (MainThread): Acquiring new bigquery connection "master".
2021-05-27 13:34:44.588618 (MainThread): 15:34:44 | 
2021-05-27 13:34:44.588724 (MainThread): 15:34:44 | Finished running 1 table model, 1 view model in 2.98s.
2021-05-27 13:34:44.588844 (MainThread): Connection 'master' was properly closed.
2021-05-27 13:34:44.588914 (MainThread): Connection 'model.resourceplanner.my_first_dbt_model' was properly closed.
2021-05-27 13:34:44.588951 (MainThread): Connection 'list_oef-stage_TestRecoursePlanner' was properly closed.
2021-05-27 13:34:44.592141 (MainThread): 
2021-05-27 13:34:44.592344 (MainThread): Completed with 1 error and 0 warnings:
2021-05-27 13:34:44.592437 (MainThread): 
2021-05-27 13:34:44.592518 (MainThread): Database Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
2021-05-27 13:34:44.592600 (MainThread):   Name Employee not found inside E at [30:19]
2021-05-27 13:34:44.592678 (MainThread):   compiled SQL at target/run/resourceplanner/models/example/my_first_dbt_model.sql
2021-05-27 13:34:44.592806 (MainThread): 
Done. PASS=0 WARN=0 ERROR=1 SKIP=1 TOTAL=2
2021-05-27 13:34:44.592983 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4e597b1a00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4e597b9d90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4e597b9d60>]}
2021-05-27 13:34:44.593111 (MainThread): Flushing usage events
2021-05-27 13:36:27.150446 (MainThread): Running with dbt=0.19.1
2021-05-27 13:36:27.325898 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/home/femke/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-05-27 13:36:27.326546 (MainThread): Tracking: tracking
2021-05-27 13:36:27.336941 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7e19253e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7e1ab86190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7e1ab86550>]}
2021-05-27 13:36:27.352419 (MainThread): Partial parsing not enabled
2021-05-27 13:36:27.353103 (MainThread): Parsing macros/catalog.sql
2021-05-27 13:36:27.361511 (MainThread): Parsing macros/adapters.sql
2021-05-27 13:36:27.389423 (MainThread): Parsing macros/etc.sql
2021-05-27 13:36:27.390886 (MainThread): Parsing macros/materializations/snapshot.sql
2021-05-27 13:36:27.392076 (MainThread): Parsing macros/materializations/copy.sql
2021-05-27 13:36:27.399288 (MainThread): Parsing macros/materializations/table.sql
2021-05-27 13:36:27.417125 (MainThread): Parsing macros/materializations/incremental.sql
2021-05-27 13:36:27.426073 (MainThread): Parsing macros/materializations/view.sql
2021-05-27 13:36:27.428044 (MainThread): Parsing macros/materializations/seed.sql
2021-05-27 13:36:27.430609 (MainThread): Parsing macros/core.sql
2021-05-27 13:36:27.433388 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-05-27 13:36:27.434523 (MainThread): Parsing macros/schema_tests/unique.sql
2021-05-27 13:36:27.435769 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-05-27 13:36:27.437086 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-05-27 13:36:27.439015 (MainThread): Parsing macros/materializations/helpers.sql
2021-05-27 13:36:27.444884 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-05-27 13:36:27.446173 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-05-27 13:36:27.450436 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-05-27 13:36:27.464643 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-05-27 13:36:27.485221 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-05-27 13:36:27.486490 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-05-27 13:36:27.498968 (MainThread): Parsing macros/materializations/table/table.sql
2021-05-27 13:36:27.503647 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-05-27 13:36:27.506967 (MainThread): Parsing macros/materializations/view/view.sql
2021-05-27 13:36:27.511237 (MainThread): Parsing macros/materializations/common/merge.sql
2021-05-27 13:36:27.520537 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-05-27 13:36:27.521715 (MainThread): Parsing macros/etc/query.sql
2021-05-27 13:36:27.522378 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-05-27 13:36:27.522996 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-05-27 13:36:27.524385 (MainThread): Parsing macros/etc/datetime.sql
2021-05-27 13:36:27.530238 (MainThread): Parsing macros/etc/is_incremental.sql
2021-05-27 13:36:27.531476 (MainThread): Parsing macros/adapters/common.sql
2021-05-27 13:36:27.562195 (MainThread): Partial parsing not enabled
2021-05-27 13:36:27.580329 (MainThread): Acquiring new bigquery connection "model.resourceplanner.my_second_dbt_model".
2021-05-27 13:36:27.587620 (MainThread): Acquiring new bigquery connection "model.resourceplanner.my_first_dbt_model".
2021-05-27 13:36:27.634435 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e7d31306-53a6-40e8-a79d-b7b5bb21350e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7e182cd4f0>]}
2021-05-27 13:36:27.637240 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e7d31306-53a6-40e8-a79d-b7b5bb21350e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7e183ab4f0>]}
2021-05-27 13:36:27.637372 (MainThread): Found 2 models, 4 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-05-27 13:36:27.638044 (MainThread): 
2021-05-27 13:36:27.638271 (MainThread): Acquiring new bigquery connection "master".
2021-05-27 13:36:27.638828 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_oef-stage".
2021-05-27 13:36:27.638949 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-05-27 13:36:27.947047 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_oef-stage_TestRecoursePlanner".
2021-05-27 13:36:27.947207 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2021-05-27 13:36:27.950643 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-05-27 13:36:28.131534 (MainThread): 15:36:28 | Concurrency: 5 threads (target='dev')
2021-05-27 13:36:28.131773 (MainThread): 15:36:28 | 
2021-05-27 13:36:28.133650 (Thread-1): Began running node model.resourceplanner.my_first_dbt_model
2021-05-27 13:36:28.133809 (Thread-1): 15:36:28 | 1 of 2 START table model TestRecoursePlanner.my_first_dbt_model...... [RUN]
2021-05-27 13:36:28.134006 (Thread-1): Acquiring new bigquery connection "model.resourceplanner.my_first_dbt_model".
2021-05-27 13:36:28.134080 (Thread-1): Compiling model.resourceplanner.my_first_dbt_model
2021-05-27 13:36:28.136133 (Thread-1): Writing injected SQL for node "model.resourceplanner.my_first_dbt_model"
2021-05-27 13:36:28.136424 (Thread-1): finished collecting timing info
2021-05-27 13:36:28.153914 (Thread-1): Opening a new connection, currently in state closed
2021-05-27 13:36:28.157134 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-05-27 13:36:28.336770 (Thread-1): Writing runtime SQL for node "model.resourceplanner.my_first_dbt_model"
2021-05-27 13:36:28.337423 (Thread-1): On model.resourceplanner.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "Bigquery", "target_name": "dev", "node_id": "model.resourceplanner.my_first_dbt_model"} */


  create or replace table `oef-stage`.`TestRecoursePlanner`.`my_first_dbt_model`
  
  
  OPTIONS()
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select M.ID, E.EmployeeID, CU.CustomerID,CO.CompanyID
from oef-stage.TestRecoursePlanner.MainData M
OUTER JOIN oef-stage.TestRecoursePlanner.Employee E
ON M.Employee = E.Employee
OUTER JOIN oef-stage.TestRecoursePlanner.Customer CU
ON M.Customer = CU.Customername
OUTER JOIN oef-stage.TestRecoursePlanner.Company CO
ON M.Company = CO.Companyname

/*
    Uncomment the line below to remove records with null `id` values
*/
  );
    
2021-05-27 13:36:28.489939 (Thread-1): Retry attempt 1 of 1 after error: BadRequest('GET https://bigquery.googleapis.com/bigquery/v2/projects/oef-stage/queries/82919b40-dd29-404d-8536-1f8d99832612?maxResults=0&location=europe-west1&prettyPrint=false: Syntax error: Expected ")" but got keyword OUTER at [29:1]')
2021-05-27 13:36:29.655464 (Thread-1): finished collecting timing info
2021-05-27 13:36:29.655781 (Thread-1): Database Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  Syntax error: Expected ")" but got keyword OUTER at [29:1]
  compiled SQL at target/run/resourceplanner/models/example/my_first_dbt_model.sql
Traceback (most recent call last):
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 149, in exception_handler
    yield
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 327, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 520, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1146, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/job/base.py", line 631, in result
    return super(_AsyncJob, self).result(timeout=timeout, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/future/polling.py", line 129, in result
    self._blocking_poll(timeout=timeout, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1042, in _blocking_poll
    super(QueryJob, self)._blocking_poll(timeout=timeout, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/future/polling.py", line 107, in _blocking_poll
    retry_(self._done_or_raise)(**kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/future/polling.py", line 85, in _done_or_raise
    if not self.done(**kwargs):
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1022, in done
    self._query_results = self._client._get_query_results(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 1557, in _get_query_results
    resource = self._call_api(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 636, in _call_api
    return call()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/_http.py", line 438, in api_request
    raise exceptions.from_http_response(response)
google.api_core.exceptions.BadRequest: 400 GET https://bigquery.googleapis.com/bigquery/v2/projects/oef-stage/queries/c81f07ab-33d4-4c43-b289-ca4cbe134925?maxResults=0&location=europe-west1&prettyPrint=false: Syntax error: Expected ")" but got keyword OUTER at [29:1]

(job ID: c81f07ab-33d4-4c43-b289-ca4cbe134925)

                                                              -----Query Job SQL Follows-----                                                              

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "Bigquery", "target_name": "dev", "node_id": "model.resourceplanner.my_first_dbt_model"} */
   2:
   3:
   4:  create or replace table `oef-stage`.`TestRecoursePlanner`.`my_first_dbt_model`
   5:  
   6:  
   7:  OPTIONS()
   8:  as (
   9:    /*
  10:    Welcome to your first dbt model!
  11:    Did you know that you can also configure models directly within SQL files?
  12:    This will override configurations stated in dbt_project.yml
  13:
  14:    Try changing "table" to "view" below
  15:*/
  16:
  17:
  18:
  19:with source_data as (
  20:
  21:    select 1 as id
  22:    union all
  23:    select null as id
  24:
  25:)
  26:
  27:select M.ID, E.EmployeeID, CU.CustomerID,CO.CompanyID
  28:from oef-stage.TestRecoursePlanner.MainData M
  29:OUTER JOIN oef-stage.TestRecoursePlanner.Employee E
  30:ON M.Employee = E.Employee
  31:OUTER JOIN oef-stage.TestRecoursePlanner.Customer CU
  32:ON M.Customer = CU.Customername
  33:OUTER JOIN oef-stage.TestRecoursePlanner.Company CO
  34:ON M.Company = CO.Companyname
  35:
  36:/*
  37:    Uncomment the line below to remove records with null `id` values
  38:*/
  39:  );
  40:    
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/base.py", line 287, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/base.py", line 389, in run
    return self.execute(compiled_node, manifest)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/run.py", line 248, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 128, in macro
  File "/home/femke/dbt-env/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/home/femke/dbt-env/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 227, in execute
    return self.connections.execute(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 338, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 329, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 153, in exception_handler
    self.handle_error(e, message)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 141, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  Syntax error: Expected ")" but got keyword OUTER at [29:1]
  compiled SQL at target/run/resourceplanner/models/example/my_first_dbt_model.sql
2021-05-27 13:36:29.658078 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e7d31306-53a6-40e8-a79d-b7b5bb21350e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7e183b8b50>]}
2021-05-27 13:36:29.658371 (Thread-1): 15:36:29 | 1 of 2 ERROR creating table model TestRecoursePlanner.my_first_dbt_model [ERROR in 1.52s]
2021-05-27 13:36:29.658506 (Thread-1): Finished running node model.resourceplanner.my_first_dbt_model
2021-05-27 13:36:29.658915 (Thread-3): Began running node model.resourceplanner.my_second_dbt_model
2021-05-27 13:36:29.658996 (Thread-3): 15:36:29 | 2 of 2 SKIP relation TestRecoursePlanner.my_second_dbt_model......... [SKIP]
2021-05-27 13:36:29.659103 (Thread-3): Finished running node model.resourceplanner.my_second_dbt_model
2021-05-27 13:36:29.659730 (MainThread): Acquiring new bigquery connection "master".
2021-05-27 13:36:29.659886 (MainThread): 15:36:29 | 
2021-05-27 13:36:29.659986 (MainThread): 15:36:29 | Finished running 1 table model, 1 view model in 2.02s.
2021-05-27 13:36:29.660074 (MainThread): Connection 'master' was properly closed.
2021-05-27 13:36:29.660114 (MainThread): Connection 'model.resourceplanner.my_first_dbt_model' was properly closed.
2021-05-27 13:36:29.660147 (MainThread): Connection 'list_oef-stage_TestRecoursePlanner' was properly closed.
2021-05-27 13:36:29.663754 (MainThread): 
2021-05-27 13:36:29.663954 (MainThread): Completed with 1 error and 0 warnings:
2021-05-27 13:36:29.664048 (MainThread): 
2021-05-27 13:36:29.665863 (MainThread): Database Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
2021-05-27 13:36:29.665999 (MainThread):   Syntax error: Expected ")" but got keyword OUTER at [29:1]
2021-05-27 13:36:29.666112 (MainThread):   compiled SQL at target/run/resourceplanner/models/example/my_first_dbt_model.sql
2021-05-27 13:36:29.666239 (MainThread): 
Done. PASS=0 WARN=0 ERROR=1 SKIP=1 TOTAL=2
2021-05-27 13:36:29.666423 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7e1831e040>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7e182b7df0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7e182b7a30>]}
2021-05-27 13:36:29.666561 (MainThread): Flushing usage events
2021-05-27 13:37:07.195219 (MainThread): Running with dbt=0.19.1
2021-05-27 13:37:07.370577 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/home/femke/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-05-27 13:37:07.371193 (MainThread): Tracking: tracking
2021-05-27 13:37:07.381395 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fda64af4fd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fda64b74490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fda64b074f0>]}
2021-05-27 13:37:07.396577 (MainThread): Partial parsing not enabled
2021-05-27 13:37:07.397324 (MainThread): Parsing macros/catalog.sql
2021-05-27 13:37:07.410939 (MainThread): Parsing macros/adapters.sql
2021-05-27 13:37:07.427088 (MainThread): Parsing macros/etc.sql
2021-05-27 13:37:07.428460 (MainThread): Parsing macros/materializations/snapshot.sql
2021-05-27 13:37:07.429632 (MainThread): Parsing macros/materializations/copy.sql
2021-05-27 13:37:07.432752 (MainThread): Parsing macros/materializations/table.sql
2021-05-27 13:37:07.439629 (MainThread): Parsing macros/materializations/incremental.sql
2021-05-27 13:37:07.448213 (MainThread): Parsing macros/materializations/view.sql
2021-05-27 13:37:07.450114 (MainThread): Parsing macros/materializations/seed.sql
2021-05-27 13:37:07.452318 (MainThread): Parsing macros/core.sql
2021-05-27 13:37:07.454859 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-05-27 13:37:07.455847 (MainThread): Parsing macros/schema_tests/unique.sql
2021-05-27 13:37:07.456964 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-05-27 13:37:07.458194 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-05-27 13:37:07.459962 (MainThread): Parsing macros/materializations/helpers.sql
2021-05-27 13:37:07.465842 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-05-27 13:37:07.467083 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-05-27 13:37:07.471342 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-05-27 13:37:07.485127 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-05-27 13:37:07.505227 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-05-27 13:37:07.506607 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-05-27 13:37:07.518874 (MainThread): Parsing macros/materializations/table/table.sql
2021-05-27 13:37:07.523494 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-05-27 13:37:07.526807 (MainThread): Parsing macros/materializations/view/view.sql
2021-05-27 13:37:07.531144 (MainThread): Parsing macros/materializations/common/merge.sql
2021-05-27 13:37:07.540188 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-05-27 13:37:07.541318 (MainThread): Parsing macros/etc/query.sql
2021-05-27 13:37:07.542038 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-05-27 13:37:07.542662 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-05-27 13:37:07.544033 (MainThread): Parsing macros/etc/datetime.sql
2021-05-27 13:37:07.549773 (MainThread): Parsing macros/etc/is_incremental.sql
2021-05-27 13:37:07.550885 (MainThread): Parsing macros/adapters/common.sql
2021-05-27 13:37:07.582156 (MainThread): Partial parsing not enabled
2021-05-27 13:37:07.598313 (MainThread): Acquiring new bigquery connection "model.resourceplanner.my_second_dbt_model".
2021-05-27 13:37:07.607430 (MainThread): Acquiring new bigquery connection "model.resourceplanner.my_first_dbt_model".
2021-05-27 13:37:07.652810 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '6925a1cb-257d-4718-93c1-b05240647e3c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fda6224f850>]}
2021-05-27 13:37:07.655496 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '6925a1cb-257d-4718-93c1-b05240647e3c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fda6232f430>]}
2021-05-27 13:37:07.655642 (MainThread): Found 2 models, 4 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-05-27 13:37:07.656237 (MainThread): 
2021-05-27 13:37:07.656483 (MainThread): Acquiring new bigquery connection "master".
2021-05-27 13:37:07.657022 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_oef-stage".
2021-05-27 13:37:07.657144 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-05-27 13:37:07.954021 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_oef-stage_TestRecoursePlanner".
2021-05-27 13:37:07.954182 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2021-05-27 13:37:07.957431 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-05-27 13:37:08.124428 (MainThread): 15:37:08 | Concurrency: 5 threads (target='dev')
2021-05-27 13:37:08.124661 (MainThread): 15:37:08 | 
2021-05-27 13:37:08.126267 (Thread-1): Began running node model.resourceplanner.my_first_dbt_model
2021-05-27 13:37:08.126487 (Thread-1): 15:37:08 | 1 of 2 START table model TestRecoursePlanner.my_first_dbt_model...... [RUN]
2021-05-27 13:37:08.126683 (Thread-1): Acquiring new bigquery connection "model.resourceplanner.my_first_dbt_model".
2021-05-27 13:37:08.126756 (Thread-1): Compiling model.resourceplanner.my_first_dbt_model
2021-05-27 13:37:08.128717 (Thread-1): Writing injected SQL for node "model.resourceplanner.my_first_dbt_model"
2021-05-27 13:37:08.129200 (Thread-1): finished collecting timing info
2021-05-27 13:37:08.143377 (Thread-1): Opening a new connection, currently in state closed
2021-05-27 13:37:08.148373 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-05-27 13:37:08.329487 (Thread-1): Writing runtime SQL for node "model.resourceplanner.my_first_dbt_model"
2021-05-27 13:37:08.330029 (Thread-1): On model.resourceplanner.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "Bigquery", "target_name": "dev", "node_id": "model.resourceplanner.my_first_dbt_model"} */


  create or replace table `oef-stage`.`TestRecoursePlanner`.`my_first_dbt_model`
  
  
  OPTIONS()
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select M.ID, E.EmployeeID, CU.CustomerID,CO.CompanyID
from oef-stage.TestRecoursePlanner.MainData M
FULL JOIN oef-stage.TestRecoursePlanner.Employee E
ON M.Employee = E.Employee
FULL JOIN oef-stage.TestRecoursePlanner.Customer CU
ON M.Customer = CU.Customername
FULL JOIN oef-stage.TestRecoursePlanner.Company CO
ON M.Company = CO.Companyname

/*
    Uncomment the line below to remove records with null `id` values
*/
  );
    
2021-05-27 13:37:08.569272 (Thread-1): Retry attempt 1 of 1 after error: BadRequest('GET https://bigquery.googleapis.com/bigquery/v2/projects/oef-stage/queries/5f2af808-6b68-4260-be75-f6b0054aa8ae?maxResults=0&location=europe-west1&prettyPrint=false: Name Employee not found inside E at [30:19]')
2021-05-27 13:37:10.282531 (Thread-1): finished collecting timing info
2021-05-27 13:37:10.282950 (Thread-1): Database Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  Name Employee not found inside E at [30:19]
  compiled SQL at target/run/resourceplanner/models/example/my_first_dbt_model.sql
Traceback (most recent call last):
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 149, in exception_handler
    yield
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 327, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 520, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1146, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/job/base.py", line 631, in result
    return super(_AsyncJob, self).result(timeout=timeout, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/future/polling.py", line 129, in result
    self._blocking_poll(timeout=timeout, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1042, in _blocking_poll
    super(QueryJob, self)._blocking_poll(timeout=timeout, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/future/polling.py", line 107, in _blocking_poll
    retry_(self._done_or_raise)(**kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/future/polling.py", line 85, in _done_or_raise
    if not self.done(**kwargs):
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1022, in done
    self._query_results = self._client._get_query_results(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 1557, in _get_query_results
    resource = self._call_api(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 636, in _call_api
    return call()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/_http.py", line 438, in api_request
    raise exceptions.from_http_response(response)
google.api_core.exceptions.BadRequest: 400 GET https://bigquery.googleapis.com/bigquery/v2/projects/oef-stage/queries/0bbf2694-dc9f-40de-bc94-0e3b7a732644?maxResults=0&location=europe-west1&prettyPrint=false: Name Employee not found inside E at [30:19]

(job ID: 0bbf2694-dc9f-40de-bc94-0e3b7a732644)

                                                              -----Query Job SQL Follows-----                                                              

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "Bigquery", "target_name": "dev", "node_id": "model.resourceplanner.my_first_dbt_model"} */
   2:
   3:
   4:  create or replace table `oef-stage`.`TestRecoursePlanner`.`my_first_dbt_model`
   5:  
   6:  
   7:  OPTIONS()
   8:  as (
   9:    /*
  10:    Welcome to your first dbt model!
  11:    Did you know that you can also configure models directly within SQL files?
  12:    This will override configurations stated in dbt_project.yml
  13:
  14:    Try changing "table" to "view" below
  15:*/
  16:
  17:
  18:
  19:with source_data as (
  20:
  21:    select 1 as id
  22:    union all
  23:    select null as id
  24:
  25:)
  26:
  27:select M.ID, E.EmployeeID, CU.CustomerID,CO.CompanyID
  28:from oef-stage.TestRecoursePlanner.MainData M
  29:FULL JOIN oef-stage.TestRecoursePlanner.Employee E
  30:ON M.Employee = E.Employee
  31:FULL JOIN oef-stage.TestRecoursePlanner.Customer CU
  32:ON M.Customer = CU.Customername
  33:FULL JOIN oef-stage.TestRecoursePlanner.Company CO
  34:ON M.Company = CO.Companyname
  35:
  36:/*
  37:    Uncomment the line below to remove records with null `id` values
  38:*/
  39:  );
  40:    
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/base.py", line 287, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/base.py", line 389, in run
    return self.execute(compiled_node, manifest)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/run.py", line 248, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 128, in macro
  File "/home/femke/dbt-env/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/home/femke/dbt-env/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 227, in execute
    return self.connections.execute(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 338, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 329, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 153, in exception_handler
    self.handle_error(e, message)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 141, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  Name Employee not found inside E at [30:19]
  compiled SQL at target/run/resourceplanner/models/example/my_first_dbt_model.sql
2021-05-27 13:37:10.284683 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6925a1cb-257d-4718-93c1-b05240647e3c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fda623479d0>]}
2021-05-27 13:37:10.284912 (Thread-1): 15:37:10 | 1 of 2 ERROR creating table model TestRecoursePlanner.my_first_dbt_model [ERROR in 2.16s]
2021-05-27 13:37:10.285104 (Thread-1): Finished running node model.resourceplanner.my_first_dbt_model
2021-05-27 13:37:10.285551 (Thread-3): Began running node model.resourceplanner.my_second_dbt_model
2021-05-27 13:37:10.285634 (Thread-3): 15:37:10 | 2 of 2 SKIP relation TestRecoursePlanner.my_second_dbt_model......... [SKIP]
2021-05-27 13:37:10.285742 (Thread-3): Finished running node model.resourceplanner.my_second_dbt_model
2021-05-27 13:37:10.286461 (MainThread): Acquiring new bigquery connection "master".
2021-05-27 13:37:10.286627 (MainThread): 15:37:10 | 
2021-05-27 13:37:10.286729 (MainThread): 15:37:10 | Finished running 1 table model, 1 view model in 2.63s.
2021-05-27 13:37:10.286816 (MainThread): Connection 'master' was properly closed.
2021-05-27 13:37:10.286855 (MainThread): Connection 'model.resourceplanner.my_first_dbt_model' was properly closed.
2021-05-27 13:37:10.286886 (MainThread): Connection 'list_oef-stage_TestRecoursePlanner' was properly closed.
2021-05-27 13:37:10.289765 (MainThread): 
2021-05-27 13:37:10.289899 (MainThread): Completed with 1 error and 0 warnings:
2021-05-27 13:37:10.289994 (MainThread): 
2021-05-27 13:37:10.290074 (MainThread): Database Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
2021-05-27 13:37:10.290159 (MainThread):   Name Employee not found inside E at [30:19]
2021-05-27 13:37:10.290391 (MainThread):   compiled SQL at target/run/resourceplanner/models/example/my_first_dbt_model.sql
2021-05-27 13:37:10.290583 (MainThread): 
Done. PASS=0 WARN=0 ERROR=1 SKIP=1 TOTAL=2
2021-05-27 13:37:10.290766 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fda64a96f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fda623f87c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fda62305e80>]}
2021-05-27 13:37:10.290912 (MainThread): Flushing usage events
2021-05-27 13:37:45.391786 (MainThread): Running with dbt=0.19.1
2021-05-27 13:37:45.592604 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/home/femke/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-05-27 13:37:45.593241 (MainThread): Tracking: tracking
2021-05-27 13:37:45.604032 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe806d81f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe8086362e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe8086365e0>]}
2021-05-27 13:37:45.624184 (MainThread): Partial parsing not enabled
2021-05-27 13:37:45.624892 (MainThread): Parsing macros/catalog.sql
2021-05-27 13:37:45.638436 (MainThread): Parsing macros/adapters.sql
2021-05-27 13:37:45.655975 (MainThread): Parsing macros/etc.sql
2021-05-27 13:37:45.657464 (MainThread): Parsing macros/materializations/snapshot.sql
2021-05-27 13:37:45.658811 (MainThread): Parsing macros/materializations/copy.sql
2021-05-27 13:37:45.662839 (MainThread): Parsing macros/materializations/table.sql
2021-05-27 13:37:45.670305 (MainThread): Parsing macros/materializations/incremental.sql
2021-05-27 13:37:45.678976 (MainThread): Parsing macros/materializations/view.sql
2021-05-27 13:37:45.680940 (MainThread): Parsing macros/materializations/seed.sql
2021-05-27 13:37:45.683212 (MainThread): Parsing macros/core.sql
2021-05-27 13:37:45.685839 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-05-27 13:37:45.686822 (MainThread): Parsing macros/schema_tests/unique.sql
2021-05-27 13:37:45.687939 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-05-27 13:37:45.689160 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-05-27 13:37:45.691034 (MainThread): Parsing macros/materializations/helpers.sql
2021-05-27 13:37:45.697107 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-05-27 13:37:45.698421 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-05-27 13:37:45.702883 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-05-27 13:37:45.716962 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-05-27 13:37:45.737751 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-05-27 13:37:45.738970 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-05-27 13:37:45.752704 (MainThread): Parsing macros/materializations/table/table.sql
2021-05-27 13:37:45.757829 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-05-27 13:37:45.775059 (MainThread): Parsing macros/materializations/view/view.sql
2021-05-27 13:37:45.779783 (MainThread): Parsing macros/materializations/common/merge.sql
2021-05-27 13:37:45.789152 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-05-27 13:37:45.790393 (MainThread): Parsing macros/etc/query.sql
2021-05-27 13:37:45.791109 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-05-27 13:37:45.791756 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-05-27 13:37:45.793293 (MainThread): Parsing macros/etc/datetime.sql
2021-05-27 13:37:45.799653 (MainThread): Parsing macros/etc/is_incremental.sql
2021-05-27 13:37:45.800911 (MainThread): Parsing macros/adapters/common.sql
2021-05-27 13:37:45.832953 (MainThread): Partial parsing not enabled
2021-05-27 13:37:45.849297 (MainThread): Acquiring new bigquery connection "model.resourceplanner.my_second_dbt_model".
2021-05-27 13:37:45.856306 (MainThread): Acquiring new bigquery connection "model.resourceplanner.my_first_dbt_model".
2021-05-27 13:37:45.902819 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '6521b0f6-a840-4bc7-9107-0e2bcf7a751b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe805d7d610>]}
2021-05-27 13:37:45.906368 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '6521b0f6-a840-4bc7-9107-0e2bcf7a751b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe805e5d5b0>]}
2021-05-27 13:37:45.906599 (MainThread): Found 2 models, 4 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-05-27 13:37:45.907219 (MainThread): 
2021-05-27 13:37:45.907487 (MainThread): Acquiring new bigquery connection "master".
2021-05-27 13:37:45.908068 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_oef-stage".
2021-05-27 13:37:45.908188 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-05-27 13:37:46.203645 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_oef-stage_TestRecoursePlanner".
2021-05-27 13:37:46.203807 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2021-05-27 13:37:46.206916 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-05-27 13:37:46.378854 (MainThread): 15:37:46 | Concurrency: 5 threads (target='dev')
2021-05-27 13:37:46.379086 (MainThread): 15:37:46 | 
2021-05-27 13:37:46.380767 (Thread-1): Began running node model.resourceplanner.my_first_dbt_model
2021-05-27 13:37:46.380920 (Thread-1): 15:37:46 | 1 of 2 START table model TestRecoursePlanner.my_first_dbt_model...... [RUN]
2021-05-27 13:37:46.381112 (Thread-1): Acquiring new bigquery connection "model.resourceplanner.my_first_dbt_model".
2021-05-27 13:37:46.381185 (Thread-1): Compiling model.resourceplanner.my_first_dbt_model
2021-05-27 13:37:46.382846 (Thread-1): Writing injected SQL for node "model.resourceplanner.my_first_dbt_model"
2021-05-27 13:37:46.383054 (Thread-1): finished collecting timing info
2021-05-27 13:37:46.400219 (Thread-1): Opening a new connection, currently in state closed
2021-05-27 13:37:46.403821 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-05-27 13:37:46.616473 (Thread-1): Writing runtime SQL for node "model.resourceplanner.my_first_dbt_model"
2021-05-27 13:37:46.616950 (Thread-1): On model.resourceplanner.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "Bigquery", "target_name": "dev", "node_id": "model.resourceplanner.my_first_dbt_model"} */


  create or replace table `oef-stage`.`TestRecoursePlanner`.`my_first_dbt_model`
  
  
  OPTIONS()
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select M.ID, E.EmployeeID, CU.CustomerID,CO.CompanyID
from oef-stage.TestRecoursePlanner.MainData M
FULL JOIN oef-stage.TestRecoursePlanner.Employee E
ON M.Employee = E.Firstname
FULL JOIN oef-stage.TestRecoursePlanner.Customer CU
ON M.Customer = CU.Customername
FULL JOIN oef-stage.TestRecoursePlanner.Company CO
ON M.Company = CO.Companyname

/*
    Uncomment the line below to remove records with null `id` values
*/
  );
    
2021-05-27 13:37:50.407374 (Thread-1): finished collecting timing info
2021-05-27 13:37:50.407699 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6521b0f6-a840-4bc7-9107-0e2bcf7a751b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe805e67a60>]}
2021-05-27 13:37:50.407894 (Thread-1): 15:37:50 | 1 of 2 OK created table model TestRecoursePlanner.my_first_dbt_model. [CREATE TABLE (18.0 rows, 5.2 KB processed) in 4.03s]
2021-05-27 13:37:50.408068 (Thread-1): Finished running node model.resourceplanner.my_first_dbt_model
2021-05-27 13:37:50.408472 (Thread-3): Began running node model.resourceplanner.my_second_dbt_model
2021-05-27 13:37:50.408611 (Thread-3): 15:37:50 | 2 of 2 START view model TestRecoursePlanner.my_second_dbt_model...... [RUN]
2021-05-27 13:37:50.408809 (Thread-3): Acquiring new bigquery connection "model.resourceplanner.my_second_dbt_model".
2021-05-27 13:37:50.408871 (Thread-3): Compiling model.resourceplanner.my_second_dbt_model
2021-05-27 13:37:50.410696 (Thread-3): Writing injected SQL for node "model.resourceplanner.my_second_dbt_model"
2021-05-27 13:37:50.411021 (Thread-3): finished collecting timing info
2021-05-27 13:37:50.446644 (Thread-3): unclosed <socket.socket fd=5, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.0.2.15', 60110), raddr=('216.58.211.106', 443)>
2021-05-27 13:37:50.446921 (Thread-3): unclosed <socket.socket fd=6, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.0.2.15', 50272), raddr=('172.217.168.234', 443)>
2021-05-27 13:37:50.452736 (Thread-3): Writing runtime SQL for node "model.resourceplanner.my_second_dbt_model"
2021-05-27 13:37:50.453166 (Thread-3): Opening a new connection, currently in state init
2021-05-27 13:37:50.458647 (Thread-3): On model.resourceplanner.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "Bigquery", "target_name": "dev", "node_id": "model.resourceplanner.my_second_dbt_model"} */


  create or replace view `oef-stage`.`TestRecoursePlanner`.`my_second_dbt_model`
  OPTIONS()
  as -- Use the `ref` function to select from other models

select *
from `oef-stage`.`TestRecoursePlanner`.`my_first_dbt_model`;


2021-05-27 13:37:51.093952 (Thread-3): finished collecting timing info
2021-05-27 13:37:51.094498 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6521b0f6-a840-4bc7-9107-0e2bcf7a751b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe805e15f10>]}
2021-05-27 13:37:51.094713 (Thread-3): 15:37:51 | 2 of 2 OK created view model TestRecoursePlanner.my_second_dbt_model. [OK in 0.69s]
2021-05-27 13:37:51.094888 (Thread-3): Finished running node model.resourceplanner.my_second_dbt_model
2021-05-27 13:37:51.095921 (MainThread): Acquiring new bigquery connection "master".
2021-05-27 13:37:51.096081 (MainThread): 15:37:51 | 
2021-05-27 13:37:51.096203 (MainThread): 15:37:51 | Finished running 1 table model, 1 view model in 5.19s.
2021-05-27 13:37:51.096296 (MainThread): Connection 'master' was properly closed.
2021-05-27 13:37:51.096335 (MainThread): Connection 'model.resourceplanner.my_first_dbt_model' was properly closed.
2021-05-27 13:37:51.096365 (MainThread): Connection 'list_oef-stage_TestRecoursePlanner' was properly closed.
2021-05-27 13:37:51.096394 (MainThread): Connection 'model.resourceplanner.my_second_dbt_model' was properly closed.
2021-05-27 13:37:51.098977 (MainThread): 
2021-05-27 13:37:51.099082 (MainThread): Completed successfully
2021-05-27 13:37:51.099201 (MainThread): 
Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
2021-05-27 13:37:51.099348 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe805dcd490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe805e4bc10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe805d67e50>]}
2021-05-27 13:37:51.099457 (MainThread): Flushing usage events
2021-05-27 13:38:38.414858 (MainThread): Running with dbt=0.19.1
2021-05-27 13:38:38.687453 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/home/femke/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-05-27 13:38:38.688146 (MainThread): Tracking: tracking
2021-05-27 13:38:38.702081 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe605c5aa90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe60758d160>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe60758d5b0>]}
2021-05-27 13:38:38.722582 (MainThread): Partial parsing not enabled
2021-05-27 13:38:38.723320 (MainThread): Parsing macros/catalog.sql
2021-05-27 13:38:38.736710 (MainThread): Parsing macros/adapters.sql
2021-05-27 13:38:38.766028 (MainThread): Parsing macros/etc.sql
2021-05-27 13:38:38.771112 (MainThread): Parsing macros/materializations/snapshot.sql
2021-05-27 13:38:38.772372 (MainThread): Parsing macros/materializations/copy.sql
2021-05-27 13:38:38.778173 (MainThread): Parsing macros/materializations/table.sql
2021-05-27 13:38:38.786870 (MainThread): Parsing macros/materializations/incremental.sql
2021-05-27 13:38:38.797372 (MainThread): Parsing macros/materializations/view.sql
2021-05-27 13:38:38.800161 (MainThread): Parsing macros/materializations/seed.sql
2021-05-27 13:38:38.803137 (MainThread): Parsing macros/core.sql
2021-05-27 13:38:38.806669 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-05-27 13:38:38.808171 (MainThread): Parsing macros/schema_tests/unique.sql
2021-05-27 13:38:38.809784 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-05-27 13:38:38.811230 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-05-27 13:38:38.813132 (MainThread): Parsing macros/materializations/helpers.sql
2021-05-27 13:38:38.820889 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-05-27 13:38:38.822208 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-05-27 13:38:38.827066 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-05-27 13:38:38.842727 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-05-27 13:38:38.864677 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-05-27 13:38:38.865955 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-05-27 13:38:38.879681 (MainThread): Parsing macros/materializations/table/table.sql
2021-05-27 13:38:38.884334 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-05-27 13:38:38.887864 (MainThread): Parsing macros/materializations/view/view.sql
2021-05-27 13:38:38.892125 (MainThread): Parsing macros/materializations/common/merge.sql
2021-05-27 13:38:38.901408 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-05-27 13:38:38.902599 (MainThread): Parsing macros/etc/query.sql
2021-05-27 13:38:38.903306 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-05-27 13:38:38.903902 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-05-27 13:38:38.905271 (MainThread): Parsing macros/etc/datetime.sql
2021-05-27 13:38:38.911264 (MainThread): Parsing macros/etc/is_incremental.sql
2021-05-27 13:38:38.912407 (MainThread): Parsing macros/adapters/common.sql
2021-05-27 13:38:38.943566 (MainThread): Partial parsing not enabled
2021-05-27 13:38:38.959900 (MainThread): Acquiring new bigquery connection "model.resourceplanner.my_second_dbt_model".
2021-05-27 13:38:38.967314 (MainThread): Acquiring new bigquery connection "model.resourceplanner.my_first_dbt_model".
2021-05-27 13:38:39.012502 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'bb347a1c-db48-4dc7-b2d4-2318caf69ecb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe604cd5670>]}
2021-05-27 13:38:39.015543 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'bb347a1c-db48-4dc7-b2d4-2318caf69ecb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe604db2610>]}
2021-05-27 13:38:39.015715 (MainThread): Found 2 models, 4 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-05-27 13:38:39.016363 (MainThread): 
2021-05-27 13:38:39.016599 (MainThread): Acquiring new bigquery connection "master".
2021-05-27 13:38:39.017206 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_oef-stage".
2021-05-27 13:38:39.017333 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-05-27 13:38:39.343597 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_oef-stage_TestRecoursePlanner".
2021-05-27 13:38:39.343759 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2021-05-27 13:38:39.346916 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-05-27 13:38:39.524041 (MainThread): 15:38:39 | Concurrency: 5 threads (target='dev')
2021-05-27 13:38:39.524283 (MainThread): 15:38:39 | 
2021-05-27 13:38:39.526010 (Thread-1): Began running node model.resourceplanner.my_first_dbt_model
2021-05-27 13:38:39.526171 (Thread-1): 15:38:39 | 1 of 2 START table model TestRecoursePlanner.my_first_dbt_model...... [RUN]
2021-05-27 13:38:39.526372 (Thread-1): Acquiring new bigquery connection "model.resourceplanner.my_first_dbt_model".
2021-05-27 13:38:39.526449 (Thread-1): Compiling model.resourceplanner.my_first_dbt_model
2021-05-27 13:38:39.528145 (Thread-1): Writing injected SQL for node "model.resourceplanner.my_first_dbt_model"
2021-05-27 13:38:39.528418 (Thread-1): finished collecting timing info
2021-05-27 13:38:39.544604 (Thread-1): Opening a new connection, currently in state closed
2021-05-27 13:38:39.548250 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-05-27 13:38:39.755963 (Thread-1): Writing runtime SQL for node "model.resourceplanner.my_first_dbt_model"
2021-05-27 13:38:39.756458 (Thread-1): On model.resourceplanner.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "Bigquery", "target_name": "dev", "node_id": "model.resourceplanner.my_first_dbt_model"} */


  create or replace table `oef-stage`.`TestRecoursePlanner`.`my_first_dbt_model`
  
  
  OPTIONS()
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select M.ID, E.EmployeeID, CU.CustomerID,CO.CompanyID
from oef-stage.TestRecoursePlanner.MainData M
INNER JOIN oef-stage.TestRecoursePlanner.Employee E
ON M.Employee = E.Firstname
INNER JOIN oef-stage.TestRecoursePlanner.Customer CU
ON M.Customer = CU.Customername
INNER JOIN oef-stage.TestRecoursePlanner.Company CO
ON M.Company = CO.Companyname

/*
    Uncomment the line below to remove records with null `id` values
*/
  );
    
2021-05-27 13:38:44.161476 (Thread-1): finished collecting timing info
2021-05-27 13:38:44.161874 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bb347a1c-db48-4dc7-b2d4-2318caf69ecb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe604d1f2e0>]}
2021-05-27 13:38:44.162090 (Thread-1): 15:38:44 | 1 of 2 OK created table model TestRecoursePlanner.my_first_dbt_model. [CREATE TABLE (13.0 rows, 5.2 KB processed) in 4.64s]
2021-05-27 13:38:44.162266 (Thread-1): Finished running node model.resourceplanner.my_first_dbt_model
2021-05-27 13:38:44.162637 (Thread-3): Began running node model.resourceplanner.my_second_dbt_model
2021-05-27 13:38:44.162982 (Thread-3): 15:38:44 | 2 of 2 START view model TestRecoursePlanner.my_second_dbt_model...... [RUN]
2021-05-27 13:38:44.163489 (Thread-3): Acquiring new bigquery connection "model.resourceplanner.my_second_dbt_model".
2021-05-27 13:38:44.163577 (Thread-3): Compiling model.resourceplanner.my_second_dbt_model
2021-05-27 13:38:44.182798 (Thread-3): Writing injected SQL for node "model.resourceplanner.my_second_dbt_model"
2021-05-27 13:38:44.183174 (Thread-3): finished collecting timing info
2021-05-27 13:38:44.211912 (Thread-3): unclosed <socket.socket fd=5, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.0.2.15', 60128), raddr=('216.58.211.106', 443)>
2021-05-27 13:38:44.212185 (Thread-3): unclosed <socket.socket fd=6, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.0.2.15', 50290), raddr=('172.217.168.234', 443)>
2021-05-27 13:38:44.217712 (Thread-3): Writing runtime SQL for node "model.resourceplanner.my_second_dbt_model"
2021-05-27 13:38:44.218102 (Thread-3): Opening a new connection, currently in state init
2021-05-27 13:38:44.221323 (Thread-3): On model.resourceplanner.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "Bigquery", "target_name": "dev", "node_id": "model.resourceplanner.my_second_dbt_model"} */


  create or replace view `oef-stage`.`TestRecoursePlanner`.`my_second_dbt_model`
  OPTIONS()
  as -- Use the `ref` function to select from other models

select *
from `oef-stage`.`TestRecoursePlanner`.`my_first_dbt_model`;


2021-05-27 13:38:44.876958 (Thread-3): finished collecting timing info
2021-05-27 13:38:44.877493 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bb347a1c-db48-4dc7-b2d4-2318caf69ecb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe604dbe820>]}
2021-05-27 13:38:44.877849 (Thread-3): 15:38:44 | 2 of 2 OK created view model TestRecoursePlanner.my_second_dbt_model. [OK in 0.71s]
2021-05-27 13:38:44.878052 (Thread-3): Finished running node model.resourceplanner.my_second_dbt_model
2021-05-27 13:38:44.878967 (MainThread): Acquiring new bigquery connection "master".
2021-05-27 13:38:44.879164 (MainThread): 15:38:44 | 
2021-05-27 13:38:44.879271 (MainThread): 15:38:44 | Finished running 1 table model, 1 view model in 5.86s.
2021-05-27 13:38:44.879359 (MainThread): Connection 'master' was properly closed.
2021-05-27 13:38:44.879400 (MainThread): Connection 'model.resourceplanner.my_first_dbt_model' was properly closed.
2021-05-27 13:38:44.879432 (MainThread): Connection 'list_oef-stage_TestRecoursePlanner' was properly closed.
2021-05-27 13:38:44.879463 (MainThread): Connection 'model.resourceplanner.my_second_dbt_model' was properly closed.
2021-05-27 13:38:44.882696 (MainThread): 
2021-05-27 13:38:44.882886 (MainThread): Completed successfully
2021-05-27 13:38:44.882985 (MainThread): 
Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
2021-05-27 13:38:44.883169 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe604cbfdf0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe604e7ccd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe604db2520>]}
2021-05-27 13:38:44.883292 (MainThread): Flushing usage events
2021-05-27 13:39:40.485991 (MainThread): Running with dbt=0.19.1
2021-05-27 13:39:40.667169 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/home/femke/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-05-27 13:39:40.667760 (MainThread): Tracking: tracking
2021-05-27 13:39:40.677966 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f50866569d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5087f4b0d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5087f4b4c0>]}
2021-05-27 13:39:40.692837 (MainThread): Partial parsing not enabled
2021-05-27 13:39:40.693528 (MainThread): Parsing macros/catalog.sql
2021-05-27 13:39:40.706140 (MainThread): Parsing macros/adapters.sql
2021-05-27 13:39:40.724352 (MainThread): Parsing macros/etc.sql
2021-05-27 13:39:40.726317 (MainThread): Parsing macros/materializations/snapshot.sql
2021-05-27 13:39:40.727761 (MainThread): Parsing macros/materializations/copy.sql
2021-05-27 13:39:40.731142 (MainThread): Parsing macros/materializations/table.sql
2021-05-27 13:39:40.738550 (MainThread): Parsing macros/materializations/incremental.sql
2021-05-27 13:39:40.747302 (MainThread): Parsing macros/materializations/view.sql
2021-05-27 13:39:40.749247 (MainThread): Parsing macros/materializations/seed.sql
2021-05-27 13:39:40.751664 (MainThread): Parsing macros/core.sql
2021-05-27 13:39:40.754310 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-05-27 13:39:40.755296 (MainThread): Parsing macros/schema_tests/unique.sql
2021-05-27 13:39:40.756388 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-05-27 13:39:40.757650 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-05-27 13:39:40.759403 (MainThread): Parsing macros/materializations/helpers.sql
2021-05-27 13:39:40.765257 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-05-27 13:39:40.766515 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-05-27 13:39:40.770876 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-05-27 13:39:40.784726 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-05-27 13:39:40.804762 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-05-27 13:39:40.806043 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-05-27 13:39:40.818587 (MainThread): Parsing macros/materializations/table/table.sql
2021-05-27 13:39:40.823309 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-05-27 13:39:40.826713 (MainThread): Parsing macros/materializations/view/view.sql
2021-05-27 13:39:40.830920 (MainThread): Parsing macros/materializations/common/merge.sql
2021-05-27 13:39:40.839934 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-05-27 13:39:40.841040 (MainThread): Parsing macros/etc/query.sql
2021-05-27 13:39:40.841756 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-05-27 13:39:40.842391 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-05-27 13:39:40.843758 (MainThread): Parsing macros/etc/datetime.sql
2021-05-27 13:39:40.849555 (MainThread): Parsing macros/etc/is_incremental.sql
2021-05-27 13:39:40.850679 (MainThread): Parsing macros/adapters/common.sql
2021-05-27 13:39:40.881855 (MainThread): Partial parsing not enabled
2021-05-27 13:39:40.897940 (MainThread): Acquiring new bigquery connection "model.resourceplanner.my_second_dbt_model".
2021-05-27 13:39:40.904828 (MainThread): Acquiring new bigquery connection "model.resourceplanner.my_first_dbt_model".
2021-05-27 13:39:40.950192 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd5411bf6-b692-4b36-a09e-bede3c8c0e6a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f50856d3fd0>]}
2021-05-27 13:39:40.953166 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd5411bf6-b692-4b36-a09e-bede3c8c0e6a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f50857b0490>]}
2021-05-27 13:39:40.953347 (MainThread): Found 2 models, 4 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-05-27 13:39:40.953943 (MainThread): 
2021-05-27 13:39:40.954237 (MainThread): Acquiring new bigquery connection "master".
2021-05-27 13:39:40.954799 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_oef-stage".
2021-05-27 13:39:40.954927 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-05-27 13:39:41.289369 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_oef-stage_TestRecoursePlanner".
2021-05-27 13:39:41.289529 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2021-05-27 13:39:41.292893 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-05-27 13:39:41.457226 (MainThread): 15:39:41 | Concurrency: 5 threads (target='dev')
2021-05-27 13:39:41.457753 (MainThread): 15:39:41 | 
2021-05-27 13:39:41.459523 (Thread-1): Began running node model.resourceplanner.my_first_dbt_model
2021-05-27 13:39:41.459689 (Thread-1): 15:39:41 | 1 of 2 START table model TestRecoursePlanner.my_first_dbt_model...... [RUN]
2021-05-27 13:39:41.459904 (Thread-1): Acquiring new bigquery connection "model.resourceplanner.my_first_dbt_model".
2021-05-27 13:39:41.460005 (Thread-1): Compiling model.resourceplanner.my_first_dbt_model
2021-05-27 13:39:41.462111 (Thread-1): Writing injected SQL for node "model.resourceplanner.my_first_dbt_model"
2021-05-27 13:39:41.462434 (Thread-1): finished collecting timing info
2021-05-27 13:39:41.478478 (Thread-1): Opening a new connection, currently in state closed
2021-05-27 13:39:41.481838 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-05-27 13:39:41.686624 (Thread-1): Writing runtime SQL for node "model.resourceplanner.my_first_dbt_model"
2021-05-27 13:39:41.687064 (Thread-1): On model.resourceplanner.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "Bigquery", "target_name": "dev", "node_id": "model.resourceplanner.my_first_dbt_model"} */


  create or replace table `oef-stage`.`TestRecoursePlanner`.`my_first_dbt_model`
  
  
  OPTIONS()
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select M.ID, E.EmployeeID, CU.CustomerID,CO.CompanyID
from oef-stage.TestRecoursePlanner.MainData M
INNER JOIN oef-stage.TestRecoursePlanner.Employee E
ON M.Employee = E.Firstname
INNER JOIN oef-stage.TestRecoursePlanner.Customer CU
ON M.Customer = CU.Customername
INNER JOIN oef-stage.TestRecoursePlanner.Company CO
ON M.Company = CO.Companyname
ORDER BY M.ID

/*
    Uncomment the line below to remove records with null `id` values
*/
  );
    
2021-05-27 13:39:46.177777 (Thread-1): finished collecting timing info
2021-05-27 13:39:46.178109 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd5411bf6-b692-4b36-a09e-bede3c8c0e6a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f50857c4af0>]}
2021-05-27 13:39:46.178320 (Thread-1): 15:39:46 | 1 of 2 OK created table model TestRecoursePlanner.my_first_dbt_model. [CREATE TABLE (13.0 rows, 5.2 KB processed) in 4.72s]
2021-05-27 13:39:46.178684 (Thread-1): Finished running node model.resourceplanner.my_first_dbt_model
2021-05-27 13:39:46.179118 (Thread-3): Began running node model.resourceplanner.my_second_dbt_model
2021-05-27 13:39:46.179273 (Thread-3): 15:39:46 | 2 of 2 START view model TestRecoursePlanner.my_second_dbt_model...... [RUN]
2021-05-27 13:39:46.179550 (Thread-3): Acquiring new bigquery connection "model.resourceplanner.my_second_dbt_model".
2021-05-27 13:39:46.179618 (Thread-3): Compiling model.resourceplanner.my_second_dbt_model
2021-05-27 13:39:46.181111 (Thread-3): Writing injected SQL for node "model.resourceplanner.my_second_dbt_model"
2021-05-27 13:39:46.181514 (Thread-3): finished collecting timing info
2021-05-27 13:39:46.189359 (Thread-3): unclosed <socket.socket fd=8, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.0.2.15', 50314), raddr=('172.217.168.234', 443)>
2021-05-27 13:39:46.190724 (Thread-3): unclosed <socket.socket fd=7, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.0.2.15', 50312), raddr=('172.217.168.234', 443)>
2021-05-27 13:39:46.196658 (Thread-3): Writing runtime SQL for node "model.resourceplanner.my_second_dbt_model"
2021-05-27 13:39:46.197073 (Thread-3): Opening a new connection, currently in state init
2021-05-27 13:39:46.200200 (Thread-3): On model.resourceplanner.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "Bigquery", "target_name": "dev", "node_id": "model.resourceplanner.my_second_dbt_model"} */


  create or replace view `oef-stage`.`TestRecoursePlanner`.`my_second_dbt_model`
  OPTIONS()
  as -- Use the `ref` function to select from other models

select *
from `oef-stage`.`TestRecoursePlanner`.`my_first_dbt_model`;


2021-05-27 13:39:46.817566 (Thread-3): finished collecting timing info
2021-05-27 13:39:46.818406 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd5411bf6-b692-4b36-a09e-bede3c8c0e6a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f50857ddf70>]}
2021-05-27 13:39:46.818860 (Thread-3): 15:39:46 | 2 of 2 OK created view model TestRecoursePlanner.my_second_dbt_model. [OK in 0.64s]
2021-05-27 13:39:46.819099 (Thread-3): Finished running node model.resourceplanner.my_second_dbt_model
2021-05-27 13:39:46.819983 (MainThread): Acquiring new bigquery connection "master".
2021-05-27 13:39:46.820142 (MainThread): 15:39:46 | 
2021-05-27 13:39:46.820242 (MainThread): 15:39:46 | Finished running 1 table model, 1 view model in 5.87s.
2021-05-27 13:39:46.820328 (MainThread): Connection 'master' was properly closed.
2021-05-27 13:39:46.820367 (MainThread): Connection 'list_oef-stage' was properly closed.
2021-05-27 13:39:46.820397 (MainThread): Connection 'model.resourceplanner.my_first_dbt_model' was properly closed.
2021-05-27 13:39:46.820427 (MainThread): Connection 'model.resourceplanner.my_second_dbt_model' was properly closed.
2021-05-27 13:39:46.823143 (MainThread): 
2021-05-27 13:39:46.823252 (MainThread): Completed successfully
2021-05-27 13:39:46.823348 (MainThread): 
Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
2021-05-27 13:39:46.823550 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f50858dea90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5085722340>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5085701f40>]}
2021-05-27 13:39:46.823672 (MainThread): Flushing usage events
2021-05-28 11:55:00.159114 (MainThread): Running with dbt=0.19.1
2021-05-28 11:55:00.346634 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/home/femke/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-05-28 11:55:00.347243 (MainThread): Tracking: tracking
2021-05-28 11:55:00.364420 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f987f3b99d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9880cee040>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9880cee4c0>]}
2021-05-28 11:55:00.375350 (MainThread): Partial parsing not enabled
2021-05-28 11:55:00.376046 (MainThread): Parsing macros/catalog.sql
2021-05-28 11:55:00.391305 (MainThread): Parsing macros/adapters.sql
2021-05-28 11:55:00.410247 (MainThread): Parsing macros/etc.sql
2021-05-28 11:55:00.411855 (MainThread): Parsing macros/materializations/snapshot.sql
2021-05-28 11:55:00.413251 (MainThread): Parsing macros/materializations/copy.sql
2021-05-28 11:55:00.416521 (MainThread): Parsing macros/materializations/table.sql
2021-05-28 11:55:00.423546 (MainThread): Parsing macros/materializations/incremental.sql
2021-05-28 11:55:00.432508 (MainThread): Parsing macros/materializations/view.sql
2021-05-28 11:55:00.434462 (MainThread): Parsing macros/materializations/seed.sql
2021-05-28 11:55:00.437257 (MainThread): Parsing macros/core.sql
2021-05-28 11:55:00.440436 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-05-28 11:55:00.441455 (MainThread): Parsing macros/schema_tests/unique.sql
2021-05-28 11:55:00.442585 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-05-28 11:55:00.443884 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-05-28 11:55:00.445676 (MainThread): Parsing macros/materializations/helpers.sql
2021-05-28 11:55:00.451865 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-05-28 11:55:00.453262 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-05-28 11:55:00.457647 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-05-28 11:55:00.473462 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-05-28 11:55:00.494560 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-05-28 11:55:00.495951 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-05-28 11:55:00.508695 (MainThread): Parsing macros/materializations/table/table.sql
2021-05-28 11:55:00.513550 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-05-28 11:55:00.516965 (MainThread): Parsing macros/materializations/view/view.sql
2021-05-28 11:55:00.521702 (MainThread): Parsing macros/materializations/common/merge.sql
2021-05-28 11:55:00.531479 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-05-28 11:55:00.532689 (MainThread): Parsing macros/etc/query.sql
2021-05-28 11:55:00.533401 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-05-28 11:55:00.534165 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-05-28 11:55:00.535918 (MainThread): Parsing macros/etc/datetime.sql
2021-05-28 11:55:00.542105 (MainThread): Parsing macros/etc/is_incremental.sql
2021-05-28 11:55:00.543245 (MainThread): Parsing macros/adapters/common.sql
2021-05-28 11:55:00.578162 (MainThread): Partial parsing not enabled
2021-05-28 11:55:00.596748 (MainThread): Acquiring new bigquery connection "model.resourceplanner.trydates".
2021-05-28 11:55:00.604426 (MainThread): Acquiring new bigquery connection "model.resourceplanner.my_second_dbt_model".
2021-05-28 11:55:00.607452 (MainThread): Acquiring new bigquery connection "model.resourceplanner.my_first_dbt_model".
2021-05-28 11:55:00.658985 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '38bb1adc-807b-4037-bae4-f6f5d2dc7711', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f987e42ab80>]}
2021-05-28 11:55:00.662946 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '38bb1adc-807b-4037-bae4-f6f5d2dc7711', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f987e416c10>]}
2021-05-28 11:55:00.663159 (MainThread): Found 3 models, 4 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-05-28 11:55:00.664041 (MainThread): 
2021-05-28 11:55:00.664326 (MainThread): Acquiring new bigquery connection "master".
2021-05-28 11:55:00.665267 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_oef-stage".
2021-05-28 11:55:00.665420 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-05-28 11:55:01.057241 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_oef-stage_TestRecoursePlanner".
2021-05-28 11:55:01.057405 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2021-05-28 11:55:01.060539 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-05-28 11:55:01.241273 (MainThread): 13:55:01 | Concurrency: 5 threads (target='dev')
2021-05-28 11:55:01.241509 (MainThread): 13:55:01 | 
2021-05-28 11:55:01.243213 (Thread-1): Began running node model.resourceplanner.my_first_dbt_model
2021-05-28 11:55:01.243368 (Thread-1): 13:55:01 | 1 of 3 START table model TestRecoursePlanner.my_first_dbt_model...... [RUN]
2021-05-28 11:55:01.243462 (Thread-2): Began running node model.resourceplanner.trydates
2021-05-28 11:55:01.243566 (Thread-2): 13:55:01 | 2 of 3 START table model TestRecoursePlanner.trydates................ [RUN]
2021-05-28 11:55:01.243825 (Thread-1): Acquiring new bigquery connection "model.resourceplanner.my_first_dbt_model".
2021-05-28 11:55:01.243897 (Thread-1): Compiling model.resourceplanner.my_first_dbt_model
2021-05-28 11:55:01.245900 (Thread-1): Writing injected SQL for node "model.resourceplanner.my_first_dbt_model"
2021-05-28 11:55:01.246373 (Thread-1): finished collecting timing info
2021-05-28 11:55:01.246683 (Thread-2): Acquiring new bigquery connection "model.resourceplanner.trydates".
2021-05-28 11:55:01.253269 (Thread-2): Compiling model.resourceplanner.trydates
2021-05-28 11:55:01.254778 (Thread-2): Writing injected SQL for node "model.resourceplanner.trydates"
2021-05-28 11:55:01.255056 (Thread-2): finished collecting timing info
2021-05-28 11:55:01.282778 (Thread-1): Opening a new connection, currently in state closed
2021-05-28 11:55:01.300158 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-05-28 11:55:01.300954 (Thread-1): unclosed <socket.socket fd=5, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.0.2.15', 44160), raddr=('142.250.179.138', 443)>
2021-05-28 11:55:01.301123 (Thread-1): unclosed <socket.socket fd=6, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.0.2.15', 55310), raddr=('216.58.214.10', 443)>
2021-05-28 11:55:01.301285 (Thread-1): unclosed <socket.socket fd=8, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.0.2.15', 55314), raddr=('216.58.214.10', 443)>
2021-05-28 11:55:01.301448 (Thread-1): unclosed <socket.socket fd=7, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.0.2.15', 44164), raddr=('142.250.179.138', 443)>
2021-05-28 11:55:01.307545 (Thread-2): Writing runtime SQL for node "model.resourceplanner.trydates"
2021-05-28 11:55:01.307942 (Thread-2): Opening a new connection, currently in state closed
2021-05-28 11:55:01.311072 (Thread-2): On model.resourceplanner.trydates: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "Bigquery", "target_name": "dev", "node_id": "model.resourceplanner.trydates"} */


  create or replace table `oef-stage`.`TestRecoursePlanner`.`trydates`
  
  
  OPTIONS()
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select M.ID, E.EmployeeID, CU.CustomerID,CO.CompanyID
from oef-stage.TestRecoursePlanner.MainData M
INNER JOIN oef-stage.TestRecoursePlanner.Employee E
ON M.Employee = E.Firstname
INNER JOIN oef-stage.TestRecoursePlanner.Customer CU
ON M.Customer = CU.Customername
INNER JOIN oef-stage.TestRecoursePlanner.Company CO
ON M.Company = CO.Companyname
ORDER BY M.ID

/*
    Uncomment the line below to remove records with null `id` values
*/
  );
    
2021-05-28 11:55:01.489658 (Thread-1): Writing runtime SQL for node "model.resourceplanner.my_first_dbt_model"
2021-05-28 11:55:01.490103 (Thread-1): On model.resourceplanner.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "Bigquery", "target_name": "dev", "node_id": "model.resourceplanner.my_first_dbt_model"} */


  create or replace table `oef-stage`.`TestRecoursePlanner`.`my_first_dbt_model`
  
  
  OPTIONS()
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select M.ID, E.EmployeeID, CU.CustomerID,CO.CompanyID
from oef-stage.TestRecoursePlanner.MainData M
INNER JOIN oef-stage.TestRecoursePlanner.Employee E
ON M.Employee = E.Firstname
INNER JOIN oef-stage.TestRecoursePlanner.Customer CU
ON M.Customer = CU.Customername
INNER JOIN oef-stage.TestRecoursePlanner.Company CO
ON M.Company = CO.Companyname
ORDER BY M.ID

/*
    Uncomment the line below to remove records with null `id` values
*/
  );
    
2021-05-28 11:55:06.569064 (Thread-2): finished collecting timing info
2021-05-28 11:55:06.569380 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '38bb1adc-807b-4037-bae4-f6f5d2dc7711', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f987e485370>]}
2021-05-28 11:55:06.569653 (Thread-2): 13:55:06 | 2 of 3 OK created table model TestRecoursePlanner.trydates........... [CREATE TABLE (14.0 rows, 5.4 KB processed) in 5.32s]
2021-05-28 11:55:06.569828 (Thread-2): Finished running node model.resourceplanner.trydates
2021-05-28 11:56:40.059570 (Thread-1): finished collecting timing info
2021-05-28 11:56:40.059890 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '38bb1adc-807b-4037-bae4-f6f5d2dc7711', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f987e4ea6a0>]}
2021-05-28 11:56:40.060409 (Thread-1): 13:56:40 | 1 of 3 OK created table model TestRecoursePlanner.my_first_dbt_model. [CREATE TABLE (14.0 rows, 5.4 KB processed) in 98.82s]
2021-05-28 11:56:40.060702 (Thread-1): Finished running node model.resourceplanner.my_first_dbt_model
2021-05-28 11:56:40.061183 (Thread-4): Began running node model.resourceplanner.my_second_dbt_model
2021-05-28 11:56:40.061309 (Thread-4): 13:56:40 | 3 of 3 START view model TestRecoursePlanner.my_second_dbt_model...... [RUN]
2021-05-28 11:56:40.061559 (Thread-4): Acquiring new bigquery connection "model.resourceplanner.my_second_dbt_model".
2021-05-28 11:56:40.061627 (Thread-4): Compiling model.resourceplanner.my_second_dbt_model
2021-05-28 11:56:40.063455 (Thread-4): Writing injected SQL for node "model.resourceplanner.my_second_dbt_model"
2021-05-28 11:56:40.063709 (Thread-4): finished collecting timing info
2021-05-28 11:56:40.078526 (Thread-4): Writing runtime SQL for node "model.resourceplanner.my_second_dbt_model"
2021-05-28 11:56:40.078943 (Thread-4): Opening a new connection, currently in state init
2021-05-28 11:56:40.082114 (Thread-4): On model.resourceplanner.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "Bigquery", "target_name": "dev", "node_id": "model.resourceplanner.my_second_dbt_model"} */


  create or replace view `oef-stage`.`TestRecoursePlanner`.`my_second_dbt_model`
  OPTIONS()
  as -- Use the `ref` function to select from other models

select *
from `oef-stage`.`TestRecoursePlanner`.`my_first_dbt_model`;


2021-05-28 11:56:41.414469 (Thread-4): finished collecting timing info
2021-05-28 11:56:41.414792 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '38bb1adc-807b-4037-bae4-f6f5d2dc7711', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f987c3c63d0>]}
2021-05-28 11:56:41.415012 (Thread-4): 13:56:41 | 3 of 3 OK created view model TestRecoursePlanner.my_second_dbt_model. [OK in 1.35s]
2021-05-28 11:56:41.415197 (Thread-4): Finished running node model.resourceplanner.my_second_dbt_model
2021-05-28 11:56:41.416083 (MainThread): Acquiring new bigquery connection "master".
2021-05-28 11:56:41.416252 (MainThread): 13:56:41 | 
2021-05-28 11:56:41.416357 (MainThread): 13:56:41 | Finished running 2 table models, 1 view model in 100.75s.
2021-05-28 11:56:41.416445 (MainThread): Connection 'master' was properly closed.
2021-05-28 11:56:41.416485 (MainThread): Connection 'model.resourceplanner.my_first_dbt_model' was properly closed.
2021-05-28 11:56:41.416517 (MainThread): Connection 'model.resourceplanner.trydates' was properly closed.
2021-05-28 11:56:41.416572 (MainThread): Connection 'model.resourceplanner.my_second_dbt_model' was properly closed.
2021-05-28 11:56:41.419533 (MainThread): 
2021-05-28 11:56:41.419692 (MainThread): Completed successfully
2021-05-28 11:56:41.419790 (MainThread): 
Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
2021-05-28 11:56:41.419947 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9880c75a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f987e5dd250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f987e4205b0>]}
2021-05-28 11:56:41.420071 (MainThread): Flushing usage events
2021-05-28 12:18:10.942138 (MainThread): Running with dbt=0.19.1
2021-05-28 12:18:11.143713 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/home/femke/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-05-28 12:18:11.144470 (MainThread): Tracking: tracking
2021-05-28 12:18:11.155364 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f392a001df0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f392b936100>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f392b9364c0>]}
2021-05-28 12:18:11.171492 (MainThread): Partial parsing not enabled
2021-05-28 12:18:11.176383 (MainThread): Parsing macros/catalog.sql
2021-05-28 12:18:11.184515 (MainThread): Parsing macros/adapters.sql
2021-05-28 12:18:11.207365 (MainThread): Parsing macros/etc.sql
2021-05-28 12:18:11.208910 (MainThread): Parsing macros/materializations/snapshot.sql
2021-05-28 12:18:11.210248 (MainThread): Parsing macros/materializations/copy.sql
2021-05-28 12:18:11.213587 (MainThread): Parsing macros/materializations/table.sql
2021-05-28 12:18:11.221078 (MainThread): Parsing macros/materializations/incremental.sql
2021-05-28 12:18:11.230709 (MainThread): Parsing macros/materializations/view.sql
2021-05-28 12:18:11.232784 (MainThread): Parsing macros/materializations/seed.sql
2021-05-28 12:18:11.235334 (MainThread): Parsing macros/core.sql
2021-05-28 12:18:11.238113 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-05-28 12:18:11.239361 (MainThread): Parsing macros/schema_tests/unique.sql
2021-05-28 12:18:11.240622 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-05-28 12:18:11.241933 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-05-28 12:18:11.244034 (MainThread): Parsing macros/materializations/helpers.sql
2021-05-28 12:18:11.251882 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-05-28 12:18:11.253338 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-05-28 12:18:11.258240 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-05-28 12:18:11.272845 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-05-28 12:18:11.295165 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-05-28 12:18:11.296496 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-05-28 12:18:11.309728 (MainThread): Parsing macros/materializations/table/table.sql
2021-05-28 12:18:11.314686 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-05-28 12:18:11.318156 (MainThread): Parsing macros/materializations/view/view.sql
2021-05-28 12:18:11.322839 (MainThread): Parsing macros/materializations/common/merge.sql
2021-05-28 12:18:11.332802 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-05-28 12:18:11.334251 (MainThread): Parsing macros/etc/query.sql
2021-05-28 12:18:11.335024 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-05-28 12:18:11.335720 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-05-28 12:18:11.337154 (MainThread): Parsing macros/etc/datetime.sql
2021-05-28 12:18:11.343234 (MainThread): Parsing macros/etc/is_incremental.sql
2021-05-28 12:18:11.344520 (MainThread): Parsing macros/adapters/common.sql
2021-05-28 12:18:11.380098 (MainThread): Partial parsing not enabled
2021-05-28 12:18:11.397455 (MainThread): Acquiring new bigquery connection "model.resourceplanner.trydates".
2021-05-28 12:18:11.404564 (MainThread): Acquiring new bigquery connection "model.resourceplanner.my_second_dbt_model".
2021-05-28 12:18:11.407676 (MainThread): Acquiring new bigquery connection "model.resourceplanner.my_first_dbt_model".
2021-05-28 12:18:11.457419 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '09bebf2d-2d89-4630-9c10-0b070c6e885d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3929072970>]}
2021-05-28 12:18:11.460850 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '09bebf2d-2d89-4630-9c10-0b070c6e885d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f39290cd670>]}
2021-05-28 12:18:11.461007 (MainThread): Found 3 models, 4 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-05-28 12:18:11.461685 (MainThread): 
2021-05-28 12:18:11.461953 (MainThread): Acquiring new bigquery connection "master".
2021-05-28 12:18:11.462541 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_oef-stage".
2021-05-28 12:18:11.462744 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-05-28 12:18:11.853083 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_oef-stage_TestRecoursePlanner".
2021-05-28 12:18:11.853267 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2021-05-28 12:18:11.857116 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-05-28 12:18:12.052754 (MainThread): 14:18:12 | Concurrency: 5 threads (target='dev')
2021-05-28 12:18:12.053006 (MainThread): 14:18:12 | 
2021-05-28 12:18:12.054926 (Thread-1): Began running node model.resourceplanner.my_first_dbt_model
2021-05-28 12:18:12.055244 (Thread-1): 14:18:12 | 1 of 3 START table model TestRecoursePlanner.my_first_dbt_model...... [RUN]
2021-05-28 12:18:12.055408 (Thread-2): Began running node model.resourceplanner.trydates
2021-05-28 12:18:12.055520 (Thread-2): 14:18:12 | 2 of 3 START view model TestRecoursePlanner.trydates................. [RUN]
2021-05-28 12:18:12.055770 (Thread-1): Acquiring new bigquery connection "model.resourceplanner.my_first_dbt_model".
2021-05-28 12:18:12.055853 (Thread-1): Compiling model.resourceplanner.my_first_dbt_model
2021-05-28 12:18:12.057913 (Thread-1): Writing injected SQL for node "model.resourceplanner.my_first_dbt_model"
2021-05-28 12:18:12.058151 (Thread-2): Acquiring new bigquery connection "model.resourceplanner.trydates".
2021-05-28 12:18:12.058276 (Thread-2): Compiling model.resourceplanner.trydates
2021-05-28 12:18:12.058980 (Thread-2): Writing injected SQL for node "model.resourceplanner.trydates"
2021-05-28 12:18:12.059301 (Thread-2): finished collecting timing info
2021-05-28 12:18:12.071422 (Thread-1): finished collecting timing info
2021-05-28 12:18:12.097881 (Thread-2): finished collecting timing info
2021-05-28 12:18:12.100728 (Thread-2): Compilation Error in model trydates (models/Facttable/trydates.sql)
  Trying to create view `oef-stage`.`TestRecoursePlanner`.`trydates`, but it currently exists as a table. Either drop `oef-stage`.`TestRecoursePlanner`.`trydates` manually, or run dbt with `--full-refresh` and dbt will drop it for you.
  
  > in macro bigquery__handle_existing_table (macros/materializations/view.sql)
  > called by macro handle_existing_table (macros/materializations/view/create_or_replace_view.sql)
  > called by macro create_or_replace_view (macros/materializations/view/create_or_replace_view.sql)
  > called by macro materialization_view_bigquery (macros/materializations/view.sql)
  > called by model trydates (models/Facttable/trydates.sql)
Traceback (most recent call last):
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/base.py", line 287, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/base.py", line 389, in run
    return self.execute(compiled_node, manifest)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/run.py", line 248, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 22, in macro
  File "/home/femke/dbt-env/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 50, in macro
  File "/home/femke/dbt-env/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 22, in macro
  File "/home/femke/dbt-env/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 29, in macro
  File "/home/femke/dbt-env/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/exceptions.py", line 1008, in inner
    raise exc
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/exceptions.py", line 1005, in inner
    return func(*args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/exceptions.py", line 669, in relation_wrong_type
    raise_compiler_error(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/exceptions.py", line 435, in raise_compiler_error
    raise CompilationException(msg, node)
dbt.exceptions.CompilationException: Compilation Error in model trydates (models/Facttable/trydates.sql)
  Trying to create view `oef-stage`.`TestRecoursePlanner`.`trydates`, but it currently exists as a table. Either drop `oef-stage`.`TestRecoursePlanner`.`trydates` manually, or run dbt with `--full-refresh` and dbt will drop it for you.
  
  > in macro bigquery__handle_existing_table (macros/materializations/view.sql)
  > called by macro handle_existing_table (macros/materializations/view/create_or_replace_view.sql)
  > called by macro create_or_replace_view (macros/materializations/view/create_or_replace_view.sql)
  > called by macro materialization_view_bigquery (macros/materializations/view.sql)
  > called by model trydates (models/Facttable/trydates.sql)
2021-05-28 12:18:12.101564 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '09bebf2d-2d89-4630-9c10-0b070c6e885d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f39291db370>]}
2021-05-28 12:18:12.101777 (Thread-2): 14:18:12 | 2 of 3 ERROR creating view model TestRecoursePlanner.trydates........ [ERROR in 0.04s]
2021-05-28 12:18:12.100487 (Thread-1): Opening a new connection, currently in state closed
2021-05-28 12:18:12.103825 (Thread-2): Finished running node model.resourceplanner.trydates
2021-05-28 12:18:12.105476 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-05-28 12:18:12.307427 (Thread-1): unclosed <socket.socket fd=5, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.0.2.15', 58942), raddr=('142.250.179.202', 443)>
2021-05-28 12:18:12.307729 (Thread-1): unclosed <socket.socket fd=6, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.0.2.15', 60692), raddr=('216.58.211.106', 443)>
2021-05-28 12:18:12.307860 (Thread-1): unclosed <socket.socket fd=8, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.0.2.15', 60696), raddr=('216.58.211.106', 443)>
2021-05-28 12:18:12.308012 (Thread-1): unclosed <socket.socket fd=7, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.0.2.15', 58946), raddr=('142.250.179.202', 443)>
2021-05-28 12:18:12.313434 (Thread-1): Writing runtime SQL for node "model.resourceplanner.my_first_dbt_model"
2021-05-28 12:18:12.313786 (Thread-1): On model.resourceplanner.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "Bigquery", "target_name": "dev", "node_id": "model.resourceplanner.my_first_dbt_model"} */


  create or replace table `oef-stage`.`TestRecoursePlanner`.`my_first_dbt_model`
  
  
  OPTIONS()
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select M.ID, E.EmployeeID, CU.CustomerID,CO.CompanyID
from oef-stage.TestRecoursePlanner.MainData M
INNER JOIN oef-stage.TestRecoursePlanner.Employee E
ON M.Employee = E.Firstname
INNER JOIN oef-stage.TestRecoursePlanner.Customer CU
ON M.Customer = CU.Customername
INNER JOIN oef-stage.TestRecoursePlanner.Company CO
ON M.Company = CO.Companyname
ORDER BY M.ID

/*
    Uncomment the line below to remove records with null `id` values
*/
  );
    
2021-05-28 12:18:17.168857 (Thread-1): finished collecting timing info
2021-05-28 12:18:17.169199 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '09bebf2d-2d89-4630-9c10-0b070c6e885d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3929065130>]}
2021-05-28 12:18:17.169410 (Thread-1): 14:18:17 | 1 of 3 OK created table model TestRecoursePlanner.my_first_dbt_model. [CREATE TABLE (14.0 rows, 5.4 KB processed) in 5.11s]
2021-05-28 12:18:17.169593 (Thread-1): Finished running node model.resourceplanner.my_first_dbt_model
2021-05-28 12:18:17.170308 (Thread-4): Began running node model.resourceplanner.my_second_dbt_model
2021-05-28 12:18:17.170559 (Thread-4): 14:18:17 | 3 of 3 START view model TestRecoursePlanner.my_second_dbt_model...... [RUN]
2021-05-28 12:18:17.170929 (Thread-4): Acquiring new bigquery connection "model.resourceplanner.my_second_dbt_model".
2021-05-28 12:18:17.171010 (Thread-4): Compiling model.resourceplanner.my_second_dbt_model
2021-05-28 12:18:17.172948 (Thread-4): Writing injected SQL for node "model.resourceplanner.my_second_dbt_model"
2021-05-28 12:18:17.173206 (Thread-4): finished collecting timing info
2021-05-28 12:18:17.177604 (Thread-4): Writing runtime SQL for node "model.resourceplanner.my_second_dbt_model"
2021-05-28 12:18:17.178038 (Thread-4): Opening a new connection, currently in state init
2021-05-28 12:18:17.182263 (Thread-4): On model.resourceplanner.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "Bigquery", "target_name": "dev", "node_id": "model.resourceplanner.my_second_dbt_model"} */


  create or replace view `oef-stage`.`TestRecoursePlanner`.`my_second_dbt_model`
  OPTIONS()
  as -- Use the `ref` function to select from other models

select *
from `oef-stage`.`TestRecoursePlanner`.`my_first_dbt_model`;


2021-05-28 12:18:17.828589 (Thread-4): finished collecting timing info
2021-05-28 12:18:17.828938 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '09bebf2d-2d89-4630-9c10-0b070c6e885d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3929160d30>]}
2021-05-28 12:18:17.829153 (Thread-4): 14:18:17 | 3 of 3 OK created view model TestRecoursePlanner.my_second_dbt_model. [OK in 0.66s]
2021-05-28 12:18:17.829337 (Thread-4): Finished running node model.resourceplanner.my_second_dbt_model
2021-05-28 12:18:17.830242 (MainThread): Acquiring new bigquery connection "master".
2021-05-28 12:18:17.830440 (MainThread): 14:18:17 | 
2021-05-28 12:18:17.830552 (MainThread): 14:18:17 | Finished running 2 view models, 1 table model in 6.37s.
2021-05-28 12:18:17.830642 (MainThread): Connection 'master' was properly closed.
2021-05-28 12:18:17.830683 (MainThread): Connection 'model.resourceplanner.my_first_dbt_model' was properly closed.
2021-05-28 12:18:17.830725 (MainThread): Connection 'model.resourceplanner.trydates' was properly closed.
2021-05-28 12:18:17.830758 (MainThread): Connection 'model.resourceplanner.my_second_dbt_model' was properly closed.
2021-05-28 12:18:17.831368 (MainThread): unclosed <socket.socket fd=5, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.0.2.15', 58954), raddr=('142.250.179.202', 443)>
2021-05-28 12:18:17.831873 (MainThread): unclosed <socket.socket fd=6, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.0.2.15', 60704), raddr=('216.58.211.106', 443)>
2021-05-28 12:18:17.835026 (MainThread): 
2021-05-28 12:18:17.835210 (MainThread): Completed with 1 error and 0 warnings:
2021-05-28 12:18:17.835346 (MainThread): 
2021-05-28 12:18:17.835439 (MainThread): Compilation Error in model trydates (models/Facttable/trydates.sql)
2021-05-28 12:18:17.835528 (MainThread):   Trying to create view `oef-stage`.`TestRecoursePlanner`.`trydates`, but it currently exists as a table. Either drop `oef-stage`.`TestRecoursePlanner`.`trydates` manually, or run dbt with `--full-refresh` and dbt will drop it for you.
2021-05-28 12:18:17.835613 (MainThread):   
2021-05-28 12:18:17.835695 (MainThread):   > in macro bigquery__handle_existing_table (macros/materializations/view.sql)
2021-05-28 12:18:17.835784 (MainThread):   > called by macro handle_existing_table (macros/materializations/view/create_or_replace_view.sql)
2021-05-28 12:18:17.835865 (MainThread):   > called by macro create_or_replace_view (macros/materializations/view/create_or_replace_view.sql)
2021-05-28 12:18:17.835947 (MainThread):   > called by macro materialization_view_bigquery (macros/materializations/view.sql)
2021-05-28 12:18:17.836028 (MainThread):   > called by model trydates (models/Facttable/trydates.sql)
2021-05-28 12:18:17.836123 (MainThread): 
Done. PASS=2 WARN=0 ERROR=1 SKIP=0 TOTAL=3
2021-05-28 12:18:17.836371 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f39291794c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f392905f910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f392919d1c0>]}
2021-05-28 12:18:17.836525 (MainThread): Flushing usage events
2021-05-28 12:19:02.910385 (MainThread): Running with dbt=0.19.1
2021-05-28 12:19:03.112540 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/home/femke/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-05-28 12:19:03.113349 (MainThread): Tracking: tracking
2021-05-28 12:19:03.123926 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f428f89fe20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f42911d4190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f42911d44f0>]}
2021-05-28 12:19:03.144217 (MainThread): Partial parsing not enabled
2021-05-28 12:19:03.145057 (MainThread): Parsing macros/catalog.sql
2021-05-28 12:19:03.154166 (MainThread): Parsing macros/adapters.sql
2021-05-28 12:19:03.176593 (MainThread): Parsing macros/etc.sql
2021-05-28 12:19:03.178221 (MainThread): Parsing macros/materializations/snapshot.sql
2021-05-28 12:19:03.179763 (MainThread): Parsing macros/materializations/copy.sql
2021-05-28 12:19:03.183464 (MainThread): Parsing macros/materializations/table.sql
2021-05-28 12:19:03.190765 (MainThread): Parsing macros/materializations/incremental.sql
2021-05-28 12:19:03.200125 (MainThread): Parsing macros/materializations/view.sql
2021-05-28 12:19:03.202109 (MainThread): Parsing macros/materializations/seed.sql
2021-05-28 12:19:03.204502 (MainThread): Parsing macros/core.sql
2021-05-28 12:19:03.207583 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-05-28 12:19:03.208733 (MainThread): Parsing macros/schema_tests/unique.sql
2021-05-28 12:19:03.209941 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-05-28 12:19:03.211371 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-05-28 12:19:03.213371 (MainThread): Parsing macros/materializations/helpers.sql
2021-05-28 12:19:03.220197 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-05-28 12:19:03.221490 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-05-28 12:19:03.226136 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-05-28 12:19:03.241006 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-05-28 12:19:03.264417 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-05-28 12:19:03.265684 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-05-28 12:19:03.278463 (MainThread): Parsing macros/materializations/table/table.sql
2021-05-28 12:19:03.283200 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-05-28 12:19:03.287124 (MainThread): Parsing macros/materializations/view/view.sql
2021-05-28 12:19:03.291655 (MainThread): Parsing macros/materializations/common/merge.sql
2021-05-28 12:19:03.301095 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-05-28 12:19:03.302239 (MainThread): Parsing macros/etc/query.sql
2021-05-28 12:19:03.303008 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-05-28 12:19:03.303617 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-05-28 12:19:03.305117 (MainThread): Parsing macros/etc/datetime.sql
2021-05-28 12:19:03.311254 (MainThread): Parsing macros/etc/is_incremental.sql
2021-05-28 12:19:03.312472 (MainThread): Parsing macros/adapters/common.sql
2021-05-28 12:19:03.345169 (MainThread): Partial parsing not enabled
2021-05-28 12:19:03.363758 (MainThread): Acquiring new bigquery connection "model.resourceplanner.trydates".
2021-05-28 12:19:03.372439 (MainThread): Acquiring new bigquery connection "model.resourceplanner.my_second_dbt_model".
2021-05-28 12:19:03.374956 (MainThread): Acquiring new bigquery connection "model.resourceplanner.my_first_dbt_model".
2021-05-28 12:19:03.423100 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '8d7ac792-e934-4c29-b1df-431a4770f9af', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f428e96edf0>]}
2021-05-28 12:19:03.426032 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '8d7ac792-e934-4c29-b1df-431a4770f9af', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f428e9e52e0>]}
2021-05-28 12:19:03.426172 (MainThread): Found 3 models, 4 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-05-28 12:19:03.426844 (MainThread): 
2021-05-28 12:19:03.427082 (MainThread): Acquiring new bigquery connection "master".
2021-05-28 12:19:03.427711 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_oef-stage".
2021-05-28 12:19:03.427861 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-05-28 12:19:03.734273 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_oef-stage_TestRecoursePlanner".
2021-05-28 12:19:03.734874 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2021-05-28 12:19:03.738644 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-05-28 12:19:03.913147 (MainThread): 14:19:03 | Concurrency: 5 threads (target='dev')
2021-05-28 12:19:03.913403 (MainThread): 14:19:03 | 
2021-05-28 12:19:03.915166 (Thread-1): Began running node model.resourceplanner.my_first_dbt_model
2021-05-28 12:19:03.915330 (Thread-1): 14:19:03 | 1 of 3 START table model TestRecoursePlanner.my_first_dbt_model...... [RUN]
2021-05-28 12:19:03.915432 (Thread-2): Began running node model.resourceplanner.trydates
2021-05-28 12:19:03.915542 (Thread-2): 14:19:03 | 2 of 3 START table model TestRecoursePlanner.trydates................ [RUN]
2021-05-28 12:19:03.915782 (Thread-1): Acquiring new bigquery connection "model.resourceplanner.my_first_dbt_model".
2021-05-28 12:19:03.915879 (Thread-1): Compiling model.resourceplanner.my_first_dbt_model
2021-05-28 12:19:03.918329 (Thread-1): Writing injected SQL for node "model.resourceplanner.my_first_dbt_model"
2021-05-28 12:19:03.918704 (Thread-2): Acquiring new bigquery connection "model.resourceplanner.trydates".
2021-05-28 12:19:03.918854 (Thread-2): Compiling model.resourceplanner.trydates
2021-05-28 12:19:03.920437 (Thread-2): Writing injected SQL for node "model.resourceplanner.trydates"
2021-05-28 12:19:03.920688 (Thread-2): finished collecting timing info
2021-05-28 12:19:03.933414 (Thread-1): finished collecting timing info
2021-05-28 12:19:03.957340 (Thread-2): Opening a new connection, currently in state closed
2021-05-28 12:19:03.957746 (Thread-1): Opening a new connection, currently in state closed
2021-05-28 12:19:03.962506 (Thread-2): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-05-28 12:19:03.965793 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-05-28 12:19:04.164765 (Thread-1): Writing runtime SQL for node "model.resourceplanner.my_first_dbt_model"
2021-05-28 12:19:04.165213 (Thread-1): On model.resourceplanner.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "Bigquery", "target_name": "dev", "node_id": "model.resourceplanner.my_first_dbt_model"} */


  create or replace table `oef-stage`.`TestRecoursePlanner`.`my_first_dbt_model`
  
  
  OPTIONS()
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select M.ID, E.EmployeeID, CU.CustomerID,CO.CompanyID
from oef-stage.TestRecoursePlanner.MainData M
INNER JOIN oef-stage.TestRecoursePlanner.Employee E
ON M.Employee = E.Firstname
INNER JOIN oef-stage.TestRecoursePlanner.Customer CU
ON M.Customer = CU.Customername
INNER JOIN oef-stage.TestRecoursePlanner.Company CO
ON M.Company = CO.Companyname
ORDER BY M.ID

/*
    Uncomment the line below to remove records with null `id` values
*/
  );
    
2021-05-28 12:19:04.166730 (Thread-2): unclosed <socket.socket fd=5, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.0.2.15', 58960), raddr=('142.250.179.202', 443)>
2021-05-28 12:19:04.166872 (Thread-2): unclosed <socket.socket fd=6, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.0.2.15', 60710), raddr=('216.58.211.106', 443)>
2021-05-28 12:19:04.167032 (Thread-2): unclosed <socket.socket fd=8, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.0.2.15', 60714), raddr=('216.58.211.106', 443)>
2021-05-28 12:19:04.167169 (Thread-2): unclosed <socket.socket fd=7, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.0.2.15', 58964), raddr=('142.250.179.202', 443)>
2021-05-28 12:19:04.169487 (Thread-2): Writing runtime SQL for node "model.resourceplanner.trydates"
2021-05-28 12:19:04.169931 (Thread-2): On model.resourceplanner.trydates: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "Bigquery", "target_name": "dev", "node_id": "model.resourceplanner.trydates"} */


  create or replace table `oef-stage`.`TestRecoursePlanner`.`trydates`
  
  
  OPTIONS()
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/


DECLARE @StartDate DATE = ‘2016-10-01’;
DECLARE @EndDate DATE = ‘2016-10-31’;

WHILE (@StartDate <= @EndDate)

BEGIN

print @StartDate;

— Do Something like call a proc with the variable @StartDate

set @StartDate = DATEADD(day, 1, @StartDate);

END;
/*
    Uncomment the line below to remove records with null `id` values
*/
  );
    
2021-05-28 12:19:04.326343 (Thread-2): Retry attempt 1 of 1 after error: BadRequest('GET https://bigquery.googleapis.com/bigquery/v2/projects/oef-stage/queries/3f63e4f0-ecf8-43d0-ba30-34a3daedd1fe?maxResults=0&location=europe-west1&prettyPrint=false: Syntax error: Expected "(" or keyword SELECT or keyword WITH but got keyword DECLARE at [18:1]')
2021-05-28 12:19:04.729810 (Thread-2): finished collecting timing info
2021-05-28 12:19:04.730168 (Thread-2): Database Error in model trydates (models/Facttable/trydates.sql)
  Syntax error: Expected "(" or keyword SELECT or keyword WITH but got keyword DECLARE at [18:1]
  compiled SQL at target/run/resourceplanner/models/Facttable/trydates.sql
Traceback (most recent call last):
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 149, in exception_handler
    yield
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 327, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 520, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1146, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/job/base.py", line 631, in result
    return super(_AsyncJob, self).result(timeout=timeout, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/future/polling.py", line 129, in result
    self._blocking_poll(timeout=timeout, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1042, in _blocking_poll
    super(QueryJob, self)._blocking_poll(timeout=timeout, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/future/polling.py", line 107, in _blocking_poll
    retry_(self._done_or_raise)(**kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/future/polling.py", line 85, in _done_or_raise
    if not self.done(**kwargs):
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1022, in done
    self._query_results = self._client._get_query_results(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 1557, in _get_query_results
    resource = self._call_api(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 636, in _call_api
    return call()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/_http.py", line 438, in api_request
    raise exceptions.from_http_response(response)
google.api_core.exceptions.BadRequest: 400 GET https://bigquery.googleapis.com/bigquery/v2/projects/oef-stage/queries/3f2e976f-0561-4108-8cd9-0310b07f9a62?maxResults=0&location=europe-west1&prettyPrint=false: Syntax error: Expected "(" or keyword SELECT or keyword WITH but got keyword DECLARE at [18:1]

(job ID: 3f2e976f-0561-4108-8cd9-0310b07f9a62)

                                                         -----Query Job SQL Follows-----                                                         

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "Bigquery", "target_name": "dev", "node_id": "model.resourceplanner.trydates"} */
   2:
   3:
   4:  create or replace table `oef-stage`.`TestRecoursePlanner`.`trydates`
   5:  
   6:  
   7:  OPTIONS()
   8:  as (
   9:    /*
  10:    Welcome to your first dbt model!
  11:    Did you know that you can also configure models directly within SQL files?
  12:    This will override configurations stated in dbt_project.yml
  13:
  14:    Try changing "table" to "view" below
  15:*/
  16:
  17:
  18:DECLARE @StartDate DATE = ‘2016-10-01’;
  19:DECLARE @EndDate DATE = ‘2016-10-31’;
  20:
  21:WHILE (@StartDate <= @EndDate)
  22:
  23:BEGIN
  24:
  25:print @StartDate;
  26:
  27:— Do Something like call a proc with the variable @StartDate
  28:
  29:set @StartDate = DATEADD(day, 1, @StartDate);
  30:
  31:END;
  32:/*
  33:    Uncomment the line below to remove records with null `id` values
  34:*/
  35:  );
  36:    
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/base.py", line 287, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/base.py", line 389, in run
    return self.execute(compiled_node, manifest)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/run.py", line 248, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 128, in macro
  File "/home/femke/dbt-env/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/home/femke/dbt-env/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 227, in execute
    return self.connections.execute(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 338, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 329, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 153, in exception_handler
    self.handle_error(e, message)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 141, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in model trydates (models/Facttable/trydates.sql)
  Syntax error: Expected "(" or keyword SELECT or keyword WITH but got keyword DECLARE at [18:1]
  compiled SQL at target/run/resourceplanner/models/Facttable/trydates.sql
2021-05-28 12:19:04.732081 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8d7ac792-e934-4c29-b1df-431a4770f9af', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f428d0dfd30>]}
2021-05-28 12:19:04.732320 (Thread-2): 14:19:04 | 2 of 3 ERROR creating table model TestRecoursePlanner.trydates....... [ERROR in 0.81s]
2021-05-28 12:19:04.732521 (Thread-2): Finished running node model.resourceplanner.trydates
2021-05-28 12:19:08.959095 (Thread-1): finished collecting timing info
2021-05-28 12:19:08.959682 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8d7ac792-e934-4c29-b1df-431a4770f9af', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f428ea1e3d0>]}
2021-05-28 12:19:08.960008 (Thread-1): 14:19:08 | 1 of 3 OK created table model TestRecoursePlanner.my_first_dbt_model. [CREATE TABLE (14.0 rows, 5.4 KB processed) in 5.04s]
2021-05-28 12:19:08.960459 (Thread-1): Finished running node model.resourceplanner.my_first_dbt_model
2021-05-28 12:19:08.961005 (Thread-4): Began running node model.resourceplanner.my_second_dbt_model
2021-05-28 12:19:08.961231 (Thread-4): 14:19:08 | 3 of 3 START view model TestRecoursePlanner.my_second_dbt_model...... [RUN]
2021-05-28 12:19:08.961535 (Thread-4): Acquiring new bigquery connection "model.resourceplanner.my_second_dbt_model".
2021-05-28 12:19:08.961619 (Thread-4): Compiling model.resourceplanner.my_second_dbt_model
2021-05-28 12:19:08.963606 (Thread-4): Writing injected SQL for node "model.resourceplanner.my_second_dbt_model"
2021-05-28 12:19:08.963948 (Thread-4): finished collecting timing info
2021-05-28 12:19:08.991499 (Thread-4): Writing runtime SQL for node "model.resourceplanner.my_second_dbt_model"
2021-05-28 12:19:08.991999 (Thread-4): Opening a new connection, currently in state init
2021-05-28 12:19:09.010521 (Thread-4): On model.resourceplanner.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "Bigquery", "target_name": "dev", "node_id": "model.resourceplanner.my_second_dbt_model"} */


  create or replace view `oef-stage`.`TestRecoursePlanner`.`my_second_dbt_model`
  OPTIONS()
  as -- Use the `ref` function to select from other models

select *
from `oef-stage`.`TestRecoursePlanner`.`my_first_dbt_model`;


2021-05-28 12:19:10.187173 (Thread-4): finished collecting timing info
2021-05-28 12:19:10.187574 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8d7ac792-e934-4c29-b1df-431a4770f9af', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f428ea1e3d0>]}
2021-05-28 12:19:10.187874 (Thread-4): 14:19:10 | 3 of 3 OK created view model TestRecoursePlanner.my_second_dbt_model. [OK in 1.23s]
2021-05-28 12:19:10.188030 (Thread-4): Finished running node model.resourceplanner.my_second_dbt_model
2021-05-28 12:19:10.189166 (MainThread): Acquiring new bigquery connection "master".
2021-05-28 12:19:10.189434 (MainThread): 14:19:10 | 
2021-05-28 12:19:10.189579 (MainThread): 14:19:10 | Finished running 2 table models, 1 view model in 6.76s.
2021-05-28 12:19:10.189672 (MainThread): Connection 'master' was properly closed.
2021-05-28 12:19:10.189713 (MainThread): Connection 'model.resourceplanner.my_first_dbt_model' was properly closed.
2021-05-28 12:19:10.189746 (MainThread): Connection 'model.resourceplanner.trydates' was properly closed.
2021-05-28 12:19:10.189833 (MainThread): Connection 'model.resourceplanner.my_second_dbt_model' was properly closed.
2021-05-28 12:19:10.190570 (MainThread): unclosed <socket.socket fd=5, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.0.2.15', 58978), raddr=('142.250.179.202', 443)>
2021-05-28 12:19:10.190724 (MainThread): unclosed <socket.socket fd=6, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.0.2.15', 60728), raddr=('216.58.211.106', 443)>
2021-05-28 12:19:10.196538 (MainThread): 
2021-05-28 12:19:10.196730 (MainThread): Completed with 1 error and 0 warnings:
2021-05-28 12:19:10.196839 (MainThread): 
2021-05-28 12:19:10.196931 (MainThread): Database Error in model trydates (models/Facttable/trydates.sql)
2021-05-28 12:19:10.197028 (MainThread):   Syntax error: Expected "(" or keyword SELECT or keyword WITH but got keyword DECLARE at [18:1]
2021-05-28 12:19:10.197182 (MainThread):   compiled SQL at target/run/resourceplanner/models/Facttable/trydates.sql
2021-05-28 12:19:10.197305 (MainThread): 
Done. PASS=2 WARN=0 ERROR=1 SKIP=0 TOTAL=3
2021-05-28 12:19:10.197524 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f428e9f2e20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f428eac0610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f428eac0fd0>]}
2021-05-28 12:19:10.197692 (MainThread): Flushing usage events
2021-05-31 08:21:44.408591 (MainThread): Running with dbt=0.19.1
2021-05-31 08:21:44.583466 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/home/femke/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-05-31 08:21:44.584086 (MainThread): Tracking: tracking
2021-05-31 08:21:44.594687 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2a690f6c70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2a6aa2b250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2a6aa2b550>]}
2021-05-31 08:21:44.609176 (MainThread): Partial parsing not enabled
2021-05-31 08:21:44.609866 (MainThread): Parsing macros/catalog.sql
2021-05-31 08:21:44.618356 (MainThread): Parsing macros/adapters.sql
2021-05-31 08:21:44.637895 (MainThread): Parsing macros/etc.sql
2021-05-31 08:21:44.639270 (MainThread): Parsing macros/materializations/snapshot.sql
2021-05-31 08:21:44.640513 (MainThread): Parsing macros/materializations/copy.sql
2021-05-31 08:21:44.643655 (MainThread): Parsing macros/materializations/table.sql
2021-05-31 08:21:44.650544 (MainThread): Parsing macros/materializations/incremental.sql
2021-05-31 08:21:44.659156 (MainThread): Parsing macros/materializations/view.sql
2021-05-31 08:21:44.661135 (MainThread): Parsing macros/materializations/seed.sql
2021-05-31 08:21:44.663460 (MainThread): Parsing macros/core.sql
2021-05-31 08:21:44.666093 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-05-31 08:21:44.667106 (MainThread): Parsing macros/schema_tests/unique.sql
2021-05-31 08:21:44.668243 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-05-31 08:21:44.669506 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-05-31 08:21:44.671340 (MainThread): Parsing macros/materializations/helpers.sql
2021-05-31 08:21:44.677375 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-05-31 08:21:44.678650 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-05-31 08:21:44.683006 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-05-31 08:21:44.696743 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-05-31 08:21:44.716653 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-05-31 08:21:44.717780 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-05-31 08:21:44.729969 (MainThread): Parsing macros/materializations/table/table.sql
2021-05-31 08:21:44.734464 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-05-31 08:21:44.737937 (MainThread): Parsing macros/materializations/view/view.sql
2021-05-31 08:21:44.742090 (MainThread): Parsing macros/materializations/common/merge.sql
2021-05-31 08:21:44.751118 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-05-31 08:21:44.752238 (MainThread): Parsing macros/etc/query.sql
2021-05-31 08:21:44.752902 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-05-31 08:21:44.753547 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-05-31 08:21:44.754885 (MainThread): Parsing macros/etc/datetime.sql
2021-05-31 08:21:44.761396 (MainThread): Parsing macros/etc/is_incremental.sql
2021-05-31 08:21:44.762507 (MainThread): Parsing macros/adapters/common.sql
2021-05-31 08:21:44.793965 (MainThread): Partial parsing not enabled
2021-05-31 08:21:44.810233 (MainThread): Acquiring new bigquery connection "model.resourceplanner.EmployeeDates".
2021-05-31 08:21:44.816966 (MainThread): Acquiring new bigquery connection "model.resourceplanner.trydates".
2021-05-31 08:21:44.819266 (MainThread): Acquiring new bigquery connection "model.resourceplanner.my_second_dbt_model".
2021-05-31 08:21:44.821560 (MainThread): Acquiring new bigquery connection "model.resourceplanner.my_first_dbt_model".
2021-05-31 08:21:44.864903 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'da06c8c9-e690-491c-b88e-c964162b1da5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2a681fef70>]}
2021-05-31 08:21:44.867841 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'da06c8c9-e690-491c-b88e-c964162b1da5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2a6824edc0>]}
2021-05-31 08:21:44.868026 (MainThread): Found 4 models, 4 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-05-31 08:21:44.868665 (MainThread): 
2021-05-31 08:21:44.868959 (MainThread): Acquiring new bigquery connection "master".
2021-05-31 08:21:44.869573 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_oef-stage".
2021-05-31 08:21:44.869694 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-05-31 08:21:45.271750 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_oef-stage_TestRecoursePlanner".
2021-05-31 08:21:45.271930 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2021-05-31 08:21:45.275215 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-05-31 08:21:45.453315 (MainThread): 10:21:45 | Concurrency: 5 threads (target='dev')
2021-05-31 08:21:45.453546 (MainThread): 10:21:45 | 
2021-05-31 08:21:45.455156 (Thread-1): Began running node model.resourceplanner.my_first_dbt_model
2021-05-31 08:21:45.455306 (Thread-1): 10:21:45 | 1 of 4 START table model TestRecoursePlanner.my_first_dbt_model...... [RUN]
2021-05-31 08:21:45.455399 (Thread-2): Began running node model.resourceplanner.EmployeeDates
2021-05-31 08:21:45.455500 (Thread-2): 10:21:45 | 2 of 4 START table model TestRecoursePlanner.EmployeeDates........... [RUN]
2021-05-31 08:21:45.455564 (Thread-3): Began running node model.resourceplanner.trydates
2021-05-31 08:21:45.455656 (Thread-3): 10:21:45 | 3 of 4 START table model TestRecoursePlanner.trydates................ [RUN]
2021-05-31 08:21:45.455829 (Thread-1): Acquiring new bigquery connection "model.resourceplanner.my_first_dbt_model".
2021-05-31 08:21:45.455900 (Thread-1): Compiling model.resourceplanner.my_first_dbt_model
2021-05-31 08:21:45.457788 (Thread-1): Writing injected SQL for node "model.resourceplanner.my_first_dbt_model"
2021-05-31 08:21:45.457978 (Thread-2): Acquiring new bigquery connection "model.resourceplanner.EmployeeDates".
2021-05-31 08:21:45.458263 (Thread-2): Compiling model.resourceplanner.EmployeeDates
2021-05-31 08:21:45.459382 (Thread-2): Writing injected SQL for node "model.resourceplanner.EmployeeDates"
2021-05-31 08:21:45.459531 (Thread-2): finished collecting timing info
2021-05-31 08:21:45.458157 (Thread-3): Acquiring new bigquery connection "model.resourceplanner.trydates".
2021-05-31 08:21:45.467270 (Thread-3): Compiling model.resourceplanner.trydates
2021-05-31 08:21:45.468146 (Thread-3): unclosed <socket.socket fd=5, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.0.2.15', 44516), raddr=('142.250.179.138', 443)>
2021-05-31 08:21:45.468592 (Thread-1): finished collecting timing info
2021-05-31 08:21:45.478110 (Thread-3): unclosed <socket.socket fd=6, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.0.2.15', 42896), raddr=('216.58.208.106', 443)>
2021-05-31 08:21:45.478251 (Thread-3): unclosed <socket.socket fd=8, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.0.2.15', 42900), raddr=('216.58.208.106', 443)>
2021-05-31 08:21:45.478445 (Thread-3): unclosed <socket.socket fd=7, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.0.2.15', 44520), raddr=('142.250.179.138', 443)>
2021-05-31 08:21:45.479646 (Thread-3): Writing injected SQL for node "model.resourceplanner.trydates"
2021-05-31 08:21:45.480009 (Thread-3): finished collecting timing info
2021-05-31 08:21:45.500887 (Thread-3): Opening a new connection, currently in state init
2021-05-31 08:21:45.501292 (Thread-1): Opening a new connection, currently in state closed
2021-05-31 08:21:45.515318 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-05-31 08:21:45.517779 (Thread-3): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-05-31 08:21:45.522310 (Thread-2): Writing runtime SQL for node "model.resourceplanner.EmployeeDates"
2021-05-31 08:21:45.523598 (Thread-2): Opening a new connection, currently in state closed
2021-05-31 08:21:45.526688 (Thread-2): On model.resourceplanner.EmployeeDates: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "Bigquery", "target_name": "dev", "node_id": "model.resourceplanner.EmployeeDates"} */


  create or replace table `oef-stage`.`TestRecoursePlanner`.`EmployeeDates`
  
  
  OPTIONS()
  as (
    

SELECT DISTINCT E.EmployeeID, T.full_date
FROM oef-stage.TestRecoursePlanner.Time T
CROSS JOIN oef-stage.TestRecoursePlanner.Employee E
ORDER BY T.full_date
  );
    
2021-05-31 08:21:45.691191 (Thread-1): Writing runtime SQL for node "model.resourceplanner.my_first_dbt_model"
2021-05-31 08:21:45.691618 (Thread-1): On model.resourceplanner.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "Bigquery", "target_name": "dev", "node_id": "model.resourceplanner.my_first_dbt_model"} */


  create or replace table `oef-stage`.`TestRecoursePlanner`.`my_first_dbt_model`
  
  
  OPTIONS()
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select M.ID, E.EmployeeID, CU.CustomerID,CO.CompanyID
from oef-stage.TestRecoursePlanner.MainData M
INNER JOIN oef-stage.TestRecoursePlanner.Employee E
ON M.Employee = E.Firstname
INNER JOIN oef-stage.TestRecoursePlanner.Customer CU
ON M.Customer = CU.Customername
INNER JOIN oef-stage.TestRecoursePlanner.Company CO
ON M.Company = CO.Companyname
ORDER BY M.ID

/*
    Uncomment the line below to remove records with null `id` values
*/
  );
    
2021-05-31 08:21:45.693412 (Thread-3): Writing runtime SQL for node "model.resourceplanner.trydates"
2021-05-31 08:21:45.693634 (Thread-3): On model.resourceplanner.trydates: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "Bigquery", "target_name": "dev", "node_id": "model.resourceplanner.trydates"} */


  create or replace table `oef-stage`.`TestRecoursePlanner`.`trydates`
  
  
  OPTIONS()
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/


declare @StartDate date = oef-stage.TestRecoursePlanner.MainData.StartDate
declare @EndDate date = oef-stage.TestRecoursePlanner.MainData.EndDate


/*
    Uncomment the line below to remove records with null `id` values
*/
  );
    
2021-05-31 08:21:45.867489 (Thread-3): Retry attempt 1 of 1 after error: BadRequest('GET https://bigquery.googleapis.com/bigquery/v2/projects/oef-stage/queries/f3daf8ad-efeb-45f0-95c2-6757ba487081?maxResults=0&location=europe-west1&prettyPrint=false: Syntax error: Expected "(" or keyword SELECT or keyword WITH but got keyword DECLARE at [18:1]')
2021-05-31 08:21:46.511773 (Thread-3): finished collecting timing info
2021-05-31 08:21:46.512101 (Thread-3): Database Error in model trydates (models/Facttable/trydates.sql)
  Syntax error: Expected "(" or keyword SELECT or keyword WITH but got keyword DECLARE at [18:1]
  compiled SQL at target/run/resourceplanner/models/Facttable/trydates.sql
Traceback (most recent call last):
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 149, in exception_handler
    yield
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 327, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 520, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1146, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/job/base.py", line 631, in result
    return super(_AsyncJob, self).result(timeout=timeout, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/future/polling.py", line 129, in result
    self._blocking_poll(timeout=timeout, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1042, in _blocking_poll
    super(QueryJob, self)._blocking_poll(timeout=timeout, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/future/polling.py", line 107, in _blocking_poll
    retry_(self._done_or_raise)(**kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/future/polling.py", line 85, in _done_or_raise
    if not self.done(**kwargs):
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1022, in done
    self._query_results = self._client._get_query_results(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 1557, in _get_query_results
    resource = self._call_api(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 636, in _call_api
    return call()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/_http.py", line 438, in api_request
    raise exceptions.from_http_response(response)
google.api_core.exceptions.BadRequest: 400 GET https://bigquery.googleapis.com/bigquery/v2/projects/oef-stage/queries/da3b1e52-0817-4d1b-8c20-4416a3537bf1?maxResults=0&location=europe-west1&prettyPrint=false: Syntax error: Expected "(" or keyword SELECT or keyword WITH but got keyword DECLARE at [18:1]

(job ID: da3b1e52-0817-4d1b-8c20-4416a3537bf1)

                                                         -----Query Job SQL Follows-----                                                         

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "Bigquery", "target_name": "dev", "node_id": "model.resourceplanner.trydates"} */
   2:
   3:
   4:  create or replace table `oef-stage`.`TestRecoursePlanner`.`trydates`
   5:  
   6:  
   7:  OPTIONS()
   8:  as (
   9:    /*
  10:    Welcome to your first dbt model!
  11:    Did you know that you can also configure models directly within SQL files?
  12:    This will override configurations stated in dbt_project.yml
  13:
  14:    Try changing "table" to "view" below
  15:*/
  16:
  17:
  18:declare @StartDate date = oef-stage.TestRecoursePlanner.MainData.StartDate
  19:declare @EndDate date = oef-stage.TestRecoursePlanner.MainData.EndDate
  20:
  21:
  22:/*
  23:    Uncomment the line below to remove records with null `id` values
  24:*/
  25:  );
  26:    
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/base.py", line 287, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/base.py", line 389, in run
    return self.execute(compiled_node, manifest)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/run.py", line 248, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 128, in macro
  File "/home/femke/dbt-env/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/home/femke/dbt-env/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 227, in execute
    return self.connections.execute(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 338, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 329, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 153, in exception_handler
    self.handle_error(e, message)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 141, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in model trydates (models/Facttable/trydates.sql)
  Syntax error: Expected "(" or keyword SELECT or keyword WITH but got keyword DECLARE at [18:1]
  compiled SQL at target/run/resourceplanner/models/Facttable/trydates.sql
2021-05-31 08:21:46.513837 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'da06c8c9-e690-491c-b88e-c964162b1da5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2a64002670>]}
2021-05-31 08:21:46.514086 (Thread-3): 10:21:46 | 3 of 4 ERROR creating table model TestRecoursePlanner.trydates....... [ERROR in 1.06s]
2021-05-31 08:21:46.514264 (Thread-3): Finished running node model.resourceplanner.trydates
2021-05-31 08:21:48.533572 (Thread-2): finished collecting timing info
2021-05-31 08:21:48.533880 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'da06c8c9-e690-491c-b88e-c964162b1da5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2a64097e80>]}
2021-05-31 08:21:48.534091 (Thread-2): 10:21:48 | 2 of 4 OK created table model TestRecoursePlanner.EmployeeDates...... [CREATE TABLE (43.8k rows, 57.8 KB processed) in 3.08s]
2021-05-31 08:21:48.534289 (Thread-2): Finished running node model.resourceplanner.EmployeeDates
2021-05-31 08:21:50.139524 (Thread-1): finished collecting timing info
2021-05-31 08:21:50.139834 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'da06c8c9-e690-491c-b88e-c964162b1da5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2a64089f70>]}
2021-05-31 08:21:50.140418 (Thread-1): 10:21:50 | 1 of 4 OK created table model TestRecoursePlanner.my_first_dbt_model. [CREATE TABLE (13.0 rows, 5.2 KB processed) in 4.68s]
2021-05-31 08:21:50.140677 (Thread-1): Finished running node model.resourceplanner.my_first_dbt_model
2021-05-31 08:21:50.141142 (Thread-5): Began running node model.resourceplanner.my_second_dbt_model
2021-05-31 08:21:50.141267 (Thread-5): 10:21:50 | 4 of 4 START view model TestRecoursePlanner.my_second_dbt_model...... [RUN]
2021-05-31 08:21:50.141528 (Thread-5): Acquiring new bigquery connection "model.resourceplanner.my_second_dbt_model".
2021-05-31 08:21:50.141596 (Thread-5): Compiling model.resourceplanner.my_second_dbt_model
2021-05-31 08:21:50.143101 (Thread-5): Writing injected SQL for node "model.resourceplanner.my_second_dbt_model"
2021-05-31 08:21:50.143350 (Thread-5): finished collecting timing info
2021-05-31 08:21:50.163501 (Thread-5): Writing runtime SQL for node "model.resourceplanner.my_second_dbt_model"
2021-05-31 08:21:50.163901 (Thread-5): Opening a new connection, currently in state init
2021-05-31 08:21:50.167030 (Thread-5): On model.resourceplanner.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "Bigquery", "target_name": "dev", "node_id": "model.resourceplanner.my_second_dbt_model"} */


  create or replace view `oef-stage`.`TestRecoursePlanner`.`my_second_dbt_model`
  OPTIONS()
  as -- Use the `ref` function to select from other models

select *
from `oef-stage`.`TestRecoursePlanner`.`my_first_dbt_model`;


2021-05-31 08:21:51.358969 (Thread-5): finished collecting timing info
2021-05-31 08:21:51.359282 (Thread-5): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'da06c8c9-e690-491c-b88e-c964162b1da5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2a678eebe0>]}
2021-05-31 08:21:51.359513 (Thread-5): 10:21:51 | 4 of 4 OK created view model TestRecoursePlanner.my_second_dbt_model. [OK in 1.22s]
2021-05-31 08:21:51.359681 (Thread-5): Finished running node model.resourceplanner.my_second_dbt_model
2021-05-31 08:21:51.360518 (MainThread): Acquiring new bigquery connection "master".
2021-05-31 08:21:51.360678 (MainThread): 10:21:51 | 
2021-05-31 08:21:51.360778 (MainThread): 10:21:51 | Finished running 3 table models, 1 view model in 6.49s.
2021-05-31 08:21:51.360863 (MainThread): Connection 'master' was properly closed.
2021-05-31 08:21:51.360902 (MainThread): Connection 'model.resourceplanner.my_first_dbt_model' was properly closed.
2021-05-31 08:21:51.360932 (MainThread): Connection 'model.resourceplanner.EmployeeDates' was properly closed.
2021-05-31 08:21:51.360961 (MainThread): Connection 'model.resourceplanner.trydates' was properly closed.
2021-05-31 08:21:51.360990 (MainThread): Connection 'model.resourceplanner.my_second_dbt_model' was properly closed.
2021-05-31 08:21:51.361656 (MainThread): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.0.2.15', 44536), raddr=('142.250.179.138', 443)>
2021-05-31 08:21:51.361785 (MainThread): unclosed <socket.socket fd=14, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.0.2.15', 42916), raddr=('216.58.208.106', 443)>
2021-05-31 08:21:51.365755 (MainThread): 
2021-05-31 08:21:51.365956 (MainThread): Completed with 1 error and 0 warnings:
2021-05-31 08:21:51.366057 (MainThread): 
2021-05-31 08:21:51.366137 (MainThread): Database Error in model trydates (models/Facttable/trydates.sql)
2021-05-31 08:21:51.366218 (MainThread):   Syntax error: Expected "(" or keyword SELECT or keyword WITH but got keyword DECLARE at [18:1]
2021-05-31 08:21:51.366296 (MainThread):   compiled SQL at target/run/resourceplanner/models/Facttable/trydates.sql
2021-05-31 08:21:51.366386 (MainThread): 
Done. PASS=3 WARN=0 ERROR=1 SKIP=0 TOTAL=4
2021-05-31 08:21:51.366542 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2a68252520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2a68242f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2a682cf070>]}
2021-05-31 08:21:51.366663 (MainThread): Flushing usage events
2021-05-31 09:30:28.994156 (MainThread): Running with dbt=0.19.1
2021-05-31 09:30:29.173781 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/home/femke/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-05-31 09:30:29.175027 (MainThread): Tracking: tracking
2021-05-31 09:30:29.195290 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0cee1cecd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0cefb01250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0cefb01550>]}
2021-05-31 09:30:29.210438 (MainThread): Partial parsing not enabled
2021-05-31 09:30:29.211193 (MainThread): Parsing macros/catalog.sql
2021-05-31 09:30:29.219867 (MainThread): Parsing macros/adapters.sql
2021-05-31 09:30:29.242796 (MainThread): Parsing macros/etc.sql
2021-05-31 09:30:29.244684 (MainThread): Parsing macros/materializations/snapshot.sql
2021-05-31 09:30:29.245900 (MainThread): Parsing macros/materializations/copy.sql
2021-05-31 09:30:29.249075 (MainThread): Parsing macros/materializations/table.sql
2021-05-31 09:30:29.256663 (MainThread): Parsing macros/materializations/incremental.sql
2021-05-31 09:30:29.265776 (MainThread): Parsing macros/materializations/view.sql
2021-05-31 09:30:29.267774 (MainThread): Parsing macros/materializations/seed.sql
2021-05-31 09:30:29.270116 (MainThread): Parsing macros/core.sql
2021-05-31 09:30:29.272929 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-05-31 09:30:29.273948 (MainThread): Parsing macros/schema_tests/unique.sql
2021-05-31 09:30:29.275062 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-05-31 09:30:29.276367 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-05-31 09:30:29.278178 (MainThread): Parsing macros/materializations/helpers.sql
2021-05-31 09:30:29.284399 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-05-31 09:30:29.285967 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-05-31 09:30:29.290437 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-05-31 09:30:29.304310 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-05-31 09:30:29.324765 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-05-31 09:30:29.326021 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-05-31 09:30:29.338878 (MainThread): Parsing macros/materializations/table/table.sql
2021-05-31 09:30:29.343849 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-05-31 09:30:29.347306 (MainThread): Parsing macros/materializations/view/view.sql
2021-05-31 09:30:29.351863 (MainThread): Parsing macros/materializations/common/merge.sql
2021-05-31 09:30:29.362769 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-05-31 09:30:29.363948 (MainThread): Parsing macros/etc/query.sql
2021-05-31 09:30:29.364744 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-05-31 09:30:29.365377 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-05-31 09:30:29.366764 (MainThread): Parsing macros/etc/datetime.sql
2021-05-31 09:30:29.372687 (MainThread): Parsing macros/etc/is_incremental.sql
2021-05-31 09:30:29.373944 (MainThread): Parsing macros/adapters/common.sql
2021-05-31 09:30:29.406750 (MainThread): Partial parsing not enabled
2021-05-31 09:30:29.423738 (MainThread): Acquiring new bigquery connection "model.resourceplanner.EmployeeDates".
2021-05-31 09:30:29.431512 (MainThread): Acquiring new bigquery connection "model.resourceplanner.trydates".
2021-05-31 09:30:29.433992 (MainThread): Acquiring new bigquery connection "model.resourceplanner.my_second_dbt_model".
2021-05-31 09:30:29.436517 (MainThread): Acquiring new bigquery connection "model.resourceplanner.my_first_dbt_model".
2021-05-31 09:30:29.486341 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '59af7b08-a092-42aa-9cdd-f660058d352d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ced2d4e50>]}
2021-05-31 09:30:29.489618 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '59af7b08-a092-42aa-9cdd-f660058d352d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ced327df0>]}
2021-05-31 09:30:29.489797 (MainThread): Found 4 models, 4 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-05-31 09:30:29.490574 (MainThread): 
2021-05-31 09:30:29.490976 (MainThread): Acquiring new bigquery connection "master".
2021-05-31 09:30:29.491626 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_oef-stage".
2021-05-31 09:30:29.491750 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-05-31 09:30:29.892616 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_oef-stage_TestRecoursePlanner".
2021-05-31 09:30:29.892774 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2021-05-31 09:30:29.895857 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-05-31 09:30:30.073654 (MainThread): 11:30:30 | Concurrency: 5 threads (target='dev')
2021-05-31 09:30:30.073890 (MainThread): 11:30:30 | 
2021-05-31 09:30:30.076236 (Thread-1): Began running node model.resourceplanner.my_first_dbt_model
2021-05-31 09:30:30.076463 (Thread-1): 11:30:30 | 1 of 4 START table model TestRecoursePlanner.my_first_dbt_model...... [RUN]
2021-05-31 09:30:30.076596 (Thread-2): Began running node model.resourceplanner.EmployeeDates
2021-05-31 09:30:30.076699 (Thread-2): 11:30:30 | 2 of 4 START table model TestRecoursePlanner.EmployeeDates........... [RUN]
2021-05-31 09:30:30.076765 (Thread-3): Began running node model.resourceplanner.trydates
2021-05-31 09:30:30.076857 (Thread-3): 11:30:30 | 3 of 4 START table model TestRecoursePlanner.trydates................ [RUN]
2021-05-31 09:30:30.077079 (Thread-1): Acquiring new bigquery connection "model.resourceplanner.my_first_dbt_model".
2021-05-31 09:30:30.077291 (Thread-1): Compiling model.resourceplanner.my_first_dbt_model
2021-05-31 09:30:30.083232 (Thread-1): Writing injected SQL for node "model.resourceplanner.my_first_dbt_model"
2021-05-31 09:30:30.083533 (Thread-2): Acquiring new bigquery connection "model.resourceplanner.EmployeeDates".
2021-05-31 09:30:30.083826 (Thread-2): Compiling model.resourceplanner.EmployeeDates
2021-05-31 09:30:30.083705 (Thread-3): Acquiring new bigquery connection "model.resourceplanner.trydates".
2021-05-31 09:30:30.100679 (Thread-3): Compiling model.resourceplanner.trydates
2021-05-31 09:30:30.101990 (Thread-3): Writing injected SQL for node "model.resourceplanner.trydates"
2021-05-31 09:30:30.102221 (Thread-3): finished collecting timing info
2021-05-31 09:30:30.100451 (Thread-2): Writing injected SQL for node "model.resourceplanner.EmployeeDates"
2021-05-31 09:30:30.105063 (Thread-1): finished collecting timing info
2021-05-31 09:30:30.119704 (Thread-2): finished collecting timing info
2021-05-31 09:30:30.132136 (Thread-3): unclosed <socket.socket fd=5, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.0.2.15', 53132), raddr=('142.250.179.170', 443)>
2021-05-31 09:30:30.132464 (Thread-3): unclosed <socket.socket fd=6, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.0.2.15', 46358), raddr=('172.217.17.42', 443)>
2021-05-31 09:30:30.132632 (Thread-3): unclosed <socket.socket fd=8, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.0.2.15', 46362), raddr=('172.217.17.42', 443)>
2021-05-31 09:30:30.132875 (Thread-3): unclosed <socket.socket fd=7, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.0.2.15', 53136), raddr=('142.250.179.170', 443)>
2021-05-31 09:30:30.153854 (Thread-3): Opening a new connection, currently in state init
2021-05-31 09:30:30.154202 (Thread-1): Opening a new connection, currently in state closed
2021-05-31 09:30:30.157930 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-05-31 09:30:30.154365 (Thread-2): Opening a new connection, currently in state closed
2021-05-31 09:30:30.163875 (Thread-2): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-05-31 09:30:30.167284 (Thread-3): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-05-31 09:30:30.357691 (Thread-3): Writing runtime SQL for node "model.resourceplanner.trydates"
2021-05-31 09:30:30.358599 (Thread-2): Writing runtime SQL for node "model.resourceplanner.EmployeeDates"
2021-05-31 09:30:30.361094 (Thread-2): On model.resourceplanner.EmployeeDates: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "Bigquery", "target_name": "dev", "node_id": "model.resourceplanner.EmployeeDates"} */


  create or replace table `oef-stage`.`TestRecoursePlanner`.`EmployeeDates`
  
  
  OPTIONS()
  as (
    

SELECT DISTINCT E.EmployeeID, T.full_date
FROM oef-stage.TestRecoursePlanner.Time T
CROSS JOIN oef-stage.TestRecoursePlanner.Employee E
ORDER BY T.full_date
  );
    
2021-05-31 09:30:30.360690 (Thread-1): Writing runtime SQL for node "model.resourceplanner.my_first_dbt_model"
2021-05-31 09:30:30.362677 (Thread-1): On model.resourceplanner.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "Bigquery", "target_name": "dev", "node_id": "model.resourceplanner.my_first_dbt_model"} */


  create or replace table `oef-stage`.`TestRecoursePlanner`.`my_first_dbt_model`
  
  
  OPTIONS()
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select M.ID, E.EmployeeID, CU.CustomerID,CO.CompanyID
from oef-stage.TestRecoursePlanner.MainData M
INNER JOIN oef-stage.TestRecoursePlanner.Employee E
ON M.Employee = E.Firstname
INNER JOIN oef-stage.TestRecoursePlanner.Customer CU
ON M.Customer = CU.Customername
INNER JOIN oef-stage.TestRecoursePlanner.Company CO
ON M.Company = CO.Companyname
ORDER BY M.ID

/*
    Uncomment the line below to remove records with null `id` values
*/
  );
    
2021-05-31 09:30:30.363952 (Thread-3): On model.resourceplanner.trydates: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "Bigquery", "target_name": "dev", "node_id": "model.resourceplanner.trydates"} */


  create or replace table `oef-stage`.`TestRecoursePlanner`.`trydates`
  
  
  OPTIONS()
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/


with source_data as (

    select 1 as id
    union all
    select null as id

)

select M.ID, E.EmployeeID, CU.CustomerID,CO.CompanyID
from oef-stage.TestRecoursePlanner.MainData M
INNER JOIN oef-stage.TestRecoursePlanner.Employee E
ON M.Employee = E.Firstname
INNER JOIN oef-stage.TestRecoursePlanner.Customer CU
ON M.Customer = CU.Customername
INNER JOIN oef-stage.TestRecoursePlanner.Company CO
ON M.Company = CO.Companyname
ORDER BY M.ID

/*
    Uncomment the line below to remove records with null `id` values
*/
  );
    
2021-05-31 09:30:33.844325 (Thread-2): finished collecting timing info
2021-05-31 09:30:33.844667 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '59af7b08-a092-42aa-9cdd-f660058d352d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ced2254f0>]}
2021-05-31 09:30:33.844877 (Thread-2): 11:30:33 | 2 of 4 OK created table model TestRecoursePlanner.EmployeeDates...... [CREATE TABLE (43.8k rows, 57.8 KB processed) in 3.76s]
2021-05-31 09:30:33.845063 (Thread-2): Finished running node model.resourceplanner.EmployeeDates
2021-05-31 09:30:35.168156 (Thread-1): finished collecting timing info
2021-05-31 09:30:35.168466 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '59af7b08-a092-42aa-9cdd-f660058d352d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0cec14d0a0>]}
2021-05-31 09:30:35.168760 (Thread-1): 11:30:35 | 1 of 4 OK created table model TestRecoursePlanner.my_first_dbt_model. [CREATE TABLE (14.0 rows, 5.4 KB processed) in 5.09s]
2021-05-31 09:30:35.168861 (Thread-1): Finished running node model.resourceplanner.my_first_dbt_model
2021-05-31 09:30:35.169081 (Thread-5): Began running node model.resourceplanner.my_second_dbt_model
2021-05-31 09:30:35.169191 (Thread-5): 11:30:35 | 4 of 4 START view model TestRecoursePlanner.my_second_dbt_model...... [RUN]
2021-05-31 09:30:35.169349 (Thread-5): Acquiring new bigquery connection "model.resourceplanner.my_second_dbt_model".
2021-05-31 09:30:35.169410 (Thread-5): Compiling model.resourceplanner.my_second_dbt_model
2021-05-31 09:30:35.171079 (Thread-5): Writing injected SQL for node "model.resourceplanner.my_second_dbt_model"
2021-05-31 09:30:35.171312 (Thread-5): finished collecting timing info
2021-05-31 09:30:35.190668 (Thread-5): Writing runtime SQL for node "model.resourceplanner.my_second_dbt_model"
2021-05-31 09:30:35.191198 (Thread-5): Opening a new connection, currently in state init
2021-05-31 09:30:35.194686 (Thread-5): On model.resourceplanner.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "Bigquery", "target_name": "dev", "node_id": "model.resourceplanner.my_second_dbt_model"} */


  create or replace view `oef-stage`.`TestRecoursePlanner`.`my_second_dbt_model`
  OPTIONS()
  as -- Use the `ref` function to select from other models

select *
from `oef-stage`.`TestRecoursePlanner`.`my_first_dbt_model`;


2021-05-31 09:30:35.454889 (Thread-3): finished collecting timing info
2021-05-31 09:30:35.455307 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '59af7b08-a092-42aa-9cdd-f660058d352d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0cec9c5fd0>]}
2021-05-31 09:30:35.455562 (Thread-3): 11:30:35 | 3 of 4 OK created table model TestRecoursePlanner.trydates........... [CREATE TABLE (14.0 rows, 5.4 KB processed) in 5.37s]
2021-05-31 09:30:35.455758 (Thread-3): Finished running node model.resourceplanner.trydates
2021-05-31 09:30:36.386975 (Thread-5): finished collecting timing info
2021-05-31 09:30:36.387410 (Thread-5): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '59af7b08-a092-42aa-9cdd-f660058d352d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0cec0adee0>]}
2021-05-31 09:30:36.387663 (Thread-5): 11:30:36 | 4 of 4 OK created view model TestRecoursePlanner.my_second_dbt_model. [OK in 1.22s]
2021-05-31 09:30:36.387868 (Thread-5): Finished running node model.resourceplanner.my_second_dbt_model
2021-05-31 09:30:36.389097 (MainThread): Acquiring new bigquery connection "master".
2021-05-31 09:30:36.389296 (MainThread): 11:30:36 | 
2021-05-31 09:30:36.389418 (MainThread): 11:30:36 | Finished running 3 table models, 1 view model in 6.90s.
2021-05-31 09:30:36.389505 (MainThread): Connection 'master' was properly closed.
2021-05-31 09:30:36.389545 (MainThread): Connection 'model.resourceplanner.my_first_dbt_model' was properly closed.
2021-05-31 09:30:36.389575 (MainThread): Connection 'model.resourceplanner.EmployeeDates' was properly closed.
2021-05-31 09:30:36.389603 (MainThread): Connection 'model.resourceplanner.trydates' was properly closed.
2021-05-31 09:30:36.389631 (MainThread): Connection 'model.resourceplanner.my_second_dbt_model' was properly closed.
2021-05-31 09:30:36.393885 (MainThread): 
2021-05-31 09:30:36.394109 (MainThread): Completed successfully
2021-05-31 09:30:36.394212 (MainThread): 
Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
2021-05-31 09:30:36.394371 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ced32c220>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ced2e44f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ced2f67c0>]}
2021-05-31 09:30:36.394514 (MainThread): Flushing usage events
2021-05-31 09:36:14.932496 (MainThread): Running with dbt=0.19.1
2021-05-31 09:36:15.192757 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/home/femke/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-05-31 09:36:15.193376 (MainThread): Tracking: tracking
2021-05-31 09:36:15.204007 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff42d72eb20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff42f0241c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff42f024610>]}
2021-05-31 09:36:15.224795 (MainThread): Partial parsing not enabled
2021-05-31 09:36:15.225638 (MainThread): Parsing macros/catalog.sql
2021-05-31 09:36:15.235799 (MainThread): Parsing macros/adapters.sql
2021-05-31 09:36:15.259533 (MainThread): Parsing macros/etc.sql
2021-05-31 09:36:15.261084 (MainThread): Parsing macros/materializations/snapshot.sql
2021-05-31 09:36:15.262363 (MainThread): Parsing macros/materializations/copy.sql
2021-05-31 09:36:15.265897 (MainThread): Parsing macros/materializations/table.sql
2021-05-31 09:36:15.273590 (MainThread): Parsing macros/materializations/incremental.sql
2021-05-31 09:36:15.283390 (MainThread): Parsing macros/materializations/view.sql
2021-05-31 09:36:15.285564 (MainThread): Parsing macros/materializations/seed.sql
2021-05-31 09:36:15.288205 (MainThread): Parsing macros/core.sql
2021-05-31 09:36:15.290985 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-05-31 09:36:15.292207 (MainThread): Parsing macros/schema_tests/unique.sql
2021-05-31 09:36:15.293593 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-05-31 09:36:15.294889 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-05-31 09:36:15.296825 (MainThread): Parsing macros/materializations/helpers.sql
2021-05-31 09:36:15.303027 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-05-31 09:36:15.304669 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-05-31 09:36:15.310418 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-05-31 09:36:15.329590 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-05-31 09:36:15.357657 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-05-31 09:36:15.359412 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-05-31 09:36:15.374053 (MainThread): Parsing macros/materializations/table/table.sql
2021-05-31 09:36:15.379474 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-05-31 09:36:15.383341 (MainThread): Parsing macros/materializations/view/view.sql
2021-05-31 09:36:15.388971 (MainThread): Parsing macros/materializations/common/merge.sql
2021-05-31 09:36:15.399247 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-05-31 09:36:15.400671 (MainThread): Parsing macros/etc/query.sql
2021-05-31 09:36:15.401359 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-05-31 09:36:15.402003 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-05-31 09:36:15.403488 (MainThread): Parsing macros/etc/datetime.sql
2021-05-31 09:36:15.409613 (MainThread): Parsing macros/etc/is_incremental.sql
2021-05-31 09:36:15.410870 (MainThread): Parsing macros/adapters/common.sql
2021-05-31 09:36:15.443781 (MainThread): Partial parsing not enabled
2021-05-31 09:36:15.463741 (MainThread): Acquiring new bigquery connection "model.resourceplanner.EmployeeDates".
2021-05-31 09:36:15.471434 (MainThread): Acquiring new bigquery connection "model.resourceplanner.trydates".
2021-05-31 09:36:15.473851 (MainThread): Acquiring new bigquery connection "model.resourceplanner.my_second_dbt_model".
2021-05-31 09:36:15.476265 (MainThread): Acquiring new bigquery connection "model.resourceplanner.my_first_dbt_model".
2021-05-31 09:36:15.524389 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '82a5f573-e309-4e3f-8a25-02e0e5188751', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff42c7b8f40>]}
2021-05-31 09:36:15.528372 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '82a5f573-e309-4e3f-8a25-02e0e5188751', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff42c806f40>]}
2021-05-31 09:36:15.528594 (MainThread): Found 4 models, 4 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-05-31 09:36:15.529295 (MainThread): 
2021-05-31 09:36:15.529552 (MainThread): Acquiring new bigquery connection "master".
2021-05-31 09:36:15.530212 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_oef-stage".
2021-05-31 09:36:15.530346 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-05-31 09:36:15.902936 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_oef-stage_TestRecoursePlanner".
2021-05-31 09:36:15.903091 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2021-05-31 09:36:15.906458 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-05-31 09:36:16.095875 (MainThread): 11:36:16 | Concurrency: 5 threads (target='dev')
2021-05-31 09:36:16.096138 (MainThread): 11:36:16 | 
2021-05-31 09:36:16.097793 (Thread-1): Began running node model.resourceplanner.my_first_dbt_model
2021-05-31 09:36:16.097947 (Thread-1): 11:36:16 | 1 of 4 START table model TestRecoursePlanner.my_first_dbt_model...... [RUN]
2021-05-31 09:36:16.098073 (Thread-2): Began running node model.resourceplanner.EmployeeDates
2021-05-31 09:36:16.098183 (Thread-2): 11:36:16 | 2 of 4 START table model TestRecoursePlanner.EmployeeDates........... [RUN]
2021-05-31 09:36:16.098248 (Thread-3): Began running node model.resourceplanner.trydates
2021-05-31 09:36:16.098345 (Thread-3): 11:36:16 | 3 of 4 START table model TestRecoursePlanner.trydates................ [RUN]
2021-05-31 09:36:16.098516 (Thread-1): Acquiring new bigquery connection "model.resourceplanner.my_first_dbt_model".
2021-05-31 09:36:16.098587 (Thread-1): Compiling model.resourceplanner.my_first_dbt_model
2021-05-31 09:36:16.100513 (Thread-1): Writing injected SQL for node "model.resourceplanner.my_first_dbt_model"
2021-05-31 09:36:16.100972 (Thread-1): finished collecting timing info
2021-05-31 09:36:16.101298 (Thread-2): Acquiring new bigquery connection "model.resourceplanner.EmployeeDates".
2021-05-31 09:36:16.107864 (Thread-2): Compiling model.resourceplanner.EmployeeDates
2021-05-31 09:36:16.101479 (Thread-3): Acquiring new bigquery connection "model.resourceplanner.trydates".
2021-05-31 09:36:16.109393 (Thread-3): Compiling model.resourceplanner.trydates
2021-05-31 09:36:16.110060 (Thread-3): unclosed <socket.socket fd=5, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.0.2.15', 46946), raddr=('172.217.168.202', 443)>
2021-05-31 09:36:16.110227 (Thread-3): unclosed <socket.socket fd=6, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.0.2.15', 32860), raddr=('216.58.211.106', 443)>
2021-05-31 09:36:16.110431 (Thread-3): unclosed <socket.socket fd=8, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.0.2.15', 32864), raddr=('216.58.211.106', 443)>
2021-05-31 09:36:16.110568 (Thread-3): unclosed <socket.socket fd=7, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.0.2.15', 46950), raddr=('172.217.168.202', 443)>
2021-05-31 09:36:16.109315 (Thread-2): Writing injected SQL for node "model.resourceplanner.EmployeeDates"
2021-05-31 09:36:16.120312 (Thread-2): finished collecting timing info
2021-05-31 09:36:16.119876 (Thread-3): Writing injected SQL for node "model.resourceplanner.trydates"
2021-05-31 09:36:16.150840 (Thread-3): finished collecting timing info
2021-05-31 09:36:16.151809 (Thread-3): Opening a new connection, currently in state init
2021-05-31 09:36:16.150451 (Thread-2): Opening a new connection, currently in state closed
2021-05-31 09:36:16.158739 (Thread-3): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-05-31 09:36:16.148295 (Thread-1): Opening a new connection, currently in state closed
2021-05-31 09:36:16.164881 (Thread-2): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-05-31 09:36:16.167266 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-05-31 09:36:16.362018 (Thread-3): Writing runtime SQL for node "model.resourceplanner.trydates"
2021-05-31 09:36:16.362971 (Thread-2): Writing runtime SQL for node "model.resourceplanner.EmployeeDates"
2021-05-31 09:36:16.364858 (Thread-2): On model.resourceplanner.EmployeeDates: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "Bigquery", "target_name": "dev", "node_id": "model.resourceplanner.EmployeeDates"} */


  create or replace table `oef-stage`.`TestRecoursePlanner`.`EmployeeDates`
  
  
  OPTIONS()
  as (
    

SELECT DISTINCT E.EmployeeID, T.full_date
FROM oef-stage.TestRecoursePlanner.Time T
CROSS JOIN oef-stage.TestRecoursePlanner.Employee E
ORDER BY T.full_date
  );
    
2021-05-31 09:36:16.364397 (Thread-1): Writing runtime SQL for node "model.resourceplanner.my_first_dbt_model"
2021-05-31 09:36:16.366270 (Thread-1): On model.resourceplanner.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "Bigquery", "target_name": "dev", "node_id": "model.resourceplanner.my_first_dbt_model"} */


  create or replace table `oef-stage`.`TestRecoursePlanner`.`my_first_dbt_model`
  
  
  OPTIONS()
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select M.ID, E.EmployeeID, CU.CustomerID,CO.CompanyID
from oef-stage.TestRecoursePlanner.MainData M
INNER JOIN oef-stage.TestRecoursePlanner.Employee E
ON M.Employee = E.Firstname
INNER JOIN oef-stage.TestRecoursePlanner.Customer CU
ON M.Customer = CU.Customername
INNER JOIN oef-stage.TestRecoursePlanner.Company CO
ON M.Company = CO.Companyname
ORDER BY M.ID

/*
    Uncomment the line below to remove records with null `id` values
*/
  );
    
2021-05-31 09:36:16.367333 (Thread-3): On model.resourceplanner.trydates: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "Bigquery", "target_name": "dev", "node_id": "model.resourceplanner.trydates"} */


  create or replace table `oef-stage`.`TestRecoursePlanner`.`trydates`
  
  
  OPTIONS()
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/


with source_data as (

    select 1 as id
    union all
    select null as id

)

select M.ID, E.EmployeeID, CU.CustomerID,CO.CompanyID, M.DateStart, M.DateEnd, M.Monday, M.Tuesday, M.Wednesday , M.Thursday , M.Friday
from oef-stage.TestRecoursePlanner.MainData M
INNER JOIN oef-stage.TestRecoursePlanner.Employee E
ON M.Employee = E.Firstname
INNER JOIN oef-stage.TestRecoursePlanner.Customer CU
ON M.Customer = CU.Customername
INNER JOIN oef-stage.TestRecoursePlanner.Company CO
ON M.Company = CO.Companyname
ORDER BY M.ID

/*
    Uncomment the line below to remove records with null `id` values
*/
  );
    
2021-05-31 09:36:19.517424 (Thread-2): finished collecting timing info
2021-05-31 09:36:19.517726 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '82a5f573-e309-4e3f-8a25-02e0e5188751', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff4286628e0>]}
2021-05-31 09:36:19.517933 (Thread-2): 11:36:19 | 2 of 4 OK created table model TestRecoursePlanner.EmployeeDates...... [CREATE TABLE (43.8k rows, 57.8 KB processed) in 3.42s]
2021-05-31 09:36:19.518115 (Thread-2): Finished running node model.resourceplanner.EmployeeDates
2021-05-31 09:36:20.147824 (Thread-1): finished collecting timing info
2021-05-31 09:36:20.148147 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '82a5f573-e309-4e3f-8a25-02e0e5188751', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff42861bfd0>]}
2021-05-31 09:36:20.148358 (Thread-1): 11:36:20 | 1 of 4 OK created table model TestRecoursePlanner.my_first_dbt_model. [CREATE TABLE (14.0 rows, 5.4 KB processed) in 4.05s]
2021-05-31 09:36:20.148550 (Thread-1): Finished running node model.resourceplanner.my_first_dbt_model
2021-05-31 09:36:20.148901 (Thread-5): Began running node model.resourceplanner.my_second_dbt_model
2021-05-31 09:36:20.149025 (Thread-5): 11:36:20 | 4 of 4 START view model TestRecoursePlanner.my_second_dbt_model...... [RUN]
2021-05-31 09:36:20.149233 (Thread-5): Acquiring new bigquery connection "model.resourceplanner.my_second_dbt_model".
2021-05-31 09:36:20.149300 (Thread-5): Compiling model.resourceplanner.my_second_dbt_model
2021-05-31 09:36:20.150907 (Thread-5): Writing injected SQL for node "model.resourceplanner.my_second_dbt_model"
2021-05-31 09:36:20.151182 (Thread-5): finished collecting timing info
2021-05-31 09:36:20.162065 (Thread-3): finished collecting timing info
2021-05-31 09:36:20.162608 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '82a5f573-e309-4e3f-8a25-02e0e5188751', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff42bebd280>]}
2021-05-31 09:36:20.162875 (Thread-3): 11:36:20 | 3 of 4 OK created table model TestRecoursePlanner.trydates........... [CREATE TABLE (14.0 rows, 5.4 KB processed) in 4.06s]
2021-05-31 09:36:20.163044 (Thread-3): Finished running node model.resourceplanner.trydates
2021-05-31 09:36:20.171683 (Thread-5): Writing runtime SQL for node "model.resourceplanner.my_second_dbt_model"
2021-05-31 09:36:20.172344 (Thread-5): Opening a new connection, currently in state init
2021-05-31 09:36:20.185151 (Thread-5): On model.resourceplanner.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "Bigquery", "target_name": "dev", "node_id": "model.resourceplanner.my_second_dbt_model"} */


  create or replace view `oef-stage`.`TestRecoursePlanner`.`my_second_dbt_model`
  OPTIONS()
  as -- Use the `ref` function to select from other models

select *
from `oef-stage`.`TestRecoursePlanner`.`my_first_dbt_model`;


2021-05-31 09:36:20.830039 (Thread-5): finished collecting timing info
2021-05-31 09:36:20.830608 (Thread-5): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '82a5f573-e309-4e3f-8a25-02e0e5188751', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff42bea5cd0>]}
2021-05-31 09:36:20.830847 (Thread-5): 11:36:20 | 4 of 4 OK created view model TestRecoursePlanner.my_second_dbt_model. [OK in 0.68s]
2021-05-31 09:36:20.831226 (Thread-5): Finished running node model.resourceplanner.my_second_dbt_model
2021-05-31 09:36:20.832178 (MainThread): Acquiring new bigquery connection "master".
2021-05-31 09:36:20.832345 (MainThread): 11:36:20 | 
2021-05-31 09:36:20.832453 (MainThread): 11:36:20 | Finished running 3 table models, 1 view model in 5.30s.
2021-05-31 09:36:20.832542 (MainThread): Connection 'master' was properly closed.
2021-05-31 09:36:20.832582 (MainThread): Connection 'model.resourceplanner.my_first_dbt_model' was properly closed.
2021-05-31 09:36:20.832615 (MainThread): Connection 'model.resourceplanner.EmployeeDates' was properly closed.
2021-05-31 09:36:20.832705 (MainThread): Connection 'model.resourceplanner.trydates' was properly closed.
2021-05-31 09:36:20.832741 (MainThread): Connection 'model.resourceplanner.my_second_dbt_model' was properly closed.
2021-05-31 09:36:20.833426 (MainThread): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.0.2.15', 46966), raddr=('172.217.168.202', 443)>
2021-05-31 09:36:20.833560 (MainThread): unclosed <socket.socket fd=14, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.0.2.15', 32880), raddr=('216.58.211.106', 443)>
2021-05-31 09:36:20.836815 (MainThread): 
2021-05-31 09:36:20.837006 (MainThread): Completed successfully
2021-05-31 09:36:20.837132 (MainThread): 
Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
2021-05-31 09:36:20.837303 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff42c846340>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff42c884d90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff42c8d45e0>]}
2021-05-31 09:36:20.837441 (MainThread): Flushing usage events
2021-05-31 19:36:50.538792 (MainThread): Running with dbt=0.19.1
2021-05-31 19:36:50.718315 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/home/femke/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-05-31 19:36:50.718944 (MainThread): Tracking: tracking
2021-05-31 19:36:50.730060 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6fe222baf0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6fe3b22250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6fe3b225e0>]}
2021-05-31 19:36:50.748983 (MainThread): Partial parsing not enabled
2021-05-31 19:36:50.749693 (MainThread): Parsing macros/catalog.sql
2021-05-31 19:36:50.757962 (MainThread): Parsing macros/adapters.sql
2021-05-31 19:36:50.774217 (MainThread): Parsing macros/etc.sql
2021-05-31 19:36:50.775571 (MainThread): Parsing macros/materializations/snapshot.sql
2021-05-31 19:36:50.777003 (MainThread): Parsing macros/materializations/copy.sql
2021-05-31 19:36:50.780066 (MainThread): Parsing macros/materializations/table.sql
2021-05-31 19:36:50.786859 (MainThread): Parsing macros/materializations/incremental.sql
2021-05-31 19:36:50.795267 (MainThread): Parsing macros/materializations/view.sql
2021-05-31 19:36:50.797280 (MainThread): Parsing macros/materializations/seed.sql
2021-05-31 19:36:50.799804 (MainThread): Parsing macros/core.sql
2021-05-31 19:36:50.802355 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-05-31 19:36:50.803399 (MainThread): Parsing macros/schema_tests/unique.sql
2021-05-31 19:36:50.804551 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-05-31 19:36:50.805838 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-05-31 19:36:50.807610 (MainThread): Parsing macros/materializations/helpers.sql
2021-05-31 19:36:50.813843 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-05-31 19:36:50.815154 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-05-31 19:36:50.819477 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-05-31 19:36:50.833837 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-05-31 19:36:50.854141 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-05-31 19:36:50.855361 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-05-31 19:36:50.867976 (MainThread): Parsing macros/materializations/table/table.sql
2021-05-31 19:36:50.872467 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-05-31 19:36:50.875810 (MainThread): Parsing macros/materializations/view/view.sql
2021-05-31 19:36:50.880187 (MainThread): Parsing macros/materializations/common/merge.sql
2021-05-31 19:36:50.889681 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-05-31 19:36:50.890783 (MainThread): Parsing macros/etc/query.sql
2021-05-31 19:36:50.891487 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-05-31 19:36:50.892113 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-05-31 19:36:50.893506 (MainThread): Parsing macros/etc/datetime.sql
2021-05-31 19:36:50.899297 (MainThread): Parsing macros/etc/is_incremental.sql
2021-05-31 19:36:50.900423 (MainThread): Parsing macros/adapters/common.sql
2021-05-31 19:36:50.931707 (MainThread): Partial parsing not enabled
2021-05-31 19:36:50.947818 (MainThread): Acquiring new bigquery connection "model.resourceplanner.EmployeeDates".
2021-05-31 19:36:50.954926 (MainThread): Acquiring new bigquery connection "model.resourceplanner.trydates".
2021-05-31 19:36:50.957413 (MainThread): Acquiring new bigquery connection "model.resourceplanner.FactTable".
2021-05-31 19:36:50.959810 (MainThread): Acquiring new bigquery connection "model.resourceplanner.my_second_dbt_model".
2021-05-31 19:36:50.962333 (MainThread): Acquiring new bigquery connection "model.resourceplanner.my_first_dbt_model".
2021-05-31 19:36:51.013086 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'fa2e9402-3bf9-48ba-ba69-1769c777a3dd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6fe1244fa0>]}
2021-05-31 19:36:51.016153 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'fa2e9402-3bf9-48ba-ba69-1769c777a3dd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6fe11ec490>]}
2021-05-31 19:36:51.016307 (MainThread): Found 5 models, 4 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-05-31 19:36:51.017056 (MainThread): 
2021-05-31 19:36:51.017322 (MainThread): Acquiring new bigquery connection "master".
2021-05-31 19:36:51.018023 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_oef-stage".
2021-05-31 19:36:51.018151 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-05-31 19:36:51.130644 (MainThread): Connection 'master' was properly closed.
2021-05-31 19:36:51.130750 (MainThread): Connection 'list_oef-stage' was properly closed.
2021-05-31 19:36:51.130861 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6fe12d6520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6fe11feca0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6fe1244df0>]}
2021-05-31 19:36:51.130986 (MainThread): Flushing usage events
2021-05-31 19:36:51.548818 (MainThread): Encountered an error:
2021-05-31 19:36:51.549224 (MainThread): Runtime Error
  Unable to generate access token, if you're using impersonate_service_account, make sure your initial account has the "roles/iam.serviceAccountTokenCreator" role on the account you are trying to impersonate.
  
  ('invalid_grant: Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.', {'error': 'invalid_grant', 'error_description': 'Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.'})
2021-05-31 19:36:51.551010 (MainThread): Traceback (most recent call last):
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 149, in exception_handler
    yield
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/impl.py", line 203, in query_schemas
    return [ds.dataset_id for ds in all_datasets]
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/impl.py", line 203, in <listcomp>
    return [ds.dataset_id for ds in all_datasets]
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/page_iterator.py", line 212, in _items_iter
    for page in self._page_iter(increment=False):
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/page_iterator.py", line 243, in _page_iter
    page = self._next_page()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/page_iterator.py", line 369, in _next_page
    response = self._get_next_page_response()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/page_iterator.py", line 418, in _get_next_page_response
    return self.api_request(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 369, in api_request
    return self._call_api(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 636, in _call_api
    return call()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/_http.py", line 427, in api_request
    response = self._make_request(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/_http.py", line 291, in _make_request
    return self._do_request(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/_http.py", line 329, in _do_request
    return self.http.request(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/auth/transport/requests.py", line 478, in request
    self.credentials.before_request(auth_request, method, url, request_headers)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/auth/credentials.py", line 133, in before_request
    self.refresh(request)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/oauth2/service_account.py", line 376, in refresh
    access_token, expiry, _ = _client.jwt_grant(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/oauth2/_client.py", line 193, in jwt_grant
    response_data = _token_endpoint_request(request, token_uri, body)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/oauth2/_client.py", line 165, in _token_endpoint_request
    _handle_error_response(response_data)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/oauth2/_client.py", line 60, in _handle_error_response
    raise exceptions.RefreshError(error_details, response_data)
google.auth.exceptions.RefreshError: ('invalid_grant: Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.', {'error': 'invalid_grant', 'error_description': 'Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.'})

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/main.py", line 125, in main
    results, succeeded = handle_and_check(args)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/main.py", line 203, in handle_and_check
    task, res = run_from_args(parsed)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/main.py", line 256, in run_from_args
    results = task.run()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/runnable.py", line 426, in run
    result = self.execute_with_hooks(selected_uids)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/runnable.py", line 383, in execute_with_hooks
    self.before_run(adapter, selected_uids)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/run.py", line 409, in before_run
    self.create_schemas(adapter, selected_uids)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/runnable.py", line 515, in create_schemas
    existing_schemas_lowered.update(ls_future.result())
  File "/usr/lib/python3.8/concurrent/futures/_base.py", line 432, in result
    return self.__get_result()
  File "/usr/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
    raise self._exception
  File "/usr/lib/python3.8/concurrent/futures/thread.py", line 57, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/utils.py", line 469, in connected
    return func(*args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/runnable.py", line 492, in list_schemas
    for s in adapter.list_schemas(database_quoted)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/impl.py", line 205, in list_schemas
    return self.connections._retry_and_handle(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 166, in exception_handler
    raise RuntimeException(message)
dbt.exceptions.RuntimeException: Runtime Error
  Unable to generate access token, if you're using impersonate_service_account, make sure your initial account has the "roles/iam.serviceAccountTokenCreator" role on the account you are trying to impersonate.
  
  ('invalid_grant: Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.', {'error': 'invalid_grant', 'error_description': 'Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.'})

2021-05-31 19:41:16.539912 (MainThread): Running with dbt=0.19.1
2021-05-31 19:41:16.723513 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/home/femke/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-05-31 19:41:16.724153 (MainThread): Tracking: tracking
2021-05-31 19:41:16.734515 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f42120fef70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f421217e490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f42121114c0>]}
2021-05-31 19:41:16.749895 (MainThread): Partial parsing not enabled
2021-05-31 19:41:16.750708 (MainThread): Parsing macros/catalog.sql
2021-05-31 19:41:16.759070 (MainThread): Parsing macros/adapters.sql
2021-05-31 19:41:16.780534 (MainThread): Parsing macros/etc.sql
2021-05-31 19:41:16.782044 (MainThread): Parsing macros/materializations/snapshot.sql
2021-05-31 19:41:16.783252 (MainThread): Parsing macros/materializations/copy.sql
2021-05-31 19:41:16.786449 (MainThread): Parsing macros/materializations/table.sql
2021-05-31 19:41:16.793680 (MainThread): Parsing macros/materializations/incremental.sql
2021-05-31 19:41:16.802505 (MainThread): Parsing macros/materializations/view.sql
2021-05-31 19:41:16.804474 (MainThread): Parsing macros/materializations/seed.sql
2021-05-31 19:41:16.806833 (MainThread): Parsing macros/core.sql
2021-05-31 19:41:16.809466 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-05-31 19:41:16.810484 (MainThread): Parsing macros/schema_tests/unique.sql
2021-05-31 19:41:16.811661 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-05-31 19:41:16.812965 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-05-31 19:41:16.814811 (MainThread): Parsing macros/materializations/helpers.sql
2021-05-31 19:41:16.820671 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-05-31 19:41:16.821917 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-05-31 19:41:16.826218 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-05-31 19:41:16.840698 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-05-31 19:41:16.861020 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-05-31 19:41:16.862191 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-05-31 19:41:16.874547 (MainThread): Parsing macros/materializations/table/table.sql
2021-05-31 19:41:16.884372 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-05-31 19:41:16.887947 (MainThread): Parsing macros/materializations/view/view.sql
2021-05-31 19:41:16.892960 (MainThread): Parsing macros/materializations/common/merge.sql
2021-05-31 19:41:16.902105 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-05-31 19:41:16.903270 (MainThread): Parsing macros/etc/query.sql
2021-05-31 19:41:16.903949 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-05-31 19:41:16.904575 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-05-31 19:41:16.906180 (MainThread): Parsing macros/etc/datetime.sql
2021-05-31 19:41:16.912218 (MainThread): Parsing macros/etc/is_incremental.sql
2021-05-31 19:41:16.913397 (MainThread): Parsing macros/adapters/common.sql
2021-05-31 19:41:16.945490 (MainThread): Partial parsing not enabled
2021-05-31 19:41:16.963067 (MainThread): Acquiring new bigquery connection "model.resourceplanner.EmployeeDates".
2021-05-31 19:41:16.970290 (MainThread): Acquiring new bigquery connection "model.resourceplanner.trydates".
2021-05-31 19:41:16.972716 (MainThread): Acquiring new bigquery connection "model.resourceplanner.FactTable".
2021-05-31 19:41:16.975326 (MainThread): Acquiring new bigquery connection "model.resourceplanner.my_second_dbt_model".
2021-05-31 19:41:16.977689 (MainThread): Acquiring new bigquery connection "model.resourceplanner.my_first_dbt_model".
2021-05-31 19:41:17.023689 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '66f39114-3b52-4ca2-a184-9808dc210398', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f420f81c310>]}
2021-05-31 19:41:17.027110 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '66f39114-3b52-4ca2-a184-9808dc210398', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f420f810ee0>]}
2021-05-31 19:41:17.027304 (MainThread): Found 5 models, 4 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-05-31 19:41:17.028019 (MainThread): 
2021-05-31 19:41:17.028267 (MainThread): Acquiring new bigquery connection "master".
2021-05-31 19:41:17.029025 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_oef-stage".
2021-05-31 19:41:17.029154 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-05-31 19:41:17.115305 (MainThread): Connection 'master' was properly closed.
2021-05-31 19:41:17.115427 (MainThread): Connection 'list_oef-stage' was properly closed.
2021-05-31 19:41:17.115573 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f420f9073a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f420f7ddf40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f420f939f70>]}
2021-05-31 19:41:17.115737 (MainThread): Flushing usage events
2021-05-31 19:41:17.543693 (MainThread): Encountered an error:
2021-05-31 19:41:17.544400 (MainThread): Runtime Error
  Unable to generate access token, if you're using impersonate_service_account, make sure your initial account has the "roles/iam.serviceAccountTokenCreator" role on the account you are trying to impersonate.
  
  ('invalid_grant: Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.', {'error': 'invalid_grant', 'error_description': 'Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.'})
2021-05-31 19:41:17.546432 (MainThread): Traceback (most recent call last):
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 149, in exception_handler
    yield
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/impl.py", line 203, in query_schemas
    return [ds.dataset_id for ds in all_datasets]
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/impl.py", line 203, in <listcomp>
    return [ds.dataset_id for ds in all_datasets]
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/page_iterator.py", line 212, in _items_iter
    for page in self._page_iter(increment=False):
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/page_iterator.py", line 243, in _page_iter
    page = self._next_page()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/page_iterator.py", line 369, in _next_page
    response = self._get_next_page_response()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/page_iterator.py", line 418, in _get_next_page_response
    return self.api_request(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 369, in api_request
    return self._call_api(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 636, in _call_api
    return call()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/_http.py", line 427, in api_request
    response = self._make_request(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/_http.py", line 291, in _make_request
    return self._do_request(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/_http.py", line 329, in _do_request
    return self.http.request(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/auth/transport/requests.py", line 478, in request
    self.credentials.before_request(auth_request, method, url, request_headers)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/auth/credentials.py", line 133, in before_request
    self.refresh(request)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/oauth2/service_account.py", line 376, in refresh
    access_token, expiry, _ = _client.jwt_grant(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/oauth2/_client.py", line 193, in jwt_grant
    response_data = _token_endpoint_request(request, token_uri, body)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/oauth2/_client.py", line 165, in _token_endpoint_request
    _handle_error_response(response_data)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/oauth2/_client.py", line 60, in _handle_error_response
    raise exceptions.RefreshError(error_details, response_data)
google.auth.exceptions.RefreshError: ('invalid_grant: Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.', {'error': 'invalid_grant', 'error_description': 'Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.'})

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/main.py", line 125, in main
    results, succeeded = handle_and_check(args)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/main.py", line 203, in handle_and_check
    task, res = run_from_args(parsed)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/main.py", line 256, in run_from_args
    results = task.run()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/runnable.py", line 426, in run
    result = self.execute_with_hooks(selected_uids)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/runnable.py", line 383, in execute_with_hooks
    self.before_run(adapter, selected_uids)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/run.py", line 409, in before_run
    self.create_schemas(adapter, selected_uids)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/runnable.py", line 515, in create_schemas
    existing_schemas_lowered.update(ls_future.result())
  File "/usr/lib/python3.8/concurrent/futures/_base.py", line 432, in result
    return self.__get_result()
  File "/usr/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
    raise self._exception
  File "/usr/lib/python3.8/concurrent/futures/thread.py", line 57, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/utils.py", line 469, in connected
    return func(*args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/runnable.py", line 492, in list_schemas
    for s in adapter.list_schemas(database_quoted)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/impl.py", line 205, in list_schemas
    return self.connections._retry_and_handle(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 166, in exception_handler
    raise RuntimeException(message)
dbt.exceptions.RuntimeException: Runtime Error
  Unable to generate access token, if you're using impersonate_service_account, make sure your initial account has the "roles/iam.serviceAccountTokenCreator" role on the account you are trying to impersonate.
  
  ('invalid_grant: Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.', {'error': 'invalid_grant', 'error_description': 'Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.'})

2021-06-01 10:49:51.374270 (MainThread): Running with dbt=0.19.1
2021-06-01 10:49:51.552956 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/home/femke/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-06-01 10:49:51.553559 (MainThread): Tracking: tracking
2021-06-01 10:49:51.563876 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2eadec5a00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2eaf7f9190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2eaf7f94f0>]}
2021-06-01 10:49:51.574448 (MainThread): Partial parsing not enabled
2021-06-01 10:49:51.575100 (MainThread): Parsing macros/catalog.sql
2021-06-01 10:49:51.588383 (MainThread): Parsing macros/adapters.sql
2021-06-01 10:49:51.608954 (MainThread): Parsing macros/etc.sql
2021-06-01 10:49:51.610412 (MainThread): Parsing macros/materializations/snapshot.sql
2021-06-01 10:49:51.611693 (MainThread): Parsing macros/materializations/copy.sql
2021-06-01 10:49:51.614759 (MainThread): Parsing macros/materializations/table.sql
2021-06-01 10:49:51.621769 (MainThread): Parsing macros/materializations/incremental.sql
2021-06-01 10:49:51.630624 (MainThread): Parsing macros/materializations/view.sql
2021-06-01 10:49:51.632589 (MainThread): Parsing macros/materializations/seed.sql
2021-06-01 10:49:51.635044 (MainThread): Parsing macros/core.sql
2021-06-01 10:49:51.637675 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-06-01 10:49:51.638718 (MainThread): Parsing macros/schema_tests/unique.sql
2021-06-01 10:49:51.639964 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-06-01 10:49:51.641280 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-06-01 10:49:51.643121 (MainThread): Parsing macros/materializations/helpers.sql
2021-06-01 10:49:51.649428 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-06-01 10:49:51.650767 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-06-01 10:49:51.655289 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-06-01 10:49:51.669313 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-06-01 10:49:51.689741 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-06-01 10:49:51.690995 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-06-01 10:49:51.703729 (MainThread): Parsing macros/materializations/table/table.sql
2021-06-01 10:49:51.708384 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-06-01 10:49:51.711874 (MainThread): Parsing macros/materializations/view/view.sql
2021-06-01 10:49:51.716417 (MainThread): Parsing macros/materializations/common/merge.sql
2021-06-01 10:49:51.725941 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-06-01 10:49:51.727115 (MainThread): Parsing macros/etc/query.sql
2021-06-01 10:49:51.727829 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-06-01 10:49:51.728451 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-06-01 10:49:51.729882 (MainThread): Parsing macros/etc/datetime.sql
2021-06-01 10:49:51.735876 (MainThread): Parsing macros/etc/is_incremental.sql
2021-06-01 10:49:51.737006 (MainThread): Parsing macros/adapters/common.sql
2021-06-01 10:49:51.768293 (MainThread): Partial parsing not enabled
2021-06-01 10:49:51.784190 (MainThread): Acquiring new bigquery connection "model.resourceplanner.EmployeeDates".
2021-06-01 10:49:51.790941 (MainThread): Acquiring new bigquery connection "model.resourceplanner.trydates".
2021-06-01 10:49:51.793272 (MainThread): Acquiring new bigquery connection "model.resourceplanner.FactTable".
2021-06-01 10:49:51.795632 (MainThread): Acquiring new bigquery connection "model.resourceplanner.my_second_dbt_model".
2021-06-01 10:49:51.797967 (MainThread): Acquiring new bigquery connection "model.resourceplanner.my_first_dbt_model".
2021-06-01 10:49:51.843007 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '576bc1ad-cd9c-4ae9-ac9e-c058741eb0aa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2eacf04700>]}
2021-06-01 10:49:51.845955 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '576bc1ad-cd9c-4ae9-ac9e-c058741eb0aa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ead0e9850>]}
2021-06-01 10:49:51.846093 (MainThread): Found 5 models, 4 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-06-01 10:49:51.846767 (MainThread): 
2021-06-01 10:49:51.846992 (MainThread): Acquiring new bigquery connection "master".
2021-06-01 10:49:51.847678 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_oef-stage".
2021-06-01 10:49:51.847799 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-06-01 10:49:52.247073 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_oef-stage_TestRecoursePlanner".
2021-06-01 10:49:52.247248 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2021-06-01 10:49:52.250441 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-06-01 10:49:52.460595 (MainThread): 12:49:52 | Concurrency: 5 threads (target='dev')
2021-06-01 10:49:52.460845 (MainThread): 12:49:52 | 
2021-06-01 10:49:52.462579 (Thread-1): Began running node model.resourceplanner.my_first_dbt_model
2021-06-01 10:49:52.462763 (Thread-1): 12:49:52 | 1 of 5 START table model TestRecoursePlanner.my_first_dbt_model...... [RUN]
2021-06-01 10:49:52.462874 (Thread-2): Began running node model.resourceplanner.EmployeeDates
2021-06-01 10:49:52.463064 (Thread-2): 12:49:52 | 2 of 5 START table model TestRecoursePlanner.EmployeeDates........... [RUN]
2021-06-01 10:49:52.463133 (Thread-3): Began running node model.resourceplanner.FactTable
2021-06-01 10:49:52.463231 (Thread-3): 12:49:52 | 3 of 5 START table model TestRecoursePlanner.FactTable............... [RUN]
2021-06-01 10:49:52.463292 (Thread-4): Began running node model.resourceplanner.trydates
2021-06-01 10:49:52.463386 (Thread-4): 12:49:52 | 4 of 5 START table model TestRecoursePlanner.trydates................ [RUN]
2021-06-01 10:49:52.463604 (Thread-1): Acquiring new bigquery connection "model.resourceplanner.my_first_dbt_model".
2021-06-01 10:49:52.463680 (Thread-1): Compiling model.resourceplanner.my_first_dbt_model
2021-06-01 10:49:52.465394 (Thread-1): Writing injected SQL for node "model.resourceplanner.my_first_dbt_model"
2021-06-01 10:49:52.465631 (Thread-1): finished collecting timing info
2021-06-01 10:49:52.465922 (Thread-2): Acquiring new bigquery connection "model.resourceplanner.EmployeeDates".
2021-06-01 10:49:52.470124 (Thread-2): Compiling model.resourceplanner.EmployeeDates
2021-06-01 10:49:52.466093 (Thread-3): Acquiring new bigquery connection "model.resourceplanner.FactTable".
2021-06-01 10:49:52.472426 (Thread-3): Compiling model.resourceplanner.FactTable
2021-06-01 10:49:52.466252 (Thread-4): Acquiring new bigquery connection "model.resourceplanner.trydates".
2021-06-01 10:49:52.483562 (Thread-4): Compiling model.resourceplanner.trydates
2021-06-01 10:49:52.484864 (Thread-4): Writing injected SQL for node "model.resourceplanner.trydates"
2021-06-01 10:49:52.472316 (Thread-2): Writing injected SQL for node "model.resourceplanner.EmployeeDates"
2021-06-01 10:49:52.485306 (Thread-1): unclosed <socket.socket fd=5, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.0.2.15', 55416), raddr=('172.217.17.106', 443)>
2021-06-01 10:49:52.485642 (Thread-1): unclosed <socket.socket fd=6, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.0.2.15', 51950), raddr=('172.217.168.234', 443)>
2021-06-01 10:49:52.485487 (Thread-2): finished collecting timing info
2021-06-01 10:49:52.485169 (Thread-4): finished collecting timing info
2021-06-01 10:49:52.483418 (Thread-3): Writing injected SQL for node "model.resourceplanner.FactTable"
2021-06-01 10:49:52.532689 (Thread-3): finished collecting timing info
2021-06-01 10:49:52.518498 (Thread-1): Opening a new connection, currently in state closed
2021-06-01 10:49:52.526410 (Thread-4): Opening a new connection, currently in state init
2021-06-01 10:49:52.545600 (Thread-4): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-06-01 10:49:52.532406 (Thread-2): Opening a new connection, currently in state closed
2021-06-01 10:49:52.549424 (Thread-2): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-06-01 10:49:52.551258 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-06-01 10:49:52.564254 (Thread-3): Writing runtime SQL for node "model.resourceplanner.FactTable"
2021-06-01 10:49:52.564529 (Thread-3): Opening a new connection, currently in state init
2021-06-01 10:49:52.567656 (Thread-3): On model.resourceplanner.FactTable: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "Bigquery", "target_name": "dev", "node_id": "model.resourceplanner.FactTable"} */


  create or replace table `oef-stage`.`TestRecoursePlanner`.`FactTable`
  
  
  OPTIONS()
  as (
    


SELECT
  T.id,
  TD.ID AS ProjectID,
  TD.EmployeeID,
  TD.CompanyID,
  T.PM_AM,
  T.full_date,
  T.day_name,
  CASE
    WHEN T.day_name = "Monday" THEN IF (TD.Monday = 'Available', '0', IF (TD.Monday = 'Full', '0,5', IF (PM_AM = TD.Monday, '0,5', '0') ))
    WHEN T.day_name = "Tuesday" THEN IF (TD.Tuesday = 'Available', '0', IF (TD.Tuesday = 'Full', '0,5', IF (PM_AM = TD.Tuesday, '0,5', '0') ))
    WHEN T.day_name = "Wednesday" THEN IF (TD.Wednesday = 'Available', '0', IF (TD.Wednesday = 'Full', '0,5', IF (PM_AM = TD.Wednesday, '0,5', '0') ))
    WHEN T.day_name = "Thursday" THEN IF (TD.Thursday = 'Available', '0', IF (TD.Thursday = 'Full', '0,5', IF (PM_AM = TD.Thursday, '0,5', '0') ))
    WHEN T.day_name = "Friday" THEN IF (TD.Friday = 'Available', '0', IF (TD.Friday  = 'Full', '0,5', IF (PM_AM = TD.Friday , '0,5', '0') ))
  ELSE
  '0'
END
  AS Is_Booked,
  DATE_DIFF( DateEnd, DateStart,DAY)AS Duration
FROM
  `oef-stage.TestRecoursePlanner.Time` T
CROSS JOIN
  `oef-stage.TestRecoursePlanner.trydates` TD

WHERE T.full_Date  BETWEEN TD.DateStart
  AND TD.DateEnd
ORDER BY
  T.full_date
  );
    
2021-06-01 10:49:52.767576 (Thread-2): Writing runtime SQL for node "model.resourceplanner.EmployeeDates"
2021-06-01 10:49:52.768127 (Thread-2): On model.resourceplanner.EmployeeDates: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "Bigquery", "target_name": "dev", "node_id": "model.resourceplanner.EmployeeDates"} */


  create or replace table `oef-stage`.`TestRecoursePlanner`.`EmployeeDates`
  
  
  OPTIONS()
  as (
    

SELECT DISTINCT E.EmployeeID, T.full_date
FROM oef-stage.TestRecoursePlanner.Time T
CROSS JOIN oef-stage.TestRecoursePlanner.Employee E
ORDER BY T.full_date
  );
    
2021-06-01 10:49:52.770070 (Thread-4): Writing runtime SQL for node "model.resourceplanner.trydates"
2021-06-01 10:49:52.770297 (Thread-4): On model.resourceplanner.trydates: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "Bigquery", "target_name": "dev", "node_id": "model.resourceplanner.trydates"} */


  create or replace table `oef-stage`.`TestRecoursePlanner`.`trydates`
  
  
  OPTIONS()
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/


with source_data as (

    select 1 as id
    union all
    select null as id

)

select M.ID, E.EmployeeID, CU.CustomerID,CO.CompanyID, M.DateStart, M.DateEnd, M.Monday, M.Tuesday, M.Wednesday , M.Thursday , M.Friday
from oef-stage.TestRecoursePlanner.MainData M
INNER JOIN oef-stage.TestRecoursePlanner.Employee E
ON M.Employee = E.Firstname
INNER JOIN oef-stage.TestRecoursePlanner.Customer CU
ON M.Customer = CU.Customername
INNER JOIN oef-stage.TestRecoursePlanner.Company CO
ON M.Company = CO.Companyname
ORDER BY M.ID

/*
    Uncomment the line below to remove records with null `id` values
*/
  );
    
2021-06-01 10:49:52.784728 (Thread-1): Writing runtime SQL for node "model.resourceplanner.my_first_dbt_model"
2021-06-01 10:49:52.785090 (Thread-1): On model.resourceplanner.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "Bigquery", "target_name": "dev", "node_id": "model.resourceplanner.my_first_dbt_model"} */


  create or replace table `oef-stage`.`TestRecoursePlanner`.`my_first_dbt_model`
  
  
  OPTIONS()
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select M.ID, E.EmployeeID, CU.CustomerID,CO.CompanyID
from oef-stage.TestRecoursePlanner.MainData M
INNER JOIN oef-stage.TestRecoursePlanner.Employee E
ON M.Employee = E.Firstname
INNER JOIN oef-stage.TestRecoursePlanner.Customer CU
ON M.Customer = CU.Customername
INNER JOIN oef-stage.TestRecoursePlanner.Company CO
ON M.Company = CO.Companyname
ORDER BY M.ID

/*
    Uncomment the line below to remove records with null `id` values
*/
  );
    
2021-06-01 10:49:54.483435 (Thread-3): finished collecting timing info
2021-06-01 10:49:54.483735 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '576bc1ad-cd9c-4ae9-ac9e-c058741eb0aa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2eac53dfd0>]}
2021-06-01 10:49:54.483955 (Thread-3): 12:49:54 | 3 of 5 OK created table model TestRecoursePlanner.FactTable.......... [CREATE TABLE (992.0 rows, 251.6 KB processed) in 2.02s]
2021-06-01 10:49:54.484132 (Thread-3): Finished running node model.resourceplanner.FactTable
2021-06-01 10:49:55.991102 (Thread-2): finished collecting timing info
2021-06-01 10:49:55.991426 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '576bc1ad-cd9c-4ae9-ac9e-c058741eb0aa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2eac5841f0>]}
2021-06-01 10:49:55.991625 (Thread-2): 12:49:55 | 2 of 5 OK created table model TestRecoursePlanner.EmployeeDates...... [CREATE TABLE (43.8k rows, 57.8 KB processed) in 3.53s]
2021-06-01 10:49:55.991798 (Thread-2): Finished running node model.resourceplanner.EmployeeDates
2021-06-01 10:49:57.220229 (Thread-1): finished collecting timing info
2021-06-01 10:49:57.220558 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '576bc1ad-cd9c-4ae9-ac9e-c058741eb0aa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2eac573430>]}
2021-06-01 10:49:57.220757 (Thread-1): 12:49:57 | 1 of 5 OK created table model TestRecoursePlanner.my_first_dbt_model. [CREATE TABLE (14.0 rows, 5.4 KB processed) in 4.76s]
2021-06-01 10:49:57.220929 (Thread-1): Finished running node model.resourceplanner.my_first_dbt_model
2021-06-01 10:49:57.221144 (Thread-5): Began running node model.resourceplanner.my_second_dbt_model
2021-06-01 10:49:57.221258 (Thread-5): 12:49:57 | 5 of 5 START view model TestRecoursePlanner.my_second_dbt_model...... [RUN]
2021-06-01 10:49:57.221725 (Thread-5): Acquiring new bigquery connection "model.resourceplanner.my_second_dbt_model".
2021-06-01 10:49:57.221791 (Thread-5): Compiling model.resourceplanner.my_second_dbt_model
2021-06-01 10:49:57.223220 (Thread-5): Writing injected SQL for node "model.resourceplanner.my_second_dbt_model"
2021-06-01 10:49:57.223693 (Thread-5): finished collecting timing info
2021-06-01 10:49:57.238275 (Thread-5): Writing runtime SQL for node "model.resourceplanner.my_second_dbt_model"
2021-06-01 10:49:57.238716 (Thread-5): Opening a new connection, currently in state init
2021-06-01 10:49:57.242080 (Thread-5): On model.resourceplanner.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "Bigquery", "target_name": "dev", "node_id": "model.resourceplanner.my_second_dbt_model"} */


  create or replace view `oef-stage`.`TestRecoursePlanner`.`my_second_dbt_model`
  OPTIONS()
  as -- Use the `ref` function to select from other models

select *
from `oef-stage`.`TestRecoursePlanner`.`my_first_dbt_model`;


2021-06-01 10:49:57.282632 (Thread-4): finished collecting timing info
2021-06-01 10:49:57.282924 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '576bc1ad-cd9c-4ae9-ac9e-c058741eb0aa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2eac4ef1c0>]}
2021-06-01 10:49:57.283180 (Thread-4): 12:49:57 | 4 of 5 OK created table model TestRecoursePlanner.trydates........... [CREATE TABLE (14.0 rows, 5.4 KB processed) in 4.82s]
2021-06-01 10:49:57.283336 (Thread-4): Finished running node model.resourceplanner.trydates
2021-06-01 10:49:57.900739 (Thread-5): finished collecting timing info
2021-06-01 10:49:57.901033 (Thread-5): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '576bc1ad-cd9c-4ae9-ac9e-c058741eb0aa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2eac584ca0>]}
2021-06-01 10:49:57.901235 (Thread-5): 12:49:57 | 5 of 5 OK created view model TestRecoursePlanner.my_second_dbt_model. [OK in 0.68s]
2021-06-01 10:49:57.901417 (Thread-5): Finished running node model.resourceplanner.my_second_dbt_model
2021-06-01 10:49:57.902305 (MainThread): Acquiring new bigquery connection "master".
2021-06-01 10:49:57.902467 (MainThread): 12:49:57 | 
2021-06-01 10:49:57.902567 (MainThread): 12:49:57 | Finished running 4 table models, 1 view model in 6.06s.
2021-06-01 10:49:57.902653 (MainThread): Connection 'master' was properly closed.
2021-06-01 10:49:57.902693 (MainThread): Connection 'model.resourceplanner.my_first_dbt_model' was properly closed.
2021-06-01 10:49:57.902725 (MainThread): Connection 'model.resourceplanner.EmployeeDates' was properly closed.
2021-06-01 10:49:57.902754 (MainThread): Connection 'model.resourceplanner.FactTable' was properly closed.
2021-06-01 10:49:57.902784 (MainThread): Connection 'model.resourceplanner.trydates' was properly closed.
2021-06-01 10:49:57.902813 (MainThread): Connection 'model.resourceplanner.my_second_dbt_model' was properly closed.
2021-06-01 10:49:57.905717 (MainThread): 
2021-06-01 10:49:57.905823 (MainThread): Completed successfully
2021-06-01 10:49:57.905944 (MainThread): 
Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
2021-06-01 10:49:57.906089 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2eacf0db20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2eacef0b50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2eacef0eb0>]}
2021-06-01 10:49:57.906196 (MainThread): Flushing usage events
2021-06-01 16:29:31.837435 (MainThread): Running with dbt=0.19.1
2021-06-01 16:29:32.012789 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/home/femke/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-06-01 16:29:32.013475 (MainThread): Tracking: tracking
2021-06-01 16:29:32.023843 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb70dde4cd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb70f719130>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb70f719520>]}
2021-06-01 16:29:32.039429 (MainThread): Partial parsing not enabled
2021-06-01 16:29:32.040161 (MainThread): Parsing macros/catalog.sql
2021-06-01 16:29:32.047906 (MainThread): Parsing macros/adapters.sql
2021-06-01 16:29:32.068526 (MainThread): Parsing macros/etc.sql
2021-06-01 16:29:32.069985 (MainThread): Parsing macros/materializations/snapshot.sql
2021-06-01 16:29:32.071214 (MainThread): Parsing macros/materializations/copy.sql
2021-06-01 16:29:32.074328 (MainThread): Parsing macros/materializations/table.sql
2021-06-01 16:29:32.081342 (MainThread): Parsing macros/materializations/incremental.sql
2021-06-01 16:29:32.090003 (MainThread): Parsing macros/materializations/view.sql
2021-06-01 16:29:32.091937 (MainThread): Parsing macros/materializations/seed.sql
2021-06-01 16:29:32.094370 (MainThread): Parsing macros/core.sql
2021-06-01 16:29:32.097014 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-06-01 16:29:32.098040 (MainThread): Parsing macros/schema_tests/unique.sql
2021-06-01 16:29:32.099225 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-06-01 16:29:32.100465 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-06-01 16:29:32.102314 (MainThread): Parsing macros/materializations/helpers.sql
2021-06-01 16:29:32.108385 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-06-01 16:29:32.109624 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-06-01 16:29:32.114109 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-06-01 16:29:32.128087 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-06-01 16:29:32.148895 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-06-01 16:29:32.150127 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-06-01 16:29:32.162455 (MainThread): Parsing macros/materializations/table/table.sql
2021-06-01 16:29:32.167067 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-06-01 16:29:32.170558 (MainThread): Parsing macros/materializations/view/view.sql
2021-06-01 16:29:32.175115 (MainThread): Parsing macros/materializations/common/merge.sql
2021-06-01 16:29:32.184143 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-06-01 16:29:32.185248 (MainThread): Parsing macros/etc/query.sql
2021-06-01 16:29:32.185920 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-06-01 16:29:32.186548 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-06-01 16:29:32.188017 (MainThread): Parsing macros/etc/datetime.sql
2021-06-01 16:29:32.193880 (MainThread): Parsing macros/etc/is_incremental.sql
2021-06-01 16:29:32.195011 (MainThread): Parsing macros/adapters/common.sql
2021-06-01 16:29:32.226108 (MainThread): Partial parsing not enabled
2021-06-01 16:29:32.242490 (MainThread): Acquiring new bigquery connection "model.resourceplanner.EmployeeDates".
2021-06-01 16:29:32.249265 (MainThread): Acquiring new bigquery connection "model.resourceplanner.trydates".
2021-06-01 16:29:32.252847 (MainThread): Acquiring new bigquery connection "model.resourceplanner.FactTable".
2021-06-01 16:29:32.255936 (MainThread): Acquiring new bigquery connection "model.resourceplanner.my_second_dbt_model".
2021-06-01 16:29:32.258383 (MainThread): Acquiring new bigquery connection "model.resourceplanner.my_first_dbt_model".
2021-06-01 16:29:32.303721 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '4d1537da-1cc3-4140-b4d1-80d26d63c307', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb70ce23760>]}
2021-06-01 16:29:32.313347 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '4d1537da-1cc3-4140-b4d1-80d26d63c307', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb70ce18fa0>]}
2021-06-01 16:29:32.313524 (MainThread): Found 5 models, 4 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-06-01 16:29:32.314245 (MainThread): 
2021-06-01 16:29:32.314490 (MainThread): Acquiring new bigquery connection "master".
2021-06-01 16:29:32.315194 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_oef-stage".
2021-06-01 16:29:32.315318 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-06-01 16:29:32.428629 (MainThread): Connection 'master' was properly closed.
2021-06-01 16:29:32.428750 (MainThread): Connection 'list_oef-stage' was properly closed.
2021-06-01 16:29:32.428866 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb70cf0c460>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb70cdc13d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb70cdf07c0>]}
2021-06-01 16:29:32.429019 (MainThread): Flushing usage events
2021-06-01 16:29:32.851168 (MainThread): Encountered an error:
2021-06-01 16:29:32.851558 (MainThread): Runtime Error
  Unable to generate access token, if you're using impersonate_service_account, make sure your initial account has the "roles/iam.serviceAccountTokenCreator" role on the account you are trying to impersonate.
  
  ('invalid_grant: Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.', {'error': 'invalid_grant', 'error_description': 'Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.'})
2021-06-01 16:29:32.853285 (MainThread): Traceback (most recent call last):
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 149, in exception_handler
    yield
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/impl.py", line 203, in query_schemas
    return [ds.dataset_id for ds in all_datasets]
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/impl.py", line 203, in <listcomp>
    return [ds.dataset_id for ds in all_datasets]
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/page_iterator.py", line 212, in _items_iter
    for page in self._page_iter(increment=False):
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/page_iterator.py", line 243, in _page_iter
    page = self._next_page()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/page_iterator.py", line 369, in _next_page
    response = self._get_next_page_response()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/page_iterator.py", line 418, in _get_next_page_response
    return self.api_request(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 369, in api_request
    return self._call_api(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 636, in _call_api
    return call()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/_http.py", line 427, in api_request
    response = self._make_request(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/_http.py", line 291, in _make_request
    return self._do_request(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/_http.py", line 329, in _do_request
    return self.http.request(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/auth/transport/requests.py", line 478, in request
    self.credentials.before_request(auth_request, method, url, request_headers)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/auth/credentials.py", line 133, in before_request
    self.refresh(request)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/oauth2/service_account.py", line 376, in refresh
    access_token, expiry, _ = _client.jwt_grant(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/oauth2/_client.py", line 193, in jwt_grant
    response_data = _token_endpoint_request(request, token_uri, body)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/oauth2/_client.py", line 165, in _token_endpoint_request
    _handle_error_response(response_data)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/oauth2/_client.py", line 60, in _handle_error_response
    raise exceptions.RefreshError(error_details, response_data)
google.auth.exceptions.RefreshError: ('invalid_grant: Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.', {'error': 'invalid_grant', 'error_description': 'Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.'})

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/main.py", line 125, in main
    results, succeeded = handle_and_check(args)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/main.py", line 203, in handle_and_check
    task, res = run_from_args(parsed)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/main.py", line 256, in run_from_args
    results = task.run()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/runnable.py", line 426, in run
    result = self.execute_with_hooks(selected_uids)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/runnable.py", line 383, in execute_with_hooks
    self.before_run(adapter, selected_uids)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/run.py", line 409, in before_run
    self.create_schemas(adapter, selected_uids)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/runnable.py", line 515, in create_schemas
    existing_schemas_lowered.update(ls_future.result())
  File "/usr/lib/python3.8/concurrent/futures/_base.py", line 432, in result
    return self.__get_result()
  File "/usr/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
    raise self._exception
  File "/usr/lib/python3.8/concurrent/futures/thread.py", line 57, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/utils.py", line 469, in connected
    return func(*args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/runnable.py", line 492, in list_schemas
    for s in adapter.list_schemas(database_quoted)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/impl.py", line 205, in list_schemas
    return self.connections._retry_and_handle(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 166, in exception_handler
    raise RuntimeException(message)
dbt.exceptions.RuntimeException: Runtime Error
  Unable to generate access token, if you're using impersonate_service_account, make sure your initial account has the "roles/iam.serviceAccountTokenCreator" role on the account you are trying to impersonate.
  
  ('invalid_grant: Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.', {'error': 'invalid_grant', 'error_description': 'Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.'})

2021-06-01 16:29:39.291759 (MainThread): Running with dbt=0.19.1
2021-06-01 16:29:39.473419 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/home/femke/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-06-01 16:29:39.474156 (MainThread): Tracking: tracking
2021-06-01 16:29:39.484493 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4e42355af0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4e43c0c280>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4e43c0c5e0>]}
2021-06-01 16:29:39.500750 (MainThread): Partial parsing not enabled
2021-06-01 16:29:39.501488 (MainThread): Parsing macros/catalog.sql
2021-06-01 16:29:39.509650 (MainThread): Parsing macros/adapters.sql
2021-06-01 16:29:39.533328 (MainThread): Parsing macros/etc.sql
2021-06-01 16:29:39.534757 (MainThread): Parsing macros/materializations/snapshot.sql
2021-06-01 16:29:39.536032 (MainThread): Parsing macros/materializations/copy.sql
2021-06-01 16:29:39.539189 (MainThread): Parsing macros/materializations/table.sql
2021-06-01 16:29:39.546314 (MainThread): Parsing macros/materializations/incremental.sql
2021-06-01 16:29:39.555231 (MainThread): Parsing macros/materializations/view.sql
2021-06-01 16:29:39.557235 (MainThread): Parsing macros/materializations/seed.sql
2021-06-01 16:29:39.559583 (MainThread): Parsing macros/core.sql
2021-06-01 16:29:39.562167 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-06-01 16:29:39.563209 (MainThread): Parsing macros/schema_tests/unique.sql
2021-06-01 16:29:39.564308 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-06-01 16:29:39.565541 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-06-01 16:29:39.567339 (MainThread): Parsing macros/materializations/helpers.sql
2021-06-01 16:29:39.573115 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-06-01 16:29:39.574353 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-06-01 16:29:39.578598 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-06-01 16:29:39.592272 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-06-01 16:29:39.612108 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-06-01 16:29:39.613295 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-06-01 16:29:39.625429 (MainThread): Parsing macros/materializations/table/table.sql
2021-06-01 16:29:39.629808 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-06-01 16:29:39.633106 (MainThread): Parsing macros/materializations/view/view.sql
2021-06-01 16:29:39.637332 (MainThread): Parsing macros/materializations/common/merge.sql
2021-06-01 16:29:39.646295 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-06-01 16:29:39.647434 (MainThread): Parsing macros/etc/query.sql
2021-06-01 16:29:39.648126 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-06-01 16:29:39.648742 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-06-01 16:29:39.650112 (MainThread): Parsing macros/etc/datetime.sql
2021-06-01 16:29:39.655832 (MainThread): Parsing macros/etc/is_incremental.sql
2021-06-01 16:29:39.656910 (MainThread): Parsing macros/adapters/common.sql
2021-06-01 16:29:39.687287 (MainThread): Partial parsing not enabled
2021-06-01 16:29:39.703130 (MainThread): Acquiring new bigquery connection "model.resourceplanner.EmployeeDates".
2021-06-01 16:29:39.709793 (MainThread): Acquiring new bigquery connection "model.resourceplanner.trydates".
2021-06-01 16:29:39.712124 (MainThread): Acquiring new bigquery connection "model.resourceplanner.FactTable".
2021-06-01 16:29:39.714521 (MainThread): Acquiring new bigquery connection "model.resourceplanner.my_second_dbt_model".
2021-06-01 16:29:39.716864 (MainThread): Acquiring new bigquery connection "model.resourceplanner.my_first_dbt_model".
2021-06-01 16:29:39.762307 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5295346e-24af-4265-a0de-15f2f5ad6773', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4e41369820>]}
2021-06-01 16:29:39.765212 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5295346e-24af-4265-a0de-15f2f5ad6773', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4e41316490>]}
2021-06-01 16:29:39.765364 (MainThread): Found 5 models, 4 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-06-01 16:29:39.766046 (MainThread): 
2021-06-01 16:29:39.766280 (MainThread): Acquiring new bigquery connection "master".
2021-06-01 16:29:39.766905 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_oef-stage".
2021-06-01 16:29:39.767087 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-06-01 16:29:39.828149 (MainThread): Connection 'master' was properly closed.
2021-06-01 16:29:39.828269 (MainThread): Connection 'list_oef-stage' was properly closed.
2021-06-01 16:29:39.828382 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4e413ff520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4e41328ca0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4e413697f0>]}
2021-06-01 16:29:39.828553 (MainThread): Flushing usage events
2021-06-01 16:29:40.206852 (MainThread): Encountered an error:
2021-06-01 16:29:40.207249 (MainThread): Runtime Error
  Unable to generate access token, if you're using impersonate_service_account, make sure your initial account has the "roles/iam.serviceAccountTokenCreator" role on the account you are trying to impersonate.
  
  ('invalid_grant: Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.', {'error': 'invalid_grant', 'error_description': 'Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.'})
2021-06-01 16:29:40.208976 (MainThread): Traceback (most recent call last):
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 149, in exception_handler
    yield
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/impl.py", line 203, in query_schemas
    return [ds.dataset_id for ds in all_datasets]
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/impl.py", line 203, in <listcomp>
    return [ds.dataset_id for ds in all_datasets]
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/page_iterator.py", line 212, in _items_iter
    for page in self._page_iter(increment=False):
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/page_iterator.py", line 243, in _page_iter
    page = self._next_page()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/page_iterator.py", line 369, in _next_page
    response = self._get_next_page_response()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/page_iterator.py", line 418, in _get_next_page_response
    return self.api_request(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 369, in api_request
    return self._call_api(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 636, in _call_api
    return call()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/_http.py", line 427, in api_request
    response = self._make_request(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/_http.py", line 291, in _make_request
    return self._do_request(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/_http.py", line 329, in _do_request
    return self.http.request(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/auth/transport/requests.py", line 478, in request
    self.credentials.before_request(auth_request, method, url, request_headers)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/auth/credentials.py", line 133, in before_request
    self.refresh(request)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/oauth2/service_account.py", line 376, in refresh
    access_token, expiry, _ = _client.jwt_grant(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/oauth2/_client.py", line 193, in jwt_grant
    response_data = _token_endpoint_request(request, token_uri, body)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/oauth2/_client.py", line 165, in _token_endpoint_request
    _handle_error_response(response_data)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/oauth2/_client.py", line 60, in _handle_error_response
    raise exceptions.RefreshError(error_details, response_data)
google.auth.exceptions.RefreshError: ('invalid_grant: Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.', {'error': 'invalid_grant', 'error_description': 'Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.'})

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/main.py", line 125, in main
    results, succeeded = handle_and_check(args)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/main.py", line 203, in handle_and_check
    task, res = run_from_args(parsed)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/main.py", line 256, in run_from_args
    results = task.run()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/runnable.py", line 426, in run
    result = self.execute_with_hooks(selected_uids)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/runnable.py", line 383, in execute_with_hooks
    self.before_run(adapter, selected_uids)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/run.py", line 409, in before_run
    self.create_schemas(adapter, selected_uids)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/runnable.py", line 515, in create_schemas
    existing_schemas_lowered.update(ls_future.result())
  File "/usr/lib/python3.8/concurrent/futures/_base.py", line 432, in result
    return self.__get_result()
  File "/usr/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
    raise self._exception
  File "/usr/lib/python3.8/concurrent/futures/thread.py", line 57, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/utils.py", line 469, in connected
    return func(*args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/runnable.py", line 492, in list_schemas
    for s in adapter.list_schemas(database_quoted)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/impl.py", line 205, in list_schemas
    return self.connections._retry_and_handle(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 166, in exception_handler
    raise RuntimeException(message)
dbt.exceptions.RuntimeException: Runtime Error
  Unable to generate access token, if you're using impersonate_service_account, make sure your initial account has the "roles/iam.serviceAccountTokenCreator" role on the account you are trying to impersonate.
  
  ('invalid_grant: Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.', {'error': 'invalid_grant', 'error_description': 'Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.'})

2021-06-01 16:29:42.077391 (MainThread): Running with dbt=0.19.1
2021-06-01 16:29:42.259114 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/home/femke/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-06-01 16:29:42.259725 (MainThread): Tracking: tracking
2021-06-01 16:29:42.269403 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbdb6397c70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbdb7ccc250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbdb7ccc550>]}
2021-06-01 16:29:42.285337 (MainThread): Partial parsing not enabled
2021-06-01 16:29:42.286100 (MainThread): Parsing macros/catalog.sql
2021-06-01 16:29:42.296398 (MainThread): Parsing macros/adapters.sql
2021-06-01 16:29:42.315643 (MainThread): Parsing macros/etc.sql
2021-06-01 16:29:42.317077 (MainThread): Parsing macros/materializations/snapshot.sql
2021-06-01 16:29:42.318272 (MainThread): Parsing macros/materializations/copy.sql
2021-06-01 16:29:42.321408 (MainThread): Parsing macros/materializations/table.sql
2021-06-01 16:29:42.328412 (MainThread): Parsing macros/materializations/incremental.sql
2021-06-01 16:29:42.337002 (MainThread): Parsing macros/materializations/view.sql
2021-06-01 16:29:42.338972 (MainThread): Parsing macros/materializations/seed.sql
2021-06-01 16:29:42.341313 (MainThread): Parsing macros/core.sql
2021-06-01 16:29:42.344083 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-06-01 16:29:42.345193 (MainThread): Parsing macros/schema_tests/unique.sql
2021-06-01 16:29:42.346439 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-06-01 16:29:42.347688 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-06-01 16:29:42.349514 (MainThread): Parsing macros/materializations/helpers.sql
2021-06-01 16:29:42.355719 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-06-01 16:29:42.356997 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-06-01 16:29:42.361247 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-06-01 16:29:42.375008 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-06-01 16:29:42.395976 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-06-01 16:29:42.397360 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-06-01 16:29:42.410049 (MainThread): Parsing macros/materializations/table/table.sql
2021-06-01 16:29:42.414698 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-06-01 16:29:42.418060 (MainThread): Parsing macros/materializations/view/view.sql
2021-06-01 16:29:42.422304 (MainThread): Parsing macros/materializations/common/merge.sql
2021-06-01 16:29:42.431734 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-06-01 16:29:42.432885 (MainThread): Parsing macros/etc/query.sql
2021-06-01 16:29:42.433627 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-06-01 16:29:42.434254 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-06-01 16:29:42.435711 (MainThread): Parsing macros/etc/datetime.sql
2021-06-01 16:29:42.441664 (MainThread): Parsing macros/etc/is_incremental.sql
2021-06-01 16:29:42.442811 (MainThread): Parsing macros/adapters/common.sql
2021-06-01 16:29:42.474796 (MainThread): Partial parsing not enabled
2021-06-01 16:29:42.491765 (MainThread): Acquiring new bigquery connection "model.resourceplanner.EmployeeDates".
2021-06-01 16:29:42.499303 (MainThread): Acquiring new bigquery connection "model.resourceplanner.trydates".
2021-06-01 16:29:42.501899 (MainThread): Acquiring new bigquery connection "model.resourceplanner.FactTable".
2021-06-01 16:29:42.504353 (MainThread): Acquiring new bigquery connection "model.resourceplanner.my_second_dbt_model".
2021-06-01 16:29:42.506867 (MainThread): Acquiring new bigquery connection "model.resourceplanner.my_first_dbt_model".
2021-06-01 16:29:42.555174 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '11c5162c-e604-4874-9bc4-bb533b04e8f2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbdb53d67c0>]}
2021-06-01 16:29:42.558631 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '11c5162c-e604-4874-9bc4-bb533b04e8f2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbdb53c2f40>]}
2021-06-01 16:29:42.558838 (MainThread): Found 5 models, 4 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-06-01 16:29:42.559519 (MainThread): 
2021-06-01 16:29:42.559757 (MainThread): Acquiring new bigquery connection "master".
2021-06-01 16:29:42.560445 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_oef-stage".
2021-06-01 16:29:42.560568 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-06-01 16:29:42.624301 (MainThread): Connection 'master' was properly closed.
2021-06-01 16:29:42.624420 (MainThread): Connection 'list_oef-stage' was properly closed.
2021-06-01 16:29:42.624536 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbdb54bf490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbdb5392040>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbdb542d460>]}
2021-06-01 16:29:42.624689 (MainThread): Flushing usage events
2021-06-01 16:29:43.006332 (MainThread): Encountered an error:
2021-06-01 16:29:43.006773 (MainThread): Runtime Error
  Unable to generate access token, if you're using impersonate_service_account, make sure your initial account has the "roles/iam.serviceAccountTokenCreator" role on the account you are trying to impersonate.
  
  ('invalid_grant: Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.', {'error': 'invalid_grant', 'error_description': 'Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.'})
2021-06-01 16:29:43.008509 (MainThread): Traceback (most recent call last):
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 149, in exception_handler
    yield
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/impl.py", line 203, in query_schemas
    return [ds.dataset_id for ds in all_datasets]
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/impl.py", line 203, in <listcomp>
    return [ds.dataset_id for ds in all_datasets]
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/page_iterator.py", line 212, in _items_iter
    for page in self._page_iter(increment=False):
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/page_iterator.py", line 243, in _page_iter
    page = self._next_page()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/page_iterator.py", line 369, in _next_page
    response = self._get_next_page_response()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/page_iterator.py", line 418, in _get_next_page_response
    return self.api_request(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 369, in api_request
    return self._call_api(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 636, in _call_api
    return call()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/_http.py", line 427, in api_request
    response = self._make_request(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/_http.py", line 291, in _make_request
    return self._do_request(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/_http.py", line 329, in _do_request
    return self.http.request(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/auth/transport/requests.py", line 478, in request
    self.credentials.before_request(auth_request, method, url, request_headers)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/auth/credentials.py", line 133, in before_request
    self.refresh(request)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/oauth2/service_account.py", line 376, in refresh
    access_token, expiry, _ = _client.jwt_grant(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/oauth2/_client.py", line 193, in jwt_grant
    response_data = _token_endpoint_request(request, token_uri, body)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/oauth2/_client.py", line 165, in _token_endpoint_request
    _handle_error_response(response_data)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/oauth2/_client.py", line 60, in _handle_error_response
    raise exceptions.RefreshError(error_details, response_data)
google.auth.exceptions.RefreshError: ('invalid_grant: Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.', {'error': 'invalid_grant', 'error_description': 'Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.'})

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/main.py", line 125, in main
    results, succeeded = handle_and_check(args)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/main.py", line 203, in handle_and_check
    task, res = run_from_args(parsed)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/main.py", line 256, in run_from_args
    results = task.run()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/runnable.py", line 426, in run
    result = self.execute_with_hooks(selected_uids)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/runnable.py", line 383, in execute_with_hooks
    self.before_run(adapter, selected_uids)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/run.py", line 409, in before_run
    self.create_schemas(adapter, selected_uids)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/runnable.py", line 515, in create_schemas
    existing_schemas_lowered.update(ls_future.result())
  File "/usr/lib/python3.8/concurrent/futures/_base.py", line 432, in result
    return self.__get_result()
  File "/usr/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
    raise self._exception
  File "/usr/lib/python3.8/concurrent/futures/thread.py", line 57, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/utils.py", line 469, in connected
    return func(*args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/runnable.py", line 492, in list_schemas
    for s in adapter.list_schemas(database_quoted)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/impl.py", line 205, in list_schemas
    return self.connections._retry_and_handle(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 166, in exception_handler
    raise RuntimeException(message)
dbt.exceptions.RuntimeException: Runtime Error
  Unable to generate access token, if you're using impersonate_service_account, make sure your initial account has the "roles/iam.serviceAccountTokenCreator" role on the account you are trying to impersonate.
  
  ('invalid_grant: Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.', {'error': 'invalid_grant', 'error_description': 'Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.'})

2021-06-01 16:29:44.893841 (MainThread): Running with dbt=0.19.1
2021-06-01 16:29:45.068450 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/home/femke/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-06-01 16:29:45.069078 (MainThread): Tracking: tracking
2021-06-01 16:29:45.083069 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc31b1fc9d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc31cb70160>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc31cb704c0>]}
2021-06-01 16:29:45.093770 (MainThread): Partial parsing not enabled
2021-06-01 16:29:45.098402 (MainThread): Parsing macros/catalog.sql
2021-06-01 16:29:45.102747 (MainThread): Parsing macros/adapters.sql
2021-06-01 16:29:45.122810 (MainThread): Parsing macros/etc.sql
2021-06-01 16:29:45.124226 (MainThread): Parsing macros/materializations/snapshot.sql
2021-06-01 16:29:45.125407 (MainThread): Parsing macros/materializations/copy.sql
2021-06-01 16:29:45.128510 (MainThread): Parsing macros/materializations/table.sql
2021-06-01 16:29:45.135324 (MainThread): Parsing macros/materializations/incremental.sql
2021-06-01 16:29:45.143560 (MainThread): Parsing macros/materializations/view.sql
2021-06-01 16:29:45.145393 (MainThread): Parsing macros/materializations/seed.sql
2021-06-01 16:29:45.147625 (MainThread): Parsing macros/core.sql
2021-06-01 16:29:45.150109 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-06-01 16:29:45.151104 (MainThread): Parsing macros/schema_tests/unique.sql
2021-06-01 16:29:45.152187 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-06-01 16:29:45.153371 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-06-01 16:29:45.155167 (MainThread): Parsing macros/materializations/helpers.sql
2021-06-01 16:29:45.160958 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-06-01 16:29:45.162163 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-06-01 16:29:45.166377 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-06-01 16:29:45.180054 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-06-01 16:29:45.199476 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-06-01 16:29:45.200648 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-06-01 16:29:45.216852 (MainThread): Parsing macros/materializations/table/table.sql
2021-06-01 16:29:45.221309 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-06-01 16:29:45.224532 (MainThread): Parsing macros/materializations/view/view.sql
2021-06-01 16:29:45.228667 (MainThread): Parsing macros/materializations/common/merge.sql
2021-06-01 16:29:45.237680 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-06-01 16:29:45.238819 (MainThread): Parsing macros/etc/query.sql
2021-06-01 16:29:45.239530 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-06-01 16:29:45.240153 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-06-01 16:29:45.241543 (MainThread): Parsing macros/etc/datetime.sql
2021-06-01 16:29:45.247307 (MainThread): Parsing macros/etc/is_incremental.sql
2021-06-01 16:29:45.248404 (MainThread): Parsing macros/adapters/common.sql
2021-06-01 16:29:45.280140 (MainThread): Partial parsing not enabled
2021-06-01 16:29:45.303059 (MainThread): Acquiring new bigquery connection "model.resourceplanner.EmployeeDates".
2021-06-01 16:29:45.309789 (MainThread): Acquiring new bigquery connection "model.resourceplanner.trydates".
2021-06-01 16:29:45.312050 (MainThread): Acquiring new bigquery connection "model.resourceplanner.FactTable".
2021-06-01 16:29:45.314477 (MainThread): Acquiring new bigquery connection "model.resourceplanner.my_second_dbt_model".
2021-06-01 16:29:45.316736 (MainThread): Acquiring new bigquery connection "model.resourceplanner.my_first_dbt_model".
2021-06-01 16:29:45.361174 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '3720f6de-1ccf-4c93-a621-3a4203e25094', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc31a23a370>]}
2021-06-01 16:29:45.364107 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '3720f6de-1ccf-4c93-a621-3a4203e25094', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc31cafd610>]}
2021-06-01 16:29:45.364242 (MainThread): Found 5 models, 4 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-06-01 16:29:45.364913 (MainThread): 
2021-06-01 16:29:45.365148 (MainThread): Acquiring new bigquery connection "master".
2021-06-01 16:29:45.365817 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_oef-stage".
2021-06-01 16:29:45.365937 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-06-01 16:29:45.442096 (MainThread): Connection 'master' was properly closed.
2021-06-01 16:29:45.442215 (MainThread): Connection 'list_oef-stage' was properly closed.
2021-06-01 16:29:45.442332 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc31a324400>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc31a1f3f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc31a358940>]}
2021-06-01 16:29:45.442483 (MainThread): Flushing usage events
2021-06-01 16:29:45.821326 (MainThread): Encountered an error:
2021-06-01 16:29:45.821747 (MainThread): Runtime Error
  Unable to generate access token, if you're using impersonate_service_account, make sure your initial account has the "roles/iam.serviceAccountTokenCreator" role on the account you are trying to impersonate.
  
  ('invalid_grant: Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.', {'error': 'invalid_grant', 'error_description': 'Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.'})
2021-06-01 16:29:45.823501 (MainThread): Traceback (most recent call last):
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 149, in exception_handler
    yield
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/impl.py", line 203, in query_schemas
    return [ds.dataset_id for ds in all_datasets]
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/impl.py", line 203, in <listcomp>
    return [ds.dataset_id for ds in all_datasets]
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/page_iterator.py", line 212, in _items_iter
    for page in self._page_iter(increment=False):
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/page_iterator.py", line 243, in _page_iter
    page = self._next_page()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/page_iterator.py", line 369, in _next_page
    response = self._get_next_page_response()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/page_iterator.py", line 418, in _get_next_page_response
    return self.api_request(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 369, in api_request
    return self._call_api(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 636, in _call_api
    return call()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/_http.py", line 427, in api_request
    response = self._make_request(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/_http.py", line 291, in _make_request
    return self._do_request(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/_http.py", line 329, in _do_request
    return self.http.request(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/auth/transport/requests.py", line 478, in request
    self.credentials.before_request(auth_request, method, url, request_headers)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/auth/credentials.py", line 133, in before_request
    self.refresh(request)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/oauth2/service_account.py", line 376, in refresh
    access_token, expiry, _ = _client.jwt_grant(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/oauth2/_client.py", line 193, in jwt_grant
    response_data = _token_endpoint_request(request, token_uri, body)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/oauth2/_client.py", line 165, in _token_endpoint_request
    _handle_error_response(response_data)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/oauth2/_client.py", line 60, in _handle_error_response
    raise exceptions.RefreshError(error_details, response_data)
google.auth.exceptions.RefreshError: ('invalid_grant: Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.', {'error': 'invalid_grant', 'error_description': 'Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.'})

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/main.py", line 125, in main
    results, succeeded = handle_and_check(args)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/main.py", line 203, in handle_and_check
    task, res = run_from_args(parsed)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/main.py", line 256, in run_from_args
    results = task.run()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/runnable.py", line 426, in run
    result = self.execute_with_hooks(selected_uids)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/runnable.py", line 383, in execute_with_hooks
    self.before_run(adapter, selected_uids)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/run.py", line 409, in before_run
    self.create_schemas(adapter, selected_uids)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/runnable.py", line 515, in create_schemas
    existing_schemas_lowered.update(ls_future.result())
  File "/usr/lib/python3.8/concurrent/futures/_base.py", line 432, in result
    return self.__get_result()
  File "/usr/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
    raise self._exception
  File "/usr/lib/python3.8/concurrent/futures/thread.py", line 57, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/utils.py", line 469, in connected
    return func(*args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/runnable.py", line 492, in list_schemas
    for s in adapter.list_schemas(database_quoted)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/impl.py", line 205, in list_schemas
    return self.connections._retry_and_handle(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 166, in exception_handler
    raise RuntimeException(message)
dbt.exceptions.RuntimeException: Runtime Error
  Unable to generate access token, if you're using impersonate_service_account, make sure your initial account has the "roles/iam.serviceAccountTokenCreator" role on the account you are trying to impersonate.
  
  ('invalid_grant: Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.', {'error': 'invalid_grant', 'error_description': 'Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.'})

2021-06-01 16:30:45.443243 (MainThread): Running with dbt=0.19.1
2021-06-01 16:30:45.624204 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/home/femke/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-06-01 16:30:45.624812 (MainThread): Tracking: tracking
2021-06-01 16:30:45.638910 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa21f2e1fd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa220ca64c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa21f2f14f0>]}
2021-06-01 16:30:45.649931 (MainThread): Partial parsing not enabled
2021-06-01 16:30:45.650658 (MainThread): Parsing macros/catalog.sql
2021-06-01 16:30:45.654776 (MainThread): Parsing macros/adapters.sql
2021-06-01 16:30:45.681220 (MainThread): Parsing macros/etc.sql
2021-06-01 16:30:45.682688 (MainThread): Parsing macros/materializations/snapshot.sql
2021-06-01 16:30:45.683892 (MainThread): Parsing macros/materializations/copy.sql
2021-06-01 16:30:45.686954 (MainThread): Parsing macros/materializations/table.sql
2021-06-01 16:30:45.693713 (MainThread): Parsing macros/materializations/incremental.sql
2021-06-01 16:30:45.702325 (MainThread): Parsing macros/materializations/view.sql
2021-06-01 16:30:45.704393 (MainThread): Parsing macros/materializations/seed.sql
2021-06-01 16:30:45.706650 (MainThread): Parsing macros/core.sql
2021-06-01 16:30:45.709289 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-06-01 16:30:45.710285 (MainThread): Parsing macros/schema_tests/unique.sql
2021-06-01 16:30:45.711408 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-06-01 16:30:45.712604 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-06-01 16:30:45.714364 (MainThread): Parsing macros/materializations/helpers.sql
2021-06-01 16:30:45.720158 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-06-01 16:30:45.721359 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-06-01 16:30:45.725708 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-06-01 16:30:45.739488 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-06-01 16:30:45.759152 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-06-01 16:30:45.760311 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-06-01 16:30:45.772591 (MainThread): Parsing macros/materializations/table/table.sql
2021-06-01 16:30:45.777040 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-06-01 16:30:45.780337 (MainThread): Parsing macros/materializations/view/view.sql
2021-06-01 16:30:45.784426 (MainThread): Parsing macros/materializations/common/merge.sql
2021-06-01 16:30:45.793171 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-06-01 16:30:45.794238 (MainThread): Parsing macros/etc/query.sql
2021-06-01 16:30:45.794939 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-06-01 16:30:45.795550 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-06-01 16:30:45.796883 (MainThread): Parsing macros/etc/datetime.sql
2021-06-01 16:30:45.802816 (MainThread): Parsing macros/etc/is_incremental.sql
2021-06-01 16:30:45.804033 (MainThread): Parsing macros/adapters/common.sql
2021-06-01 16:30:45.834003 (MainThread): Partial parsing not enabled
2021-06-01 16:30:45.853588 (MainThread): Acquiring new bigquery connection "model.resourceplanner.EmployeeDates".
2021-06-01 16:30:45.860423 (MainThread): Acquiring new bigquery connection "model.resourceplanner.trydates".
2021-06-01 16:30:45.862703 (MainThread): Acquiring new bigquery connection "model.resourceplanner.FactTable".
2021-06-01 16:30:45.865022 (MainThread): Acquiring new bigquery connection "model.resourceplanner.my_second_dbt_model".
2021-06-01 16:30:45.867285 (MainThread): Acquiring new bigquery connection "model.resourceplanner.my_first_dbt_model".
2021-06-01 16:30:45.911104 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '51e96f05-c27a-4a5c-a017-7c63f968def2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa21c9b86a0>]}
2021-06-01 16:30:45.913966 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '51e96f05-c27a-4a5c-a017-7c63f968def2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa21c9d4f40>]}
2021-06-01 16:30:45.914100 (MainThread): Found 5 models, 4 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-06-01 16:30:45.914777 (MainThread): 
2021-06-01 16:30:45.914997 (MainThread): Acquiring new bigquery connection "master".
2021-06-01 16:30:45.915714 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_oef-stage".
2021-06-01 16:30:45.915835 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-06-01 16:30:45.977705 (MainThread): Connection 'master' was properly closed.
2021-06-01 16:30:45.977832 (MainThread): Connection 'list_oef-stage' was properly closed.
2021-06-01 16:30:45.977950 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa21caa13d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa21c9c1ac0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa21c92d400>]}
2021-06-01 16:30:45.978070 (MainThread): Flushing usage events
2021-06-01 16:30:46.395368 (MainThread): Encountered an error:
2021-06-01 16:30:46.395778 (MainThread): Runtime Error
  Unable to generate access token, if you're using impersonate_service_account, make sure your initial account has the "roles/iam.serviceAccountTokenCreator" role on the account you are trying to impersonate.
  
  ('invalid_grant: Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.', {'error': 'invalid_grant', 'error_description': 'Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.'})
2021-06-01 16:30:46.397518 (MainThread): Traceback (most recent call last):
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 149, in exception_handler
    yield
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/impl.py", line 203, in query_schemas
    return [ds.dataset_id for ds in all_datasets]
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/impl.py", line 203, in <listcomp>
    return [ds.dataset_id for ds in all_datasets]
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/page_iterator.py", line 212, in _items_iter
    for page in self._page_iter(increment=False):
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/page_iterator.py", line 243, in _page_iter
    page = self._next_page()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/page_iterator.py", line 369, in _next_page
    response = self._get_next_page_response()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/page_iterator.py", line 418, in _get_next_page_response
    return self.api_request(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 369, in api_request
    return self._call_api(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 636, in _call_api
    return call()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/_http.py", line 427, in api_request
    response = self._make_request(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/_http.py", line 291, in _make_request
    return self._do_request(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/_http.py", line 329, in _do_request
    return self.http.request(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/auth/transport/requests.py", line 478, in request
    self.credentials.before_request(auth_request, method, url, request_headers)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/auth/credentials.py", line 133, in before_request
    self.refresh(request)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/oauth2/service_account.py", line 376, in refresh
    access_token, expiry, _ = _client.jwt_grant(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/oauth2/_client.py", line 193, in jwt_grant
    response_data = _token_endpoint_request(request, token_uri, body)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/oauth2/_client.py", line 165, in _token_endpoint_request
    _handle_error_response(response_data)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/oauth2/_client.py", line 60, in _handle_error_response
    raise exceptions.RefreshError(error_details, response_data)
google.auth.exceptions.RefreshError: ('invalid_grant: Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.', {'error': 'invalid_grant', 'error_description': 'Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.'})

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/main.py", line 125, in main
    results, succeeded = handle_and_check(args)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/main.py", line 203, in handle_and_check
    task, res = run_from_args(parsed)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/main.py", line 256, in run_from_args
    results = task.run()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/runnable.py", line 426, in run
    result = self.execute_with_hooks(selected_uids)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/runnable.py", line 383, in execute_with_hooks
    self.before_run(adapter, selected_uids)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/run.py", line 409, in before_run
    self.create_schemas(adapter, selected_uids)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/runnable.py", line 515, in create_schemas
    existing_schemas_lowered.update(ls_future.result())
  File "/usr/lib/python3.8/concurrent/futures/_base.py", line 432, in result
    return self.__get_result()
  File "/usr/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
    raise self._exception
  File "/usr/lib/python3.8/concurrent/futures/thread.py", line 57, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/utils.py", line 469, in connected
    return func(*args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/runnable.py", line 492, in list_schemas
    for s in adapter.list_schemas(database_quoted)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/impl.py", line 205, in list_schemas
    return self.connections._retry_and_handle(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 166, in exception_handler
    raise RuntimeException(message)
dbt.exceptions.RuntimeException: Runtime Error
  Unable to generate access token, if you're using impersonate_service_account, make sure your initial account has the "roles/iam.serviceAccountTokenCreator" role on the account you are trying to impersonate.
  
  ('invalid_grant: Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.', {'error': 'invalid_grant', 'error_description': 'Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.'})

2021-06-01 16:31:20.549434 (MainThread): Running with dbt=0.19.1
2021-06-01 16:31:20.724032 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/home/femke/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-06-01 16:31:20.724677 (MainThread): Tracking: tracking
2021-06-01 16:31:20.734690 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f35a7c86fd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f35a96524c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f35a7c98520>]}
2021-06-01 16:31:20.748756 (MainThread): Partial parsing not enabled
2021-06-01 16:31:20.749444 (MainThread): Parsing macros/catalog.sql
2021-06-01 16:31:20.757674 (MainThread): Parsing macros/adapters.sql
2021-06-01 16:31:20.778018 (MainThread): Parsing macros/etc.sql
2021-06-01 16:31:20.779456 (MainThread): Parsing macros/materializations/snapshot.sql
2021-06-01 16:31:20.780625 (MainThread): Parsing macros/materializations/copy.sql
2021-06-01 16:31:20.783700 (MainThread): Parsing macros/materializations/table.sql
2021-06-01 16:31:20.790529 (MainThread): Parsing macros/materializations/incremental.sql
2021-06-01 16:31:20.798908 (MainThread): Parsing macros/materializations/view.sql
2021-06-01 16:31:20.800808 (MainThread): Parsing macros/materializations/seed.sql
2021-06-01 16:31:20.803078 (MainThread): Parsing macros/core.sql
2021-06-01 16:31:20.805615 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-06-01 16:31:20.806693 (MainThread): Parsing macros/schema_tests/unique.sql
2021-06-01 16:31:20.807808 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-06-01 16:31:20.809008 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-06-01 16:31:20.810820 (MainThread): Parsing macros/materializations/helpers.sql
2021-06-01 16:31:20.816614 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-06-01 16:31:20.817819 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-06-01 16:31:20.822110 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-06-01 16:31:20.835848 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-06-01 16:31:20.855636 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-06-01 16:31:20.856798 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-06-01 16:31:20.868891 (MainThread): Parsing macros/materializations/table/table.sql
2021-06-01 16:31:20.873439 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-06-01 16:31:20.876883 (MainThread): Parsing macros/materializations/view/view.sql
2021-06-01 16:31:20.881002 (MainThread): Parsing macros/materializations/common/merge.sql
2021-06-01 16:31:20.889969 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-06-01 16:31:20.891092 (MainThread): Parsing macros/etc/query.sql
2021-06-01 16:31:20.891783 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-06-01 16:31:20.892372 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-06-01 16:31:20.893740 (MainThread): Parsing macros/etc/datetime.sql
2021-06-01 16:31:20.899581 (MainThread): Parsing macros/etc/is_incremental.sql
2021-06-01 16:31:20.900679 (MainThread): Parsing macros/adapters/common.sql
2021-06-01 16:31:20.931368 (MainThread): Partial parsing not enabled
2021-06-01 16:31:20.947349 (MainThread): Acquiring new bigquery connection "model.resourceplanner.EmployeeDates".
2021-06-01 16:31:20.954088 (MainThread): Acquiring new bigquery connection "model.resourceplanner.trydates".
2021-06-01 16:31:20.956335 (MainThread): Acquiring new bigquery connection "model.resourceplanner.FactTable".
2021-06-01 16:31:20.958722 (MainThread): Acquiring new bigquery connection "model.resourceplanner.my_second_dbt_model".
2021-06-01 16:31:20.960992 (MainThread): Acquiring new bigquery connection "model.resourceplanner.my_first_dbt_model".
2021-06-01 16:31:21.005428 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '3d359ea3-01bc-4e4b-ac10-b2b951c5c75b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f35a53636a0>]}
2021-06-01 16:31:21.008389 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '3d359ea3-01bc-4e4b-ac10-b2b951c5c75b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f35a537ff40>]}
2021-06-01 16:31:21.008523 (MainThread): Found 5 models, 4 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-06-01 16:31:21.009200 (MainThread): 
2021-06-01 16:31:21.009426 (MainThread): Acquiring new bigquery connection "master".
2021-06-01 16:31:21.010115 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_oef-stage".
2021-06-01 16:31:21.010237 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-06-01 16:31:21.084194 (MainThread): Connection 'master' was properly closed.
2021-06-01 16:31:21.084308 (MainThread): Connection 'list_oef-stage' was properly closed.
2021-06-01 16:31:21.084440 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f35a544d3d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f35a536cac0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f35a52d7400>]}
2021-06-01 16:31:21.084572 (MainThread): Flushing usage events
2021-06-01 16:31:21.465721 (MainThread): Encountered an error:
2021-06-01 16:31:21.466144 (MainThread): Runtime Error
  Unable to generate access token, if you're using impersonate_service_account, make sure your initial account has the "roles/iam.serviceAccountTokenCreator" role on the account you are trying to impersonate.
  
  ('invalid_grant: Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.', {'error': 'invalid_grant', 'error_description': 'Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.'})
2021-06-01 16:31:21.468347 (MainThread): Traceback (most recent call last):
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 149, in exception_handler
    yield
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/impl.py", line 203, in query_schemas
    return [ds.dataset_id for ds in all_datasets]
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/impl.py", line 203, in <listcomp>
    return [ds.dataset_id for ds in all_datasets]
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/page_iterator.py", line 212, in _items_iter
    for page in self._page_iter(increment=False):
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/page_iterator.py", line 243, in _page_iter
    page = self._next_page()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/page_iterator.py", line 369, in _next_page
    response = self._get_next_page_response()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/page_iterator.py", line 418, in _get_next_page_response
    return self.api_request(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 369, in api_request
    return self._call_api(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 636, in _call_api
    return call()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/_http.py", line 427, in api_request
    response = self._make_request(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/_http.py", line 291, in _make_request
    return self._do_request(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/_http.py", line 329, in _do_request
    return self.http.request(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/auth/transport/requests.py", line 478, in request
    self.credentials.before_request(auth_request, method, url, request_headers)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/auth/credentials.py", line 133, in before_request
    self.refresh(request)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/oauth2/service_account.py", line 376, in refresh
    access_token, expiry, _ = _client.jwt_grant(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/oauth2/_client.py", line 193, in jwt_grant
    response_data = _token_endpoint_request(request, token_uri, body)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/oauth2/_client.py", line 165, in _token_endpoint_request
    _handle_error_response(response_data)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/oauth2/_client.py", line 60, in _handle_error_response
    raise exceptions.RefreshError(error_details, response_data)
google.auth.exceptions.RefreshError: ('invalid_grant: Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.', {'error': 'invalid_grant', 'error_description': 'Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.'})

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/main.py", line 125, in main
    results, succeeded = handle_and_check(args)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/main.py", line 203, in handle_and_check
    task, res = run_from_args(parsed)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/main.py", line 256, in run_from_args
    results = task.run()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/runnable.py", line 426, in run
    result = self.execute_with_hooks(selected_uids)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/runnable.py", line 383, in execute_with_hooks
    self.before_run(adapter, selected_uids)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/run.py", line 409, in before_run
    self.create_schemas(adapter, selected_uids)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/runnable.py", line 515, in create_schemas
    existing_schemas_lowered.update(ls_future.result())
  File "/usr/lib/python3.8/concurrent/futures/_base.py", line 432, in result
    return self.__get_result()
  File "/usr/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
    raise self._exception
  File "/usr/lib/python3.8/concurrent/futures/thread.py", line 57, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/utils.py", line 469, in connected
    return func(*args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/runnable.py", line 492, in list_schemas
    for s in adapter.list_schemas(database_quoted)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/impl.py", line 205, in list_schemas
    return self.connections._retry_and_handle(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 166, in exception_handler
    raise RuntimeException(message)
dbt.exceptions.RuntimeException: Runtime Error
  Unable to generate access token, if you're using impersonate_service_account, make sure your initial account has the "roles/iam.serviceAccountTokenCreator" role on the account you are trying to impersonate.
  
  ('invalid_grant: Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.', {'error': 'invalid_grant', 'error_description': 'Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.'})

2021-06-01 16:32:49.325760 (MainThread): Running with dbt=0.19.1
2021-06-01 16:32:49.502648 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/home/femke/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-06-01 16:32:49.503283 (MainThread): Tracking: tracking
2021-06-01 16:32:49.513343 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fec3cfaadf0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fec3e91e130>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fec3e91e4c0>]}
2021-06-01 16:32:49.528764 (MainThread): Partial parsing not enabled
2021-06-01 16:32:49.529571 (MainThread): Parsing macros/catalog.sql
2021-06-01 16:32:49.538178 (MainThread): Parsing macros/adapters.sql
2021-06-01 16:32:49.560658 (MainThread): Parsing macros/etc.sql
2021-06-01 16:32:49.562088 (MainThread): Parsing macros/materializations/snapshot.sql
2021-06-01 16:32:49.563328 (MainThread): Parsing macros/materializations/copy.sql
2021-06-01 16:32:49.566359 (MainThread): Parsing macros/materializations/table.sql
2021-06-01 16:32:49.573528 (MainThread): Parsing macros/materializations/incremental.sql
2021-06-01 16:32:49.581992 (MainThread): Parsing macros/materializations/view.sql
2021-06-01 16:32:49.583911 (MainThread): Parsing macros/materializations/seed.sql
2021-06-01 16:32:49.586181 (MainThread): Parsing macros/core.sql
2021-06-01 16:32:49.588703 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-06-01 16:32:49.589698 (MainThread): Parsing macros/schema_tests/unique.sql
2021-06-01 16:32:49.590797 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-06-01 16:32:49.592047 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-06-01 16:32:49.593789 (MainThread): Parsing macros/materializations/helpers.sql
2021-06-01 16:32:49.599698 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-06-01 16:32:49.600931 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-06-01 16:32:49.605534 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-06-01 16:32:49.619556 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-06-01 16:32:49.639884 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-06-01 16:32:49.641060 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-06-01 16:32:49.653716 (MainThread): Parsing macros/materializations/table/table.sql
2021-06-01 16:32:49.658278 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-06-01 16:32:49.661701 (MainThread): Parsing macros/materializations/view/view.sql
2021-06-01 16:32:49.665969 (MainThread): Parsing macros/materializations/common/merge.sql
2021-06-01 16:32:49.675281 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-06-01 16:32:49.676373 (MainThread): Parsing macros/etc/query.sql
2021-06-01 16:32:49.677105 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-06-01 16:32:49.677754 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-06-01 16:32:49.679229 (MainThread): Parsing macros/etc/datetime.sql
2021-06-01 16:32:49.685206 (MainThread): Parsing macros/etc/is_incremental.sql
2021-06-01 16:32:49.686352 (MainThread): Parsing macros/adapters/common.sql
2021-06-01 16:32:49.718609 (MainThread): Partial parsing not enabled
2021-06-01 16:32:49.735791 (MainThread): Acquiring new bigquery connection "model.resourceplanner.EmployeeDates".
2021-06-01 16:32:49.743036 (MainThread): Acquiring new bigquery connection "model.resourceplanner.trydates".
2021-06-01 16:32:49.745385 (MainThread): Acquiring new bigquery connection "model.resourceplanner.FactTable".
2021-06-01 16:32:49.747773 (MainThread): Acquiring new bigquery connection "model.resourceplanner.my_second_dbt_model".
2021-06-01 16:32:49.750208 (MainThread): Acquiring new bigquery connection "model.resourceplanner.my_first_dbt_model".
2021-06-01 16:32:49.797456 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '41a2f6c8-e745-47d9-962a-fe384f64bfed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fec3bfe9370>]}
2021-06-01 16:32:49.800596 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '41a2f6c8-e745-47d9-962a-fe384f64bfed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fec3c1ccd30>]}
2021-06-01 16:32:49.800734 (MainThread): Found 5 models, 4 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-06-01 16:32:49.801384 (MainThread): 
2021-06-01 16:32:49.801681 (MainThread): Acquiring new bigquery connection "master".
2021-06-01 16:32:49.802310 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_oef-stage".
2021-06-01 16:32:49.802500 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-06-01 16:32:49.864839 (MainThread): Connection 'master' was properly closed.
2021-06-01 16:32:49.864952 (MainThread): Connection 'list_oef-stage' was properly closed.
2021-06-01 16:32:49.865067 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fec3c0d2400>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fec3bfa2f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fec3c1058b0>]}
2021-06-01 16:32:49.865189 (MainThread): Flushing usage events
2021-06-01 16:32:50.283132 (MainThread): Encountered an error:
2021-06-01 16:32:50.283520 (MainThread): Runtime Error
  Unable to generate access token, if you're using impersonate_service_account, make sure your initial account has the "roles/iam.serviceAccountTokenCreator" role on the account you are trying to impersonate.
  
  ('invalid_grant: Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.', {'error': 'invalid_grant', 'error_description': 'Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.'})
2021-06-01 16:32:50.285224 (MainThread): Traceback (most recent call last):
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 149, in exception_handler
    yield
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/impl.py", line 203, in query_schemas
    return [ds.dataset_id for ds in all_datasets]
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/impl.py", line 203, in <listcomp>
    return [ds.dataset_id for ds in all_datasets]
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/page_iterator.py", line 212, in _items_iter
    for page in self._page_iter(increment=False):
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/page_iterator.py", line 243, in _page_iter
    page = self._next_page()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/page_iterator.py", line 369, in _next_page
    response = self._get_next_page_response()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/page_iterator.py", line 418, in _get_next_page_response
    return self.api_request(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 369, in api_request
    return self._call_api(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 636, in _call_api
    return call()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/_http.py", line 427, in api_request
    response = self._make_request(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/_http.py", line 291, in _make_request
    return self._do_request(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/_http.py", line 329, in _do_request
    return self.http.request(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/auth/transport/requests.py", line 478, in request
    self.credentials.before_request(auth_request, method, url, request_headers)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/auth/credentials.py", line 133, in before_request
    self.refresh(request)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/oauth2/service_account.py", line 376, in refresh
    access_token, expiry, _ = _client.jwt_grant(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/oauth2/_client.py", line 193, in jwt_grant
    response_data = _token_endpoint_request(request, token_uri, body)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/oauth2/_client.py", line 165, in _token_endpoint_request
    _handle_error_response(response_data)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/oauth2/_client.py", line 60, in _handle_error_response
    raise exceptions.RefreshError(error_details, response_data)
google.auth.exceptions.RefreshError: ('invalid_grant: Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.', {'error': 'invalid_grant', 'error_description': 'Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.'})

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/main.py", line 125, in main
    results, succeeded = handle_and_check(args)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/main.py", line 203, in handle_and_check
    task, res = run_from_args(parsed)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/main.py", line 256, in run_from_args
    results = task.run()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/runnable.py", line 426, in run
    result = self.execute_with_hooks(selected_uids)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/runnable.py", line 383, in execute_with_hooks
    self.before_run(adapter, selected_uids)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/run.py", line 409, in before_run
    self.create_schemas(adapter, selected_uids)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/runnable.py", line 515, in create_schemas
    existing_schemas_lowered.update(ls_future.result())
  File "/usr/lib/python3.8/concurrent/futures/_base.py", line 432, in result
    return self.__get_result()
  File "/usr/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
    raise self._exception
  File "/usr/lib/python3.8/concurrent/futures/thread.py", line 57, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/utils.py", line 469, in connected
    return func(*args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/runnable.py", line 492, in list_schemas
    for s in adapter.list_schemas(database_quoted)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/impl.py", line 205, in list_schemas
    return self.connections._retry_and_handle(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 166, in exception_handler
    raise RuntimeException(message)
dbt.exceptions.RuntimeException: Runtime Error
  Unable to generate access token, if you're using impersonate_service_account, make sure your initial account has the "roles/iam.serviceAccountTokenCreator" role on the account you are trying to impersonate.
  
  ('invalid_grant: Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.', {'error': 'invalid_grant', 'error_description': 'Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.'})

2021-06-01 16:34:33.524460 (MainThread): Running with dbt=0.19.1
2021-06-01 16:34:33.715051 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/home/femke/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-06-01 16:34:33.715660 (MainThread): Tracking: tracking
2021-06-01 16:34:33.743918 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3ad6f23e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3ad88581c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3ad8858520>]}
2021-06-01 16:34:33.757056 (MainThread): Partial parsing not enabled
2021-06-01 16:34:33.757793 (MainThread): Parsing macros/catalog.sql
2021-06-01 16:34:33.771603 (MainThread): Parsing macros/adapters.sql
2021-06-01 16:34:33.790699 (MainThread): Parsing macros/etc.sql
2021-06-01 16:34:33.792155 (MainThread): Parsing macros/materializations/snapshot.sql
2021-06-01 16:34:33.793359 (MainThread): Parsing macros/materializations/copy.sql
2021-06-01 16:34:33.796508 (MainThread): Parsing macros/materializations/table.sql
2021-06-01 16:34:33.803379 (MainThread): Parsing macros/materializations/incremental.sql
2021-06-01 16:34:33.811862 (MainThread): Parsing macros/materializations/view.sql
2021-06-01 16:34:33.813755 (MainThread): Parsing macros/materializations/seed.sql
2021-06-01 16:34:33.816068 (MainThread): Parsing macros/core.sql
2021-06-01 16:34:33.818999 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-06-01 16:34:33.820046 (MainThread): Parsing macros/schema_tests/unique.sql
2021-06-01 16:34:33.821301 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-06-01 16:34:33.822597 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-06-01 16:34:33.824373 (MainThread): Parsing macros/materializations/helpers.sql
2021-06-01 16:34:33.830260 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-06-01 16:34:33.831538 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-06-01 16:34:33.836136 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-06-01 16:34:33.850059 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-06-01 16:34:33.870416 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-06-01 16:34:33.871614 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-06-01 16:34:33.884038 (MainThread): Parsing macros/materializations/table/table.sql
2021-06-01 16:34:33.888633 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-06-01 16:34:33.892362 (MainThread): Parsing macros/materializations/view/view.sql
2021-06-01 16:34:33.896451 (MainThread): Parsing macros/materializations/common/merge.sql
2021-06-01 16:34:33.905759 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-06-01 16:34:33.906878 (MainThread): Parsing macros/etc/query.sql
2021-06-01 16:34:33.907609 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-06-01 16:34:33.908238 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-06-01 16:34:33.909617 (MainThread): Parsing macros/etc/datetime.sql
2021-06-01 16:34:33.915455 (MainThread): Parsing macros/etc/is_incremental.sql
2021-06-01 16:34:33.916557 (MainThread): Parsing macros/adapters/common.sql
2021-06-01 16:34:33.947634 (MainThread): Partial parsing not enabled
2021-06-01 16:34:33.963814 (MainThread): Acquiring new bigquery connection "model.resourceplanner.EmployeeDates".
2021-06-01 16:34:33.970655 (MainThread): Acquiring new bigquery connection "model.resourceplanner.trydates".
2021-06-01 16:34:33.973003 (MainThread): Acquiring new bigquery connection "model.resourceplanner.FactTable".
2021-06-01 16:34:33.975475 (MainThread): Acquiring new bigquery connection "model.resourceplanner.my_second_dbt_model".
2021-06-01 16:34:33.978228 (MainThread): Acquiring new bigquery connection "model.resourceplanner.my_first_dbt_model".
2021-06-01 16:34:34.023840 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '87d0589d-8eb2-42f3-a103-c476419dddb4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3ad5f61760>]}
2021-06-01 16:34:34.026888 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '87d0589d-8eb2-42f3-a103-c476419dddb4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3ad5f56fa0>]}
2021-06-01 16:34:34.027038 (MainThread): Found 5 models, 4 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-06-01 16:34:34.027752 (MainThread): 
2021-06-01 16:34:34.027989 (MainThread): Acquiring new bigquery connection "master".
2021-06-01 16:34:34.028677 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_oef-stage".
2021-06-01 16:34:34.028802 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-06-01 16:34:34.098679 (MainThread): Connection 'master' was properly closed.
2021-06-01 16:34:34.098804 (MainThread): Connection 'list_oef-stage' was properly closed.
2021-06-01 16:34:34.098920 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3ad604b460>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3ad5f003d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3ad5f2f7c0>]}
2021-06-01 16:34:34.099141 (MainThread): Flushing usage events
2021-06-01 16:34:34.508329 (MainThread): Encountered an error:
2021-06-01 16:34:34.508739 (MainThread): Runtime Error
  Unable to generate access token, if you're using impersonate_service_account, make sure your initial account has the "roles/iam.serviceAccountTokenCreator" role on the account you are trying to impersonate.
  
  ('invalid_grant: Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.', {'error': 'invalid_grant', 'error_description': 'Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.'})
2021-06-01 16:34:34.510485 (MainThread): Traceback (most recent call last):
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 149, in exception_handler
    yield
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/impl.py", line 203, in query_schemas
    return [ds.dataset_id for ds in all_datasets]
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/impl.py", line 203, in <listcomp>
    return [ds.dataset_id for ds in all_datasets]
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/page_iterator.py", line 212, in _items_iter
    for page in self._page_iter(increment=False):
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/page_iterator.py", line 243, in _page_iter
    page = self._next_page()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/page_iterator.py", line 369, in _next_page
    response = self._get_next_page_response()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/page_iterator.py", line 418, in _get_next_page_response
    return self.api_request(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 369, in api_request
    return self._call_api(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 636, in _call_api
    return call()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/_http.py", line 427, in api_request
    response = self._make_request(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/_http.py", line 291, in _make_request
    return self._do_request(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/_http.py", line 329, in _do_request
    return self.http.request(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/auth/transport/requests.py", line 478, in request
    self.credentials.before_request(auth_request, method, url, request_headers)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/auth/credentials.py", line 133, in before_request
    self.refresh(request)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/oauth2/service_account.py", line 376, in refresh
    access_token, expiry, _ = _client.jwt_grant(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/oauth2/_client.py", line 193, in jwt_grant
    response_data = _token_endpoint_request(request, token_uri, body)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/oauth2/_client.py", line 165, in _token_endpoint_request
    _handle_error_response(response_data)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/oauth2/_client.py", line 60, in _handle_error_response
    raise exceptions.RefreshError(error_details, response_data)
google.auth.exceptions.RefreshError: ('invalid_grant: Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.', {'error': 'invalid_grant', 'error_description': 'Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.'})

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/main.py", line 125, in main
    results, succeeded = handle_and_check(args)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/main.py", line 203, in handle_and_check
    task, res = run_from_args(parsed)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/main.py", line 256, in run_from_args
    results = task.run()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/runnable.py", line 426, in run
    result = self.execute_with_hooks(selected_uids)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/runnable.py", line 383, in execute_with_hooks
    self.before_run(adapter, selected_uids)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/run.py", line 409, in before_run
    self.create_schemas(adapter, selected_uids)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/runnable.py", line 515, in create_schemas
    existing_schemas_lowered.update(ls_future.result())
  File "/usr/lib/python3.8/concurrent/futures/_base.py", line 432, in result
    return self.__get_result()
  File "/usr/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
    raise self._exception
  File "/usr/lib/python3.8/concurrent/futures/thread.py", line 57, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/utils.py", line 469, in connected
    return func(*args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/runnable.py", line 492, in list_schemas
    for s in adapter.list_schemas(database_quoted)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/impl.py", line 205, in list_schemas
    return self.connections._retry_and_handle(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 166, in exception_handler
    raise RuntimeException(message)
dbt.exceptions.RuntimeException: Runtime Error
  Unable to generate access token, if you're using impersonate_service_account, make sure your initial account has the "roles/iam.serviceAccountTokenCreator" role on the account you are trying to impersonate.
  
  ('invalid_grant: Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.', {'error': 'invalid_grant', 'error_description': 'Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.'})

2021-06-01 16:34:47.342866 (MainThread): Running with dbt=0.19.1
2021-06-01 16:34:47.527254 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/home/femke/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-06-01 16:34:47.527870 (MainThread): Tracking: tracking
2021-06-01 16:34:47.538247 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5cbe532ee0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5cbfea8190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5cbfea85b0>]}
2021-06-01 16:34:47.557731 (MainThread): Partial parsing not enabled
2021-06-01 16:34:47.558701 (MainThread): Parsing macros/catalog.sql
2021-06-01 16:34:47.567635 (MainThread): Parsing macros/adapters.sql
2021-06-01 16:34:47.587734 (MainThread): Parsing macros/etc.sql
2021-06-01 16:34:47.589180 (MainThread): Parsing macros/materializations/snapshot.sql
2021-06-01 16:34:47.590489 (MainThread): Parsing macros/materializations/copy.sql
2021-06-01 16:34:47.593607 (MainThread): Parsing macros/materializations/table.sql
2021-06-01 16:34:47.601015 (MainThread): Parsing macros/materializations/incremental.sql
2021-06-01 16:34:47.609753 (MainThread): Parsing macros/materializations/view.sql
2021-06-01 16:34:47.611852 (MainThread): Parsing macros/materializations/seed.sql
2021-06-01 16:34:47.614213 (MainThread): Parsing macros/core.sql
2021-06-01 16:34:47.616909 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-06-01 16:34:47.617961 (MainThread): Parsing macros/schema_tests/unique.sql
2021-06-01 16:34:47.619180 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-06-01 16:34:47.620459 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-06-01 16:34:47.622264 (MainThread): Parsing macros/materializations/helpers.sql
2021-06-01 16:34:47.629095 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-06-01 16:34:47.630443 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-06-01 16:34:47.634944 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-06-01 16:34:47.649249 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-06-01 16:34:47.670244 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-06-01 16:34:47.671466 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-06-01 16:34:47.684460 (MainThread): Parsing macros/materializations/table/table.sql
2021-06-01 16:34:47.689115 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-06-01 16:34:47.692570 (MainThread): Parsing macros/materializations/view/view.sql
2021-06-01 16:34:47.696939 (MainThread): Parsing macros/materializations/common/merge.sql
2021-06-01 16:34:47.706166 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-06-01 16:34:47.707298 (MainThread): Parsing macros/etc/query.sql
2021-06-01 16:34:47.707992 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-06-01 16:34:47.708637 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-06-01 16:34:47.710154 (MainThread): Parsing macros/etc/datetime.sql
2021-06-01 16:34:47.716024 (MainThread): Parsing macros/etc/is_incremental.sql
2021-06-01 16:34:47.717248 (MainThread): Parsing macros/adapters/common.sql
2021-06-01 16:34:47.749312 (MainThread): Partial parsing not enabled
2021-06-01 16:34:47.766580 (MainThread): Acquiring new bigquery connection "model.resourceplanner.EmployeeDates".
2021-06-01 16:34:47.773886 (MainThread): Acquiring new bigquery connection "model.resourceplanner.trydates".
2021-06-01 16:34:47.776244 (MainThread): Acquiring new bigquery connection "model.resourceplanner.FactTable".
2021-06-01 16:34:47.778769 (MainThread): Acquiring new bigquery connection "model.resourceplanner.my_second_dbt_model".
2021-06-01 16:34:47.781111 (MainThread): Acquiring new bigquery connection "model.resourceplanner.my_first_dbt_model".
2021-06-01 16:34:47.828721 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '3b6a8894-e628-4475-aa3b-919273528cb4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5cbd55ef70>]}
2021-06-01 16:34:47.831757 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '3b6a8894-e628-4475-aa3b-919273528cb4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5cbd5727f0>]}
2021-06-01 16:34:47.831896 (MainThread): Found 5 models, 4 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-06-01 16:34:47.832564 (MainThread): 
2021-06-01 16:34:47.832796 (MainThread): Acquiring new bigquery connection "master".
2021-06-01 16:34:47.833547 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_oef-stage".
2021-06-01 16:34:47.833672 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-06-01 16:34:47.892957 (MainThread): Connection 'master' was properly closed.
2021-06-01 16:34:47.893078 (MainThread): Connection 'list_oef-stage' was properly closed.
2021-06-01 16:34:47.893195 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5cbd65b4f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5cbd583fd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5cbd5cb580>]}
2021-06-01 16:34:47.893370 (MainThread): Flushing usage events
2021-06-01 16:34:48.272293 (MainThread): Encountered an error:
2021-06-01 16:34:48.272728 (MainThread): Runtime Error
  Unable to generate access token, if you're using impersonate_service_account, make sure your initial account has the "roles/iam.serviceAccountTokenCreator" role on the account you are trying to impersonate.
  
  ('invalid_grant: Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.', {'error': 'invalid_grant', 'error_description': 'Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.'})
2021-06-01 16:34:48.274520 (MainThread): Traceback (most recent call last):
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 149, in exception_handler
    yield
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/impl.py", line 203, in query_schemas
    return [ds.dataset_id for ds in all_datasets]
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/impl.py", line 203, in <listcomp>
    return [ds.dataset_id for ds in all_datasets]
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/page_iterator.py", line 212, in _items_iter
    for page in self._page_iter(increment=False):
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/page_iterator.py", line 243, in _page_iter
    page = self._next_page()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/page_iterator.py", line 369, in _next_page
    response = self._get_next_page_response()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/page_iterator.py", line 418, in _get_next_page_response
    return self.api_request(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 369, in api_request
    return self._call_api(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 636, in _call_api
    return call()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/_http.py", line 427, in api_request
    response = self._make_request(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/_http.py", line 291, in _make_request
    return self._do_request(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/_http.py", line 329, in _do_request
    return self.http.request(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/auth/transport/requests.py", line 478, in request
    self.credentials.before_request(auth_request, method, url, request_headers)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/auth/credentials.py", line 133, in before_request
    self.refresh(request)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/oauth2/service_account.py", line 376, in refresh
    access_token, expiry, _ = _client.jwt_grant(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/oauth2/_client.py", line 193, in jwt_grant
    response_data = _token_endpoint_request(request, token_uri, body)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/oauth2/_client.py", line 165, in _token_endpoint_request
    _handle_error_response(response_data)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/oauth2/_client.py", line 60, in _handle_error_response
    raise exceptions.RefreshError(error_details, response_data)
google.auth.exceptions.RefreshError: ('invalid_grant: Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.', {'error': 'invalid_grant', 'error_description': 'Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.'})

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/main.py", line 125, in main
    results, succeeded = handle_and_check(args)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/main.py", line 203, in handle_and_check
    task, res = run_from_args(parsed)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/main.py", line 256, in run_from_args
    results = task.run()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/runnable.py", line 426, in run
    result = self.execute_with_hooks(selected_uids)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/runnable.py", line 383, in execute_with_hooks
    self.before_run(adapter, selected_uids)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/run.py", line 409, in before_run
    self.create_schemas(adapter, selected_uids)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/runnable.py", line 515, in create_schemas
    existing_schemas_lowered.update(ls_future.result())
  File "/usr/lib/python3.8/concurrent/futures/_base.py", line 432, in result
    return self.__get_result()
  File "/usr/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
    raise self._exception
  File "/usr/lib/python3.8/concurrent/futures/thread.py", line 57, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/utils.py", line 469, in connected
    return func(*args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/runnable.py", line 492, in list_schemas
    for s in adapter.list_schemas(database_quoted)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/impl.py", line 205, in list_schemas
    return self.connections._retry_and_handle(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 166, in exception_handler
    raise RuntimeException(message)
dbt.exceptions.RuntimeException: Runtime Error
  Unable to generate access token, if you're using impersonate_service_account, make sure your initial account has the "roles/iam.serviceAccountTokenCreator" role on the account you are trying to impersonate.
  
  ('invalid_grant: Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.', {'error': 'invalid_grant', 'error_description': 'Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.'})

2021-06-01 16:37:33.509330 (MainThread): Running with dbt=0.19.1
2021-06-01 16:37:33.691714 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/home/femke/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-06-01 16:37:33.692378 (MainThread): Tracking: tracking
2021-06-01 16:37:33.703528 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff9177cfa30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff9191031c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff919103520>]}
2021-06-01 16:37:33.718583 (MainThread): Partial parsing not enabled
2021-06-01 16:37:33.719252 (MainThread): Parsing macros/catalog.sql
2021-06-01 16:37:33.727794 (MainThread): Parsing macros/adapters.sql
2021-06-01 16:37:33.747714 (MainThread): Parsing macros/etc.sql
2021-06-01 16:37:33.749090 (MainThread): Parsing macros/materializations/snapshot.sql
2021-06-01 16:37:33.750269 (MainThread): Parsing macros/materializations/copy.sql
2021-06-01 16:37:33.753456 (MainThread): Parsing macros/materializations/table.sql
2021-06-01 16:37:33.760392 (MainThread): Parsing macros/materializations/incremental.sql
2021-06-01 16:37:33.768964 (MainThread): Parsing macros/materializations/view.sql
2021-06-01 16:37:33.770870 (MainThread): Parsing macros/materializations/seed.sql
2021-06-01 16:37:33.773148 (MainThread): Parsing macros/core.sql
2021-06-01 16:37:33.775715 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-06-01 16:37:33.776705 (MainThread): Parsing macros/schema_tests/unique.sql
2021-06-01 16:37:33.777817 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-06-01 16:37:33.779050 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-06-01 16:37:33.780838 (MainThread): Parsing macros/materializations/helpers.sql
2021-06-01 16:37:33.786843 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-06-01 16:37:33.788063 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-06-01 16:37:33.792330 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-06-01 16:37:33.806199 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-06-01 16:37:33.826511 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-06-01 16:37:33.827668 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-06-01 16:37:33.844756 (MainThread): Parsing macros/materializations/table/table.sql
2021-06-01 16:37:33.851766 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-06-01 16:37:33.855261 (MainThread): Parsing macros/materializations/view/view.sql
2021-06-01 16:37:33.859469 (MainThread): Parsing macros/materializations/common/merge.sql
2021-06-01 16:37:33.868562 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-06-01 16:37:33.869676 (MainThread): Parsing macros/etc/query.sql
2021-06-01 16:37:33.870380 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-06-01 16:37:33.871022 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-06-01 16:37:33.872401 (MainThread): Parsing macros/etc/datetime.sql
2021-06-01 16:37:33.878242 (MainThread): Parsing macros/etc/is_incremental.sql
2021-06-01 16:37:33.879379 (MainThread): Parsing macros/adapters/common.sql
2021-06-01 16:37:33.913202 (MainThread): Partial parsing not enabled
2021-06-01 16:37:33.931436 (MainThread): Acquiring new bigquery connection "model.resourceplanner.EmployeeDates".
2021-06-01 16:37:33.938493 (MainThread): Acquiring new bigquery connection "model.resourceplanner.trydates".
2021-06-01 16:37:33.940854 (MainThread): Acquiring new bigquery connection "model.resourceplanner.FactTable".
2021-06-01 16:37:33.943176 (MainThread): Acquiring new bigquery connection "model.resourceplanner.my_second_dbt_model".
2021-06-01 16:37:33.945401 (MainThread): Acquiring new bigquery connection "model.resourceplanner.my_first_dbt_model".
2021-06-01 16:37:33.989028 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e529b196-242f-4197-9b4c-75164f77db28', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff91680f760>]}
2021-06-01 16:37:33.991817 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e529b196-242f-4197-9b4c-75164f77db28', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff916804fa0>]}
2021-06-01 16:37:33.991952 (MainThread): Found 5 models, 4 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-06-01 16:37:33.992645 (MainThread): 
2021-06-01 16:37:33.992896 (MainThread): Acquiring new bigquery connection "master".
2021-06-01 16:37:33.994083 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_oef-stage".
2021-06-01 16:37:33.994221 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-06-01 16:37:34.056379 (MainThread): Connection 'master' was properly closed.
2021-06-01 16:37:34.056543 (MainThread): Connection 'list_oef-stage' was properly closed.
2021-06-01 16:37:34.056673 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff9168f7460>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff9167ad3d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff9167dc7c0>]}
2021-06-01 16:37:34.056824 (MainThread): Flushing usage events
2021-06-01 16:37:34.467318 (MainThread): Encountered an error:
2021-06-01 16:37:34.467710 (MainThread): Runtime Error
  Unable to generate access token, if you're using impersonate_service_account, make sure your initial account has the "roles/iam.serviceAccountTokenCreator" role on the account you are trying to impersonate.
  
  ('invalid_grant: Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.', {'error': 'invalid_grant', 'error_description': 'Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.'})
2021-06-01 16:37:34.469406 (MainThread): Traceback (most recent call last):
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 149, in exception_handler
    yield
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/impl.py", line 203, in query_schemas
    return [ds.dataset_id for ds in all_datasets]
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/impl.py", line 203, in <listcomp>
    return [ds.dataset_id for ds in all_datasets]
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/page_iterator.py", line 212, in _items_iter
    for page in self._page_iter(increment=False):
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/page_iterator.py", line 243, in _page_iter
    page = self._next_page()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/page_iterator.py", line 369, in _next_page
    response = self._get_next_page_response()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/page_iterator.py", line 418, in _get_next_page_response
    return self.api_request(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 369, in api_request
    return self._call_api(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 636, in _call_api
    return call()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/_http.py", line 427, in api_request
    response = self._make_request(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/_http.py", line 291, in _make_request
    return self._do_request(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/_http.py", line 329, in _do_request
    return self.http.request(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/auth/transport/requests.py", line 478, in request
    self.credentials.before_request(auth_request, method, url, request_headers)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/auth/credentials.py", line 133, in before_request
    self.refresh(request)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/oauth2/service_account.py", line 376, in refresh
    access_token, expiry, _ = _client.jwt_grant(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/oauth2/_client.py", line 193, in jwt_grant
    response_data = _token_endpoint_request(request, token_uri, body)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/oauth2/_client.py", line 165, in _token_endpoint_request
    _handle_error_response(response_data)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/oauth2/_client.py", line 60, in _handle_error_response
    raise exceptions.RefreshError(error_details, response_data)
google.auth.exceptions.RefreshError: ('invalid_grant: Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.', {'error': 'invalid_grant', 'error_description': 'Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.'})

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/main.py", line 125, in main
    results, succeeded = handle_and_check(args)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/main.py", line 203, in handle_and_check
    task, res = run_from_args(parsed)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/main.py", line 256, in run_from_args
    results = task.run()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/runnable.py", line 426, in run
    result = self.execute_with_hooks(selected_uids)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/runnable.py", line 383, in execute_with_hooks
    self.before_run(adapter, selected_uids)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/run.py", line 409, in before_run
    self.create_schemas(adapter, selected_uids)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/runnable.py", line 515, in create_schemas
    existing_schemas_lowered.update(ls_future.result())
  File "/usr/lib/python3.8/concurrent/futures/_base.py", line 432, in result
    return self.__get_result()
  File "/usr/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
    raise self._exception
  File "/usr/lib/python3.8/concurrent/futures/thread.py", line 57, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/utils.py", line 469, in connected
    return func(*args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/runnable.py", line 492, in list_schemas
    for s in adapter.list_schemas(database_quoted)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/impl.py", line 205, in list_schemas
    return self.connections._retry_and_handle(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 166, in exception_handler
    raise RuntimeException(message)
dbt.exceptions.RuntimeException: Runtime Error
  Unable to generate access token, if you're using impersonate_service_account, make sure your initial account has the "roles/iam.serviceAccountTokenCreator" role on the account you are trying to impersonate.
  
  ('invalid_grant: Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.', {'error': 'invalid_grant', 'error_description': 'Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.'})

2021-06-01 16:41:38.165100 (MainThread): Running with dbt=0.19.1
2021-06-01 16:41:38.349756 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/home/femke/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-06-01 16:41:38.350364 (MainThread): Tracking: tracking
2021-06-01 16:41:38.360518 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff72f5f9a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff72fe3400>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff72f70460>]}
2021-06-01 16:41:38.375069 (MainThread): Partial parsing not enabled
2021-06-01 16:41:38.375768 (MainThread): Parsing macros/catalog.sql
2021-06-01 16:41:38.387768 (MainThread): Parsing macros/adapters.sql
2021-06-01 16:41:38.405209 (MainThread): Parsing macros/etc.sql
2021-06-01 16:41:38.406687 (MainThread): Parsing macros/materializations/snapshot.sql
2021-06-01 16:41:38.407900 (MainThread): Parsing macros/materializations/copy.sql
2021-06-01 16:41:38.411100 (MainThread): Parsing macros/materializations/table.sql
2021-06-01 16:41:38.418212 (MainThread): Parsing macros/materializations/incremental.sql
2021-06-01 16:41:38.427076 (MainThread): Parsing macros/materializations/view.sql
2021-06-01 16:41:38.429001 (MainThread): Parsing macros/materializations/seed.sql
2021-06-01 16:41:38.431369 (MainThread): Parsing macros/core.sql
2021-06-01 16:41:38.434074 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-06-01 16:41:38.435171 (MainThread): Parsing macros/schema_tests/unique.sql
2021-06-01 16:41:38.436311 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-06-01 16:41:38.437599 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-06-01 16:41:38.439402 (MainThread): Parsing macros/materializations/helpers.sql
2021-06-01 16:41:38.445180 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-06-01 16:41:38.446507 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-06-01 16:41:38.450849 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-06-01 16:41:38.464946 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-06-01 16:41:38.485186 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-06-01 16:41:38.486425 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-06-01 16:41:38.498557 (MainThread): Parsing macros/materializations/table/table.sql
2021-06-01 16:41:38.503151 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-06-01 16:41:38.506438 (MainThread): Parsing macros/materializations/view/view.sql
2021-06-01 16:41:38.510720 (MainThread): Parsing macros/materializations/common/merge.sql
2021-06-01 16:41:38.519886 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-06-01 16:41:38.521008 (MainThread): Parsing macros/etc/query.sql
2021-06-01 16:41:38.521669 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-06-01 16:41:38.522295 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-06-01 16:41:38.523838 (MainThread): Parsing macros/etc/datetime.sql
2021-06-01 16:41:38.529740 (MainThread): Parsing macros/etc/is_incremental.sql
2021-06-01 16:41:38.530871 (MainThread): Parsing macros/adapters/common.sql
2021-06-01 16:41:38.561640 (MainThread): Partial parsing not enabled
2021-06-01 16:41:38.578228 (MainThread): Acquiring new bigquery connection "model.resourceplanner.EmployeeDates".
2021-06-01 16:41:38.585528 (MainThread): Acquiring new bigquery connection "model.resourceplanner.trydates".
2021-06-01 16:41:38.588195 (MainThread): Acquiring new bigquery connection "model.resourceplanner.FactTable".
2021-06-01 16:41:38.590716 (MainThread): Acquiring new bigquery connection "model.resourceplanner.my_second_dbt_model".
2021-06-01 16:41:38.593253 (MainThread): Acquiring new bigquery connection "model.resourceplanner.my_first_dbt_model".
2021-06-01 16:41:38.640980 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '2c117727-9649-499f-a68c-c11b7e27a984', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff7067c5e0>]}
2021-06-01 16:41:38.643944 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '2c117727-9649-499f-a68c-c11b7e27a984', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff70671e50>]}
2021-06-01 16:41:38.644089 (MainThread): Found 5 models, 4 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-06-01 16:41:38.644752 (MainThread): 
2021-06-01 16:41:38.645000 (MainThread): Acquiring new bigquery connection "master".
2021-06-01 16:41:38.645667 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_oef-stage".
2021-06-01 16:41:38.645813 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-06-01 16:41:38.731348 (MainThread): Connection 'master' was properly closed.
2021-06-01 16:41:38.731485 (MainThread): Connection 'list_oef-stage' was properly closed.
2021-06-01 16:41:38.731607 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff70767310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff7063deb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff7071af70>]}
2021-06-01 16:41:38.731737 (MainThread): Flushing usage events
2021-06-01 16:41:39.139542 (MainThread): Encountered an error:
2021-06-01 16:41:39.139944 (MainThread): Runtime Error
  Unable to generate access token, if you're using impersonate_service_account, make sure your initial account has the "roles/iam.serviceAccountTokenCreator" role on the account you are trying to impersonate.
  
  ('invalid_grant: Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.', {'error': 'invalid_grant', 'error_description': 'Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.'})
2021-06-01 16:41:39.142030 (MainThread): Traceback (most recent call last):
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 149, in exception_handler
    yield
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/impl.py", line 203, in query_schemas
    return [ds.dataset_id for ds in all_datasets]
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/impl.py", line 203, in <listcomp>
    return [ds.dataset_id for ds in all_datasets]
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/page_iterator.py", line 212, in _items_iter
    for page in self._page_iter(increment=False):
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/page_iterator.py", line 243, in _page_iter
    page = self._next_page()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/page_iterator.py", line 369, in _next_page
    response = self._get_next_page_response()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/page_iterator.py", line 418, in _get_next_page_response
    return self.api_request(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 369, in api_request
    return self._call_api(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 636, in _call_api
    return call()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/_http.py", line 427, in api_request
    response = self._make_request(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/_http.py", line 291, in _make_request
    return self._do_request(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/_http.py", line 329, in _do_request
    return self.http.request(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/auth/transport/requests.py", line 478, in request
    self.credentials.before_request(auth_request, method, url, request_headers)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/auth/credentials.py", line 133, in before_request
    self.refresh(request)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/oauth2/service_account.py", line 376, in refresh
    access_token, expiry, _ = _client.jwt_grant(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/oauth2/_client.py", line 193, in jwt_grant
    response_data = _token_endpoint_request(request, token_uri, body)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/oauth2/_client.py", line 165, in _token_endpoint_request
    _handle_error_response(response_data)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/oauth2/_client.py", line 60, in _handle_error_response
    raise exceptions.RefreshError(error_details, response_data)
google.auth.exceptions.RefreshError: ('invalid_grant: Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.', {'error': 'invalid_grant', 'error_description': 'Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.'})

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/main.py", line 125, in main
    results, succeeded = handle_and_check(args)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/main.py", line 203, in handle_and_check
    task, res = run_from_args(parsed)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/main.py", line 256, in run_from_args
    results = task.run()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/runnable.py", line 426, in run
    result = self.execute_with_hooks(selected_uids)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/runnable.py", line 383, in execute_with_hooks
    self.before_run(adapter, selected_uids)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/run.py", line 409, in before_run
    self.create_schemas(adapter, selected_uids)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/runnable.py", line 515, in create_schemas
    existing_schemas_lowered.update(ls_future.result())
  File "/usr/lib/python3.8/concurrent/futures/_base.py", line 432, in result
    return self.__get_result()
  File "/usr/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
    raise self._exception
  File "/usr/lib/python3.8/concurrent/futures/thread.py", line 57, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/utils.py", line 469, in connected
    return func(*args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/runnable.py", line 492, in list_schemas
    for s in adapter.list_schemas(database_quoted)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/impl.py", line 205, in list_schemas
    return self.connections._retry_and_handle(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 166, in exception_handler
    raise RuntimeException(message)
dbt.exceptions.RuntimeException: Runtime Error
  Unable to generate access token, if you're using impersonate_service_account, make sure your initial account has the "roles/iam.serviceAccountTokenCreator" role on the account you are trying to impersonate.
  
  ('invalid_grant: Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.', {'error': 'invalid_grant', 'error_description': 'Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.'})

2021-06-01 16:43:37.333629 (MainThread): Running with dbt=0.19.1
2021-06-01 16:43:37.509063 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/home/femke/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-06-01 16:43:37.509669 (MainThread): Tracking: tracking
2021-06-01 16:43:37.519789 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2dc0a0ac40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2dc233e220>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2dc233e520>]}
2021-06-01 16:43:37.535530 (MainThread): Partial parsing not enabled
2021-06-01 16:43:37.536284 (MainThread): Parsing macros/catalog.sql
2021-06-01 16:43:37.546693 (MainThread): Parsing macros/adapters.sql
2021-06-01 16:43:37.564559 (MainThread): Parsing macros/etc.sql
2021-06-01 16:43:37.565968 (MainThread): Parsing macros/materializations/snapshot.sql
2021-06-01 16:43:37.567244 (MainThread): Parsing macros/materializations/copy.sql
2021-06-01 16:43:37.570352 (MainThread): Parsing macros/materializations/table.sql
2021-06-01 16:43:37.577285 (MainThread): Parsing macros/materializations/incremental.sql
2021-06-01 16:43:37.585778 (MainThread): Parsing macros/materializations/view.sql
2021-06-01 16:43:37.587714 (MainThread): Parsing macros/materializations/seed.sql
2021-06-01 16:43:37.590042 (MainThread): Parsing macros/core.sql
2021-06-01 16:43:37.592784 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-06-01 16:43:37.593843 (MainThread): Parsing macros/schema_tests/unique.sql
2021-06-01 16:43:37.594960 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-06-01 16:43:37.596283 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-06-01 16:43:37.598068 (MainThread): Parsing macros/materializations/helpers.sql
2021-06-01 16:43:37.613017 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-06-01 16:43:37.614330 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-06-01 16:43:37.618763 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-06-01 16:43:37.632969 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-06-01 16:43:37.653432 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-06-01 16:43:37.654656 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-06-01 16:43:37.667104 (MainThread): Parsing macros/materializations/table/table.sql
2021-06-01 16:43:37.671681 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-06-01 16:43:37.675033 (MainThread): Parsing macros/materializations/view/view.sql
2021-06-01 16:43:37.679264 (MainThread): Parsing macros/materializations/common/merge.sql
2021-06-01 16:43:37.688336 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-06-01 16:43:37.689442 (MainThread): Parsing macros/etc/query.sql
2021-06-01 16:43:37.690128 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-06-01 16:43:37.690779 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-06-01 16:43:37.692214 (MainThread): Parsing macros/etc/datetime.sql
2021-06-01 16:43:37.698020 (MainThread): Parsing macros/etc/is_incremental.sql
2021-06-01 16:43:37.699169 (MainThread): Parsing macros/adapters/common.sql
2021-06-01 16:43:37.729555 (MainThread): Partial parsing not enabled
2021-06-01 16:43:37.745618 (MainThread): Acquiring new bigquery connection "model.resourceplanner.EmployeeDates".
2021-06-01 16:43:37.752472 (MainThread): Acquiring new bigquery connection "model.resourceplanner.trydates".
2021-06-01 16:43:37.754741 (MainThread): Acquiring new bigquery connection "model.resourceplanner.FactTable".
2021-06-01 16:43:37.757053 (MainThread): Acquiring new bigquery connection "model.resourceplanner.my_second_dbt_model".
2021-06-01 16:43:37.759329 (MainThread): Acquiring new bigquery connection "model.resourceplanner.my_first_dbt_model".
2021-06-01 16:43:37.813612 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '8b9b2279-e58e-43b4-8556-06ea6433099c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2dbfa4a760>]}
2021-06-01 16:43:37.816929 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '8b9b2279-e58e-43b4-8556-06ea6433099c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2dbfa3ffa0>]}
2021-06-01 16:43:37.817090 (MainThread): Found 5 models, 4 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-06-01 16:43:37.817806 (MainThread): 
2021-06-01 16:43:37.818057 (MainThread): Acquiring new bigquery connection "master".
2021-06-01 16:43:37.818843 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_oef-stage".
2021-06-01 16:43:37.818974 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-06-01 16:43:37.906760 (MainThread): Connection 'master' was properly closed.
2021-06-01 16:43:37.906886 (MainThread): Connection 'list_oef-stage' was properly closed.
2021-06-01 16:43:37.907001 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2dbfb32460>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2dbf9e83d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2dbfa177c0>]}
2021-06-01 16:43:37.907129 (MainThread): Flushing usage events
2021-06-01 16:43:38.319678 (MainThread): Encountered an error:
2021-06-01 16:43:38.320081 (MainThread): Runtime Error
  Unable to generate access token, if you're using impersonate_service_account, make sure your initial account has the "roles/iam.serviceAccountTokenCreator" role on the account you are trying to impersonate.
  
  ('invalid_grant: Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.', {'error': 'invalid_grant', 'error_description': 'Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.'})
2021-06-01 16:43:38.322076 (MainThread): Traceback (most recent call last):
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 149, in exception_handler
    yield
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/impl.py", line 203, in query_schemas
    return [ds.dataset_id for ds in all_datasets]
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/impl.py", line 203, in <listcomp>
    return [ds.dataset_id for ds in all_datasets]
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/page_iterator.py", line 212, in _items_iter
    for page in self._page_iter(increment=False):
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/page_iterator.py", line 243, in _page_iter
    page = self._next_page()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/page_iterator.py", line 369, in _next_page
    response = self._get_next_page_response()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/page_iterator.py", line 418, in _get_next_page_response
    return self.api_request(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 369, in api_request
    return self._call_api(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 636, in _call_api
    return call()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/_http.py", line 427, in api_request
    response = self._make_request(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/_http.py", line 291, in _make_request
    return self._do_request(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/_http.py", line 329, in _do_request
    return self.http.request(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/auth/transport/requests.py", line 478, in request
    self.credentials.before_request(auth_request, method, url, request_headers)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/auth/credentials.py", line 133, in before_request
    self.refresh(request)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/oauth2/service_account.py", line 376, in refresh
    access_token, expiry, _ = _client.jwt_grant(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/oauth2/_client.py", line 193, in jwt_grant
    response_data = _token_endpoint_request(request, token_uri, body)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/oauth2/_client.py", line 165, in _token_endpoint_request
    _handle_error_response(response_data)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/oauth2/_client.py", line 60, in _handle_error_response
    raise exceptions.RefreshError(error_details, response_data)
google.auth.exceptions.RefreshError: ('invalid_grant: Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.', {'error': 'invalid_grant', 'error_description': 'Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.'})

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/main.py", line 125, in main
    results, succeeded = handle_and_check(args)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/main.py", line 203, in handle_and_check
    task, res = run_from_args(parsed)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/main.py", line 256, in run_from_args
    results = task.run()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/runnable.py", line 426, in run
    result = self.execute_with_hooks(selected_uids)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/runnable.py", line 383, in execute_with_hooks
    self.before_run(adapter, selected_uids)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/run.py", line 409, in before_run
    self.create_schemas(adapter, selected_uids)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/runnable.py", line 515, in create_schemas
    existing_schemas_lowered.update(ls_future.result())
  File "/usr/lib/python3.8/concurrent/futures/_base.py", line 432, in result
    return self.__get_result()
  File "/usr/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
    raise self._exception
  File "/usr/lib/python3.8/concurrent/futures/thread.py", line 57, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/utils.py", line 469, in connected
    return func(*args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/runnable.py", line 492, in list_schemas
    for s in adapter.list_schemas(database_quoted)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/impl.py", line 205, in list_schemas
    return self.connections._retry_and_handle(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 166, in exception_handler
    raise RuntimeException(message)
dbt.exceptions.RuntimeException: Runtime Error
  Unable to generate access token, if you're using impersonate_service_account, make sure your initial account has the "roles/iam.serviceAccountTokenCreator" role on the account you are trying to impersonate.
  
  ('invalid_grant: Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.', {'error': 'invalid_grant', 'error_description': 'Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.'})

2021-06-01 16:45:30.519323 (MainThread): Running with dbt=0.19.1
2021-06-01 16:45:30.696848 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/home/femke/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-06-01 16:45:30.697451 (MainThread): Tracking: tracking
2021-06-01 16:45:30.707544 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9f381aafa0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9f38229490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9f381bc4f0>]}
2021-06-01 16:45:30.723285 (MainThread): Partial parsing not enabled
2021-06-01 16:45:30.724062 (MainThread): Parsing macros/catalog.sql
2021-06-01 16:45:30.732433 (MainThread): Parsing macros/adapters.sql
2021-06-01 16:45:30.751494 (MainThread): Parsing macros/etc.sql
2021-06-01 16:45:30.752838 (MainThread): Parsing macros/materializations/snapshot.sql
2021-06-01 16:45:30.754006 (MainThread): Parsing macros/materializations/copy.sql
2021-06-01 16:45:30.757097 (MainThread): Parsing macros/materializations/table.sql
2021-06-01 16:45:30.763816 (MainThread): Parsing macros/materializations/incremental.sql
2021-06-01 16:45:30.772188 (MainThread): Parsing macros/materializations/view.sql
2021-06-01 16:45:30.774061 (MainThread): Parsing macros/materializations/seed.sql
2021-06-01 16:45:30.776350 (MainThread): Parsing macros/core.sql
2021-06-01 16:45:30.778912 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-06-01 16:45:30.779900 (MainThread): Parsing macros/schema_tests/unique.sql
2021-06-01 16:45:30.781000 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-06-01 16:45:30.782208 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-06-01 16:45:30.783998 (MainThread): Parsing macros/materializations/helpers.sql
2021-06-01 16:45:30.789825 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-06-01 16:45:30.791060 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-06-01 16:45:30.795290 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-06-01 16:45:30.808827 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-06-01 16:45:30.828850 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-06-01 16:45:30.830043 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-06-01 16:45:30.842200 (MainThread): Parsing macros/materializations/table/table.sql
2021-06-01 16:45:30.846733 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-06-01 16:45:30.850076 (MainThread): Parsing macros/materializations/view/view.sql
2021-06-01 16:45:30.854244 (MainThread): Parsing macros/materializations/common/merge.sql
2021-06-01 16:45:30.863216 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-06-01 16:45:30.864307 (MainThread): Parsing macros/etc/query.sql
2021-06-01 16:45:30.864993 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-06-01 16:45:30.865605 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-06-01 16:45:30.866982 (MainThread): Parsing macros/etc/datetime.sql
2021-06-01 16:45:30.872733 (MainThread): Parsing macros/etc/is_incremental.sql
2021-06-01 16:45:30.873822 (MainThread): Parsing macros/adapters/common.sql
2021-06-01 16:45:30.904579 (MainThread): Partial parsing not enabled
2021-06-01 16:45:30.920819 (MainThread): Acquiring new bigquery connection "model.resourceplanner.EmployeeDates".
2021-06-01 16:45:30.927789 (MainThread): Acquiring new bigquery connection "model.resourceplanner.trydates".
2021-06-01 16:45:30.930115 (MainThread): Acquiring new bigquery connection "model.resourceplanner.FactTable".
2021-06-01 16:45:30.932458 (MainThread): Acquiring new bigquery connection "model.resourceplanner.my_second_dbt_model".
2021-06-01 16:45:30.934769 (MainThread): Acquiring new bigquery connection "model.resourceplanner.my_first_dbt_model".
2021-06-01 16:45:30.979542 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'bd86683d-2689-4254-b9e0-67e68eb72ff9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9f358c7310>]}
2021-06-01 16:45:30.982517 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'bd86683d-2689-4254-b9e0-67e68eb72ff9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9f358bcee0>]}
2021-06-01 16:45:30.982661 (MainThread): Found 5 models, 4 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-06-01 16:45:30.983331 (MainThread): 
2021-06-01 16:45:30.983553 (MainThread): Acquiring new bigquery connection "master".
2021-06-01 16:45:30.984206 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_oef-stage".
2021-06-01 16:45:30.984329 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-06-01 16:45:31.073983 (MainThread): Connection 'master' was properly closed.
2021-06-01 16:45:31.074098 (MainThread): Connection 'list_oef-stage' was properly closed.
2021-06-01 16:45:31.074219 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9f359b23a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9f35888f40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9f359e3ee0>]}
2021-06-01 16:45:31.074343 (MainThread): Flushing usage events
2021-06-01 16:45:31.472830 (MainThread): Encountered an error:
2021-06-01 16:45:31.473219 (MainThread): Runtime Error
  Unable to generate access token, if you're using impersonate_service_account, make sure your initial account has the "roles/iam.serviceAccountTokenCreator" role on the account you are trying to impersonate.
  
  ('invalid_grant: Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.', {'error': 'invalid_grant', 'error_description': 'Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.'})
2021-06-01 16:45:31.474940 (MainThread): Traceback (most recent call last):
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 149, in exception_handler
    yield
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/impl.py", line 203, in query_schemas
    return [ds.dataset_id for ds in all_datasets]
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/impl.py", line 203, in <listcomp>
    return [ds.dataset_id for ds in all_datasets]
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/page_iterator.py", line 212, in _items_iter
    for page in self._page_iter(increment=False):
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/page_iterator.py", line 243, in _page_iter
    page = self._next_page()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/page_iterator.py", line 369, in _next_page
    response = self._get_next_page_response()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/page_iterator.py", line 418, in _get_next_page_response
    return self.api_request(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 369, in api_request
    return self._call_api(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 636, in _call_api
    return call()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/_http.py", line 427, in api_request
    response = self._make_request(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/_http.py", line 291, in _make_request
    return self._do_request(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/_http.py", line 329, in _do_request
    return self.http.request(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/auth/transport/requests.py", line 478, in request
    self.credentials.before_request(auth_request, method, url, request_headers)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/auth/credentials.py", line 133, in before_request
    self.refresh(request)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/oauth2/service_account.py", line 376, in refresh
    access_token, expiry, _ = _client.jwt_grant(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/oauth2/_client.py", line 193, in jwt_grant
    response_data = _token_endpoint_request(request, token_uri, body)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/oauth2/_client.py", line 165, in _token_endpoint_request
    _handle_error_response(response_data)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/oauth2/_client.py", line 60, in _handle_error_response
    raise exceptions.RefreshError(error_details, response_data)
google.auth.exceptions.RefreshError: ('invalid_grant: Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.', {'error': 'invalid_grant', 'error_description': 'Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.'})

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/main.py", line 125, in main
    results, succeeded = handle_and_check(args)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/main.py", line 203, in handle_and_check
    task, res = run_from_args(parsed)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/main.py", line 256, in run_from_args
    results = task.run()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/runnable.py", line 426, in run
    result = self.execute_with_hooks(selected_uids)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/runnable.py", line 383, in execute_with_hooks
    self.before_run(adapter, selected_uids)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/run.py", line 409, in before_run
    self.create_schemas(adapter, selected_uids)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/runnable.py", line 515, in create_schemas
    existing_schemas_lowered.update(ls_future.result())
  File "/usr/lib/python3.8/concurrent/futures/_base.py", line 432, in result
    return self.__get_result()
  File "/usr/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
    raise self._exception
  File "/usr/lib/python3.8/concurrent/futures/thread.py", line 57, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/utils.py", line 469, in connected
    return func(*args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/runnable.py", line 492, in list_schemas
    for s in adapter.list_schemas(database_quoted)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/impl.py", line 205, in list_schemas
    return self.connections._retry_and_handle(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 166, in exception_handler
    raise RuntimeException(message)
dbt.exceptions.RuntimeException: Runtime Error
  Unable to generate access token, if you're using impersonate_service_account, make sure your initial account has the "roles/iam.serviceAccountTokenCreator" role on the account you are trying to impersonate.
  
  ('invalid_grant: Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.', {'error': 'invalid_grant', 'error_description': 'Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.'})

2021-06-01 16:45:33.848862 (MainThread): Running with dbt=0.19.1
2021-06-01 16:45:34.020754 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/home/femke/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-06-01 16:45:34.021323 (MainThread): Tracking: tracking
2021-06-01 16:45:34.032391 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb96e332e20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb96fca60d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb96fca64f0>]}
2021-06-01 16:45:34.046452 (MainThread): Partial parsing not enabled
2021-06-01 16:45:34.047173 (MainThread): Parsing macros/catalog.sql
2021-06-01 16:45:34.055505 (MainThread): Parsing macros/adapters.sql
2021-06-01 16:45:34.075282 (MainThread): Parsing macros/etc.sql
2021-06-01 16:45:34.076641 (MainThread): Parsing macros/materializations/snapshot.sql
2021-06-01 16:45:34.077806 (MainThread): Parsing macros/materializations/copy.sql
2021-06-01 16:45:34.080961 (MainThread): Parsing macros/materializations/table.sql
2021-06-01 16:45:34.087899 (MainThread): Parsing macros/materializations/incremental.sql
2021-06-01 16:45:34.096389 (MainThread): Parsing macros/materializations/view.sql
2021-06-01 16:45:34.098274 (MainThread): Parsing macros/materializations/seed.sql
2021-06-01 16:45:34.100606 (MainThread): Parsing macros/core.sql
2021-06-01 16:45:34.103240 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-06-01 16:45:34.104238 (MainThread): Parsing macros/schema_tests/unique.sql
2021-06-01 16:45:34.105371 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-06-01 16:45:34.106633 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-06-01 16:45:34.108429 (MainThread): Parsing macros/materializations/helpers.sql
2021-06-01 16:45:34.114320 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-06-01 16:45:34.115628 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-06-01 16:45:34.120336 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-06-01 16:45:34.134222 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-06-01 16:45:34.154356 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-06-01 16:45:34.155586 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-06-01 16:45:34.167887 (MainThread): Parsing macros/materializations/table/table.sql
2021-06-01 16:45:34.172423 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-06-01 16:45:34.175796 (MainThread): Parsing macros/materializations/view/view.sql
2021-06-01 16:45:34.180095 (MainThread): Parsing macros/materializations/common/merge.sql
2021-06-01 16:45:34.189152 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-06-01 16:45:34.190274 (MainThread): Parsing macros/etc/query.sql
2021-06-01 16:45:34.190981 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-06-01 16:45:34.191579 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-06-01 16:45:34.192943 (MainThread): Parsing macros/etc/datetime.sql
2021-06-01 16:45:34.209654 (MainThread): Parsing macros/etc/is_incremental.sql
2021-06-01 16:45:34.210805 (MainThread): Parsing macros/adapters/common.sql
2021-06-01 16:45:34.241519 (MainThread): Partial parsing not enabled
2021-06-01 16:45:34.257734 (MainThread): Acquiring new bigquery connection "model.resourceplanner.EmployeeDates".
2021-06-01 16:45:34.266047 (MainThread): Acquiring new bigquery connection "model.resourceplanner.trydates".
2021-06-01 16:45:34.268437 (MainThread): Acquiring new bigquery connection "model.resourceplanner.FactTable".
2021-06-01 16:45:34.270756 (MainThread): Acquiring new bigquery connection "model.resourceplanner.my_second_dbt_model".
2021-06-01 16:45:34.272960 (MainThread): Acquiring new bigquery connection "model.resourceplanner.my_first_dbt_model".
2021-06-01 16:45:34.318702 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '806644e1-af71-4344-9443-d652e3eb17ea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb96d370700>]}
2021-06-01 16:45:34.321714 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '806644e1-af71-4344-9443-d652e3eb17ea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb96d365f70>]}
2021-06-01 16:45:34.321859 (MainThread): Found 5 models, 4 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-06-01 16:45:34.322594 (MainThread): 
2021-06-01 16:45:34.322820 (MainThread): Acquiring new bigquery connection "master".
2021-06-01 16:45:34.323479 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_oef-stage".
2021-06-01 16:45:34.323598 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-06-01 16:45:34.383955 (MainThread): Connection 'master' was properly closed.
2021-06-01 16:45:34.384077 (MainThread): Connection 'list_oef-stage' was properly closed.
2021-06-01 16:45:34.384185 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb96d45a430>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb96d332fd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb96d41c5e0>]}
2021-06-01 16:45:34.384309 (MainThread): Flushing usage events
2021-06-01 16:45:34.763025 (MainThread): Encountered an error:
2021-06-01 16:45:34.763429 (MainThread): Runtime Error
  Unable to generate access token, if you're using impersonate_service_account, make sure your initial account has the "roles/iam.serviceAccountTokenCreator" role on the account you are trying to impersonate.
  
  ('invalid_grant: Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.', {'error': 'invalid_grant', 'error_description': 'Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.'})
2021-06-01 16:45:34.765098 (MainThread): Traceback (most recent call last):
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 149, in exception_handler
    yield
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/impl.py", line 203, in query_schemas
    return [ds.dataset_id for ds in all_datasets]
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/impl.py", line 203, in <listcomp>
    return [ds.dataset_id for ds in all_datasets]
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/page_iterator.py", line 212, in _items_iter
    for page in self._page_iter(increment=False):
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/page_iterator.py", line 243, in _page_iter
    page = self._next_page()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/page_iterator.py", line 369, in _next_page
    response = self._get_next_page_response()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/page_iterator.py", line 418, in _get_next_page_response
    return self.api_request(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 369, in api_request
    return self._call_api(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 636, in _call_api
    return call()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/_http.py", line 427, in api_request
    response = self._make_request(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/_http.py", line 291, in _make_request
    return self._do_request(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/_http.py", line 329, in _do_request
    return self.http.request(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/auth/transport/requests.py", line 478, in request
    self.credentials.before_request(auth_request, method, url, request_headers)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/auth/credentials.py", line 133, in before_request
    self.refresh(request)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/oauth2/service_account.py", line 376, in refresh
    access_token, expiry, _ = _client.jwt_grant(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/oauth2/_client.py", line 193, in jwt_grant
    response_data = _token_endpoint_request(request, token_uri, body)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/oauth2/_client.py", line 165, in _token_endpoint_request
    _handle_error_response(response_data)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/oauth2/_client.py", line 60, in _handle_error_response
    raise exceptions.RefreshError(error_details, response_data)
google.auth.exceptions.RefreshError: ('invalid_grant: Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.', {'error': 'invalid_grant', 'error_description': 'Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.'})

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/main.py", line 125, in main
    results, succeeded = handle_and_check(args)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/main.py", line 203, in handle_and_check
    task, res = run_from_args(parsed)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/main.py", line 256, in run_from_args
    results = task.run()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/runnable.py", line 426, in run
    result = self.execute_with_hooks(selected_uids)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/runnable.py", line 383, in execute_with_hooks
    self.before_run(adapter, selected_uids)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/run.py", line 409, in before_run
    self.create_schemas(adapter, selected_uids)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/runnable.py", line 515, in create_schemas
    existing_schemas_lowered.update(ls_future.result())
  File "/usr/lib/python3.8/concurrent/futures/_base.py", line 432, in result
    return self.__get_result()
  File "/usr/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
    raise self._exception
  File "/usr/lib/python3.8/concurrent/futures/thread.py", line 57, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/utils.py", line 469, in connected
    return func(*args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/runnable.py", line 492, in list_schemas
    for s in adapter.list_schemas(database_quoted)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/impl.py", line 205, in list_schemas
    return self.connections._retry_and_handle(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 166, in exception_handler
    raise RuntimeException(message)
dbt.exceptions.RuntimeException: Runtime Error
  Unable to generate access token, if you're using impersonate_service_account, make sure your initial account has the "roles/iam.serviceAccountTokenCreator" role on the account you are trying to impersonate.
  
  ('invalid_grant: Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.', {'error': 'invalid_grant', 'error_description': 'Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.'})

2021-06-01 16:45:36.500320 (MainThread): Running with dbt=0.19.1
2021-06-01 16:45:36.693287 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/home/femke/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-06-01 16:45:36.693878 (MainThread): Tracking: tracking
2021-06-01 16:45:36.704173 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f00acf08eb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f00ae83c0d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f00ae83c580>]}
2021-06-01 16:45:36.719735 (MainThread): Partial parsing not enabled
2021-06-01 16:45:36.720428 (MainThread): Parsing macros/catalog.sql
2021-06-01 16:45:36.729014 (MainThread): Parsing macros/adapters.sql
2021-06-01 16:45:36.751343 (MainThread): Parsing macros/etc.sql
2021-06-01 16:45:36.752868 (MainThread): Parsing macros/materializations/snapshot.sql
2021-06-01 16:45:36.754100 (MainThread): Parsing macros/materializations/copy.sql
2021-06-01 16:45:36.757686 (MainThread): Parsing macros/materializations/table.sql
2021-06-01 16:45:36.765301 (MainThread): Parsing macros/materializations/incremental.sql
2021-06-01 16:45:36.774621 (MainThread): Parsing macros/materializations/view.sql
2021-06-01 16:45:36.778093 (MainThread): Parsing macros/materializations/seed.sql
2021-06-01 16:45:36.781057 (MainThread): Parsing macros/core.sql
2021-06-01 16:45:36.784152 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-06-01 16:45:36.785300 (MainThread): Parsing macros/schema_tests/unique.sql
2021-06-01 16:45:36.786489 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-06-01 16:45:36.787803 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-06-01 16:45:36.790406 (MainThread): Parsing macros/materializations/helpers.sql
2021-06-01 16:45:36.797115 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-06-01 16:45:36.798536 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-06-01 16:45:36.803712 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-06-01 16:45:36.818632 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-06-01 16:45:36.839229 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-06-01 16:45:36.840464 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-06-01 16:45:36.853213 (MainThread): Parsing macros/materializations/table/table.sql
2021-06-01 16:45:36.857838 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-06-01 16:45:36.861186 (MainThread): Parsing macros/materializations/view/view.sql
2021-06-01 16:45:36.865532 (MainThread): Parsing macros/materializations/common/merge.sql
2021-06-01 16:45:36.875108 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-06-01 16:45:36.876225 (MainThread): Parsing macros/etc/query.sql
2021-06-01 16:45:36.876930 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-06-01 16:45:36.877553 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-06-01 16:45:36.879149 (MainThread): Parsing macros/etc/datetime.sql
2021-06-01 16:45:36.885336 (MainThread): Parsing macros/etc/is_incremental.sql
2021-06-01 16:45:36.886504 (MainThread): Parsing macros/adapters/common.sql
2021-06-01 16:45:36.918874 (MainThread): Partial parsing not enabled
2021-06-01 16:45:36.935624 (MainThread): Acquiring new bigquery connection "model.resourceplanner.EmployeeDates".
2021-06-01 16:45:36.942762 (MainThread): Acquiring new bigquery connection "model.resourceplanner.trydates".
2021-06-01 16:45:36.945149 (MainThread): Acquiring new bigquery connection "model.resourceplanner.FactTable".
2021-06-01 16:45:36.947728 (MainThread): Acquiring new bigquery connection "model.resourceplanner.my_second_dbt_model".
2021-06-01 16:45:36.950550 (MainThread): Acquiring new bigquery connection "model.resourceplanner.my_first_dbt_model".
2021-06-01 16:45:36.997459 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '71679d0e-3066-40cc-a0a9-148887d95d34', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f00abf467c0>]}
2021-06-01 16:45:37.000376 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '71679d0e-3066-40cc-a0a9-148887d95d34', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f00abf33f70>]}
2021-06-01 16:45:37.000529 (MainThread): Found 5 models, 4 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-06-01 16:45:37.001180 (MainThread): 
2021-06-01 16:45:37.001428 (MainThread): Acquiring new bigquery connection "master".
2021-06-01 16:45:37.002102 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_oef-stage".
2021-06-01 16:45:37.002226 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-06-01 16:45:37.066962 (MainThread): Connection 'master' was properly closed.
2021-06-01 16:45:37.067077 (MainThread): Connection 'list_oef-stage' was properly closed.
2021-06-01 16:45:37.067191 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f00ac0304c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f00abeed460>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f00abf997c0>]}
2021-06-01 16:45:37.067352 (MainThread): Flushing usage events
2021-06-01 16:45:37.447269 (MainThread): Encountered an error:
2021-06-01 16:45:37.447722 (MainThread): Runtime Error
  Unable to generate access token, if you're using impersonate_service_account, make sure your initial account has the "roles/iam.serviceAccountTokenCreator" role on the account you are trying to impersonate.
  
  ('invalid_grant: Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.', {'error': 'invalid_grant', 'error_description': 'Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.'})
2021-06-01 16:45:37.449500 (MainThread): Traceback (most recent call last):
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 149, in exception_handler
    yield
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/impl.py", line 203, in query_schemas
    return [ds.dataset_id for ds in all_datasets]
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/impl.py", line 203, in <listcomp>
    return [ds.dataset_id for ds in all_datasets]
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/page_iterator.py", line 212, in _items_iter
    for page in self._page_iter(increment=False):
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/page_iterator.py", line 243, in _page_iter
    page = self._next_page()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/page_iterator.py", line 369, in _next_page
    response = self._get_next_page_response()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/page_iterator.py", line 418, in _get_next_page_response
    return self.api_request(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 369, in api_request
    return self._call_api(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 636, in _call_api
    return call()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/_http.py", line 427, in api_request
    response = self._make_request(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/_http.py", line 291, in _make_request
    return self._do_request(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/_http.py", line 329, in _do_request
    return self.http.request(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/auth/transport/requests.py", line 478, in request
    self.credentials.before_request(auth_request, method, url, request_headers)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/auth/credentials.py", line 133, in before_request
    self.refresh(request)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/oauth2/service_account.py", line 376, in refresh
    access_token, expiry, _ = _client.jwt_grant(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/oauth2/_client.py", line 193, in jwt_grant
    response_data = _token_endpoint_request(request, token_uri, body)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/oauth2/_client.py", line 165, in _token_endpoint_request
    _handle_error_response(response_data)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/oauth2/_client.py", line 60, in _handle_error_response
    raise exceptions.RefreshError(error_details, response_data)
google.auth.exceptions.RefreshError: ('invalid_grant: Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.', {'error': 'invalid_grant', 'error_description': 'Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.'})

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/main.py", line 125, in main
    results, succeeded = handle_and_check(args)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/main.py", line 203, in handle_and_check
    task, res = run_from_args(parsed)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/main.py", line 256, in run_from_args
    results = task.run()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/runnable.py", line 426, in run
    result = self.execute_with_hooks(selected_uids)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/runnable.py", line 383, in execute_with_hooks
    self.before_run(adapter, selected_uids)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/run.py", line 409, in before_run
    self.create_schemas(adapter, selected_uids)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/runnable.py", line 515, in create_schemas
    existing_schemas_lowered.update(ls_future.result())
  File "/usr/lib/python3.8/concurrent/futures/_base.py", line 432, in result
    return self.__get_result()
  File "/usr/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
    raise self._exception
  File "/usr/lib/python3.8/concurrent/futures/thread.py", line 57, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/utils.py", line 469, in connected
    return func(*args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/runnable.py", line 492, in list_schemas
    for s in adapter.list_schemas(database_quoted)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/impl.py", line 205, in list_schemas
    return self.connections._retry_and_handle(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 166, in exception_handler
    raise RuntimeException(message)
dbt.exceptions.RuntimeException: Runtime Error
  Unable to generate access token, if you're using impersonate_service_account, make sure your initial account has the "roles/iam.serviceAccountTokenCreator" role on the account you are trying to impersonate.
  
  ('invalid_grant: Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.', {'error': 'invalid_grant', 'error_description': 'Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.'})

2021-06-01 16:45:39.290347 (MainThread): Running with dbt=0.19.1
2021-06-01 16:45:39.545425 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/home/femke/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-06-01 16:45:39.546036 (MainThread): Tracking: tracking
2021-06-01 16:45:39.556524 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcebf4f2e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcec0e670a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcec0e67520>]}
2021-06-01 16:45:39.571329 (MainThread): Partial parsing not enabled
2021-06-01 16:45:39.572142 (MainThread): Parsing macros/catalog.sql
2021-06-01 16:45:39.580754 (MainThread): Parsing macros/adapters.sql
2021-06-01 16:45:39.611629 (MainThread): Parsing macros/etc.sql
2021-06-01 16:45:39.613082 (MainThread): Parsing macros/materializations/snapshot.sql
2021-06-01 16:45:39.614330 (MainThread): Parsing macros/materializations/copy.sql
2021-06-01 16:45:39.617595 (MainThread): Parsing macros/materializations/table.sql
2021-06-01 16:45:39.624727 (MainThread): Parsing macros/materializations/incremental.sql
2021-06-01 16:45:39.633572 (MainThread): Parsing macros/materializations/view.sql
2021-06-01 16:45:39.635659 (MainThread): Parsing macros/materializations/seed.sql
2021-06-01 16:45:39.638064 (MainThread): Parsing macros/core.sql
2021-06-01 16:45:39.640802 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-06-01 16:45:39.641886 (MainThread): Parsing macros/schema_tests/unique.sql
2021-06-01 16:45:39.643222 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-06-01 16:45:39.644478 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-06-01 16:45:39.646362 (MainThread): Parsing macros/materializations/helpers.sql
2021-06-01 16:45:39.652591 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-06-01 16:45:39.653857 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-06-01 16:45:39.658321 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-06-01 16:45:39.672299 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-06-01 16:45:39.692970 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-06-01 16:45:39.694161 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-06-01 16:45:39.706661 (MainThread): Parsing macros/materializations/table/table.sql
2021-06-01 16:45:39.711208 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-06-01 16:45:39.714751 (MainThread): Parsing macros/materializations/view/view.sql
2021-06-01 16:45:39.718940 (MainThread): Parsing macros/materializations/common/merge.sql
2021-06-01 16:45:39.728363 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-06-01 16:45:39.729476 (MainThread): Parsing macros/etc/query.sql
2021-06-01 16:45:39.730162 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-06-01 16:45:39.730816 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-06-01 16:45:39.732197 (MainThread): Parsing macros/etc/datetime.sql
2021-06-01 16:45:39.737990 (MainThread): Parsing macros/etc/is_incremental.sql
2021-06-01 16:45:39.739156 (MainThread): Parsing macros/adapters/common.sql
2021-06-01 16:45:39.770547 (MainThread): Partial parsing not enabled
2021-06-01 16:45:39.786930 (MainThread): Acquiring new bigquery connection "model.resourceplanner.EmployeeDates".
2021-06-01 16:45:39.793770 (MainThread): Acquiring new bigquery connection "model.resourceplanner.trydates".
2021-06-01 16:45:39.796137 (MainThread): Acquiring new bigquery connection "model.resourceplanner.FactTable".
2021-06-01 16:45:39.798538 (MainThread): Acquiring new bigquery connection "model.resourceplanner.my_second_dbt_model".
2021-06-01 16:45:39.800813 (MainThread): Acquiring new bigquery connection "model.resourceplanner.my_first_dbt_model".
2021-06-01 16:45:39.846921 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '3ed446cc-dd97-454d-b2a3-7b4f3c176d3a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcebe531760>]}
2021-06-01 16:45:39.849952 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '3ed446cc-dd97-454d-b2a3-7b4f3c176d3a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcebe525fa0>]}
2021-06-01 16:45:39.850158 (MainThread): Found 5 models, 4 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-06-01 16:45:39.850891 (MainThread): 
2021-06-01 16:45:39.851132 (MainThread): Acquiring new bigquery connection "master".
2021-06-01 16:45:39.851825 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_oef-stage".
2021-06-01 16:45:39.851951 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-06-01 16:45:39.919146 (MainThread): Connection 'master' was properly closed.
2021-06-01 16:45:39.919266 (MainThread): Connection 'list_oef-stage' was properly closed.
2021-06-01 16:45:39.919378 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcebe61a460>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcebe4cf3d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcebe4fe7c0>]}
2021-06-01 16:45:39.919539 (MainThread): Flushing usage events
2021-06-01 16:45:40.299760 (MainThread): Encountered an error:
2021-06-01 16:45:40.300184 (MainThread): Runtime Error
  Unable to generate access token, if you're using impersonate_service_account, make sure your initial account has the "roles/iam.serviceAccountTokenCreator" role on the account you are trying to impersonate.
  
  ('invalid_grant: Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.', {'error': 'invalid_grant', 'error_description': 'Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.'})
2021-06-01 16:45:40.301833 (MainThread): Traceback (most recent call last):
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 149, in exception_handler
    yield
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/impl.py", line 203, in query_schemas
    return [ds.dataset_id for ds in all_datasets]
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/impl.py", line 203, in <listcomp>
    return [ds.dataset_id for ds in all_datasets]
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/page_iterator.py", line 212, in _items_iter
    for page in self._page_iter(increment=False):
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/page_iterator.py", line 243, in _page_iter
    page = self._next_page()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/page_iterator.py", line 369, in _next_page
    response = self._get_next_page_response()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/page_iterator.py", line 418, in _get_next_page_response
    return self.api_request(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 369, in api_request
    return self._call_api(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 636, in _call_api
    return call()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/_http.py", line 427, in api_request
    response = self._make_request(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/_http.py", line 291, in _make_request
    return self._do_request(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/_http.py", line 329, in _do_request
    return self.http.request(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/auth/transport/requests.py", line 478, in request
    self.credentials.before_request(auth_request, method, url, request_headers)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/auth/credentials.py", line 133, in before_request
    self.refresh(request)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/oauth2/service_account.py", line 376, in refresh
    access_token, expiry, _ = _client.jwt_grant(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/oauth2/_client.py", line 193, in jwt_grant
    response_data = _token_endpoint_request(request, token_uri, body)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/oauth2/_client.py", line 165, in _token_endpoint_request
    _handle_error_response(response_data)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/oauth2/_client.py", line 60, in _handle_error_response
    raise exceptions.RefreshError(error_details, response_data)
google.auth.exceptions.RefreshError: ('invalid_grant: Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.', {'error': 'invalid_grant', 'error_description': 'Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.'})

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/main.py", line 125, in main
    results, succeeded = handle_and_check(args)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/main.py", line 203, in handle_and_check
    task, res = run_from_args(parsed)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/main.py", line 256, in run_from_args
    results = task.run()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/runnable.py", line 426, in run
    result = self.execute_with_hooks(selected_uids)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/runnable.py", line 383, in execute_with_hooks
    self.before_run(adapter, selected_uids)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/run.py", line 409, in before_run
    self.create_schemas(adapter, selected_uids)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/runnable.py", line 515, in create_schemas
    existing_schemas_lowered.update(ls_future.result())
  File "/usr/lib/python3.8/concurrent/futures/_base.py", line 432, in result
    return self.__get_result()
  File "/usr/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
    raise self._exception
  File "/usr/lib/python3.8/concurrent/futures/thread.py", line 57, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/utils.py", line 469, in connected
    return func(*args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/runnable.py", line 492, in list_schemas
    for s in adapter.list_schemas(database_quoted)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/impl.py", line 205, in list_schemas
    return self.connections._retry_and_handle(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 166, in exception_handler
    raise RuntimeException(message)
dbt.exceptions.RuntimeException: Runtime Error
  Unable to generate access token, if you're using impersonate_service_account, make sure your initial account has the "roles/iam.serviceAccountTokenCreator" role on the account you are trying to impersonate.
  
  ('invalid_grant: Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.', {'error': 'invalid_grant', 'error_description': 'Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.'})

2021-06-01 16:45:41.651484 (MainThread): Running with dbt=0.19.1
2021-06-01 16:45:41.831308 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/home/femke/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-06-01 16:45:41.832121 (MainThread): Tracking: tracking
2021-06-01 16:45:41.842283 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f39140a1ee0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3915a152b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3915a155b0>]}
2021-06-01 16:45:41.857583 (MainThread): Partial parsing not enabled
2021-06-01 16:45:41.858293 (MainThread): Parsing macros/catalog.sql
2021-06-01 16:45:41.866631 (MainThread): Parsing macros/adapters.sql
2021-06-01 16:45:41.887052 (MainThread): Parsing macros/etc.sql
2021-06-01 16:45:41.888469 (MainThread): Parsing macros/materializations/snapshot.sql
2021-06-01 16:45:41.889671 (MainThread): Parsing macros/materializations/copy.sql
2021-06-01 16:45:41.892757 (MainThread): Parsing macros/materializations/table.sql
2021-06-01 16:45:41.899746 (MainThread): Parsing macros/materializations/incremental.sql
2021-06-01 16:45:41.908198 (MainThread): Parsing macros/materializations/view.sql
2021-06-01 16:45:41.910106 (MainThread): Parsing macros/materializations/seed.sql
2021-06-01 16:45:41.912440 (MainThread): Parsing macros/core.sql
2021-06-01 16:45:41.915247 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-06-01 16:45:41.916265 (MainThread): Parsing macros/schema_tests/unique.sql
2021-06-01 16:45:41.917402 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-06-01 16:45:41.918638 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-06-01 16:45:41.920444 (MainThread): Parsing macros/materializations/helpers.sql
2021-06-01 16:45:41.926475 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-06-01 16:45:41.927739 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-06-01 16:45:41.932052 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-06-01 16:45:41.946214 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-06-01 16:45:41.966807 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-06-01 16:45:41.967980 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-06-01 16:45:41.980391 (MainThread): Parsing macros/materializations/table/table.sql
2021-06-01 16:45:41.984985 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-06-01 16:45:41.988355 (MainThread): Parsing macros/materializations/view/view.sql
2021-06-01 16:45:41.992626 (MainThread): Parsing macros/materializations/common/merge.sql
2021-06-01 16:45:42.001977 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-06-01 16:45:42.003119 (MainThread): Parsing macros/etc/query.sql
2021-06-01 16:45:42.003822 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-06-01 16:45:42.004451 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-06-01 16:45:42.005907 (MainThread): Parsing macros/etc/datetime.sql
2021-06-01 16:45:42.011805 (MainThread): Parsing macros/etc/is_incremental.sql
2021-06-01 16:45:42.012945 (MainThread): Parsing macros/adapters/common.sql
2021-06-01 16:45:42.044496 (MainThread): Partial parsing not enabled
2021-06-01 16:45:42.060750 (MainThread): Acquiring new bigquery connection "model.resourceplanner.EmployeeDates".
2021-06-01 16:45:42.067592 (MainThread): Acquiring new bigquery connection "model.resourceplanner.trydates".
2021-06-01 16:45:42.069915 (MainThread): Acquiring new bigquery connection "model.resourceplanner.FactTable".
2021-06-01 16:45:42.072375 (MainThread): Acquiring new bigquery connection "model.resourceplanner.my_second_dbt_model".
2021-06-01 16:45:42.074812 (MainThread): Acquiring new bigquery connection "model.resourceplanner.my_first_dbt_model".
2021-06-01 16:45:42.119799 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '2caaef3b-1119-4c25-8080-95bbcbc21056', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f39130cdf70>]}
2021-06-01 16:45:42.122768 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '2caaef3b-1119-4c25-8080-95bbcbc21056', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f39130e07f0>]}
2021-06-01 16:45:42.122913 (MainThread): Found 5 models, 4 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-06-01 16:45:42.123582 (MainThread): 
2021-06-01 16:45:42.123829 (MainThread): Acquiring new bigquery connection "master".
2021-06-01 16:45:42.124468 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_oef-stage".
2021-06-01 16:45:42.124609 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-06-01 16:45:42.186375 (MainThread): Connection 'master' was properly closed.
2021-06-01 16:45:42.186492 (MainThread): Connection 'list_oef-stage' was properly closed.
2021-06-01 16:45:42.186604 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f39131ca4f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f39130f2fd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f391313ab80>]}
2021-06-01 16:45:42.186753 (MainThread): Flushing usage events
2021-06-01 16:45:42.565164 (MainThread): Encountered an error:
2021-06-01 16:45:42.565576 (MainThread): Runtime Error
  Unable to generate access token, if you're using impersonate_service_account, make sure your initial account has the "roles/iam.serviceAccountTokenCreator" role on the account you are trying to impersonate.
  
  ('invalid_grant: Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.', {'error': 'invalid_grant', 'error_description': 'Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.'})
2021-06-01 16:45:42.567518 (MainThread): Traceback (most recent call last):
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 149, in exception_handler
    yield
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/impl.py", line 203, in query_schemas
    return [ds.dataset_id for ds in all_datasets]
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/impl.py", line 203, in <listcomp>
    return [ds.dataset_id for ds in all_datasets]
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/page_iterator.py", line 212, in _items_iter
    for page in self._page_iter(increment=False):
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/page_iterator.py", line 243, in _page_iter
    page = self._next_page()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/page_iterator.py", line 369, in _next_page
    response = self._get_next_page_response()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/page_iterator.py", line 418, in _get_next_page_response
    return self.api_request(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 369, in api_request
    return self._call_api(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 636, in _call_api
    return call()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/_http.py", line 427, in api_request
    response = self._make_request(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/_http.py", line 291, in _make_request
    return self._do_request(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/_http.py", line 329, in _do_request
    return self.http.request(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/auth/transport/requests.py", line 478, in request
    self.credentials.before_request(auth_request, method, url, request_headers)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/auth/credentials.py", line 133, in before_request
    self.refresh(request)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/oauth2/service_account.py", line 376, in refresh
    access_token, expiry, _ = _client.jwt_grant(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/oauth2/_client.py", line 193, in jwt_grant
    response_data = _token_endpoint_request(request, token_uri, body)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/oauth2/_client.py", line 165, in _token_endpoint_request
    _handle_error_response(response_data)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/oauth2/_client.py", line 60, in _handle_error_response
    raise exceptions.RefreshError(error_details, response_data)
google.auth.exceptions.RefreshError: ('invalid_grant: Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.', {'error': 'invalid_grant', 'error_description': 'Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.'})

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/main.py", line 125, in main
    results, succeeded = handle_and_check(args)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/main.py", line 203, in handle_and_check
    task, res = run_from_args(parsed)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/main.py", line 256, in run_from_args
    results = task.run()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/runnable.py", line 426, in run
    result = self.execute_with_hooks(selected_uids)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/runnable.py", line 383, in execute_with_hooks
    self.before_run(adapter, selected_uids)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/run.py", line 409, in before_run
    self.create_schemas(adapter, selected_uids)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/runnable.py", line 515, in create_schemas
    existing_schemas_lowered.update(ls_future.result())
  File "/usr/lib/python3.8/concurrent/futures/_base.py", line 432, in result
    return self.__get_result()
  File "/usr/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
    raise self._exception
  File "/usr/lib/python3.8/concurrent/futures/thread.py", line 57, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/utils.py", line 469, in connected
    return func(*args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/runnable.py", line 492, in list_schemas
    for s in adapter.list_schemas(database_quoted)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/impl.py", line 205, in list_schemas
    return self.connections._retry_and_handle(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 166, in exception_handler
    raise RuntimeException(message)
dbt.exceptions.RuntimeException: Runtime Error
  Unable to generate access token, if you're using impersonate_service_account, make sure your initial account has the "roles/iam.serviceAccountTokenCreator" role on the account you are trying to impersonate.
  
  ('invalid_grant: Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.', {'error': 'invalid_grant', 'error_description': 'Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.'})

2021-06-01 16:45:44.028506 (MainThread): Running with dbt=0.19.1
2021-06-01 16:45:44.203260 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/home/femke/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-06-01 16:45:44.203855 (MainThread): Tracking: tracking
2021-06-01 16:45:44.214072 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f18ac19fe20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f18adad2130>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f18adad2520>]}
2021-06-01 16:45:44.228294 (MainThread): Partial parsing not enabled
2021-06-01 16:45:44.228994 (MainThread): Parsing macros/catalog.sql
2021-06-01 16:45:44.237390 (MainThread): Parsing macros/adapters.sql
2021-06-01 16:45:44.260053 (MainThread): Parsing macros/etc.sql
2021-06-01 16:45:44.261514 (MainThread): Parsing macros/materializations/snapshot.sql
2021-06-01 16:45:44.262858 (MainThread): Parsing macros/materializations/copy.sql
2021-06-01 16:45:44.265975 (MainThread): Parsing macros/materializations/table.sql
2021-06-01 16:45:44.273094 (MainThread): Parsing macros/materializations/incremental.sql
2021-06-01 16:45:44.282129 (MainThread): Parsing macros/materializations/view.sql
2021-06-01 16:45:44.284173 (MainThread): Parsing macros/materializations/seed.sql
2021-06-01 16:45:44.286707 (MainThread): Parsing macros/core.sql
2021-06-01 16:45:44.289227 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-06-01 16:45:44.290208 (MainThread): Parsing macros/schema_tests/unique.sql
2021-06-01 16:45:44.291338 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-06-01 16:45:44.292559 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-06-01 16:45:44.294293 (MainThread): Parsing macros/materializations/helpers.sql
2021-06-01 16:45:44.300142 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-06-01 16:45:44.301348 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-06-01 16:45:44.305659 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-06-01 16:45:44.326717 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-06-01 16:45:44.347198 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-06-01 16:45:44.348453 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-06-01 16:45:44.360683 (MainThread): Parsing macros/materializations/table/table.sql
2021-06-01 16:45:44.365214 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-06-01 16:45:44.368552 (MainThread): Parsing macros/materializations/view/view.sql
2021-06-01 16:45:44.372784 (MainThread): Parsing macros/materializations/common/merge.sql
2021-06-01 16:45:44.381875 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-06-01 16:45:44.383036 (MainThread): Parsing macros/etc/query.sql
2021-06-01 16:45:44.383738 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-06-01 16:45:44.384343 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-06-01 16:45:44.385745 (MainThread): Parsing macros/etc/datetime.sql
2021-06-01 16:45:44.393594 (MainThread): Parsing macros/etc/is_incremental.sql
2021-06-01 16:45:44.394720 (MainThread): Parsing macros/adapters/common.sql
2021-06-01 16:45:44.427228 (MainThread): Partial parsing not enabled
2021-06-01 16:45:44.443596 (MainThread): Acquiring new bigquery connection "model.resourceplanner.EmployeeDates".
2021-06-01 16:45:44.450668 (MainThread): Acquiring new bigquery connection "model.resourceplanner.trydates".
2021-06-01 16:45:44.453084 (MainThread): Acquiring new bigquery connection "model.resourceplanner.FactTable".
2021-06-01 16:45:44.455544 (MainThread): Acquiring new bigquery connection "model.resourceplanner.my_second_dbt_model".
2021-06-01 16:45:44.457834 (MainThread): Acquiring new bigquery connection "model.resourceplanner.my_first_dbt_model".
2021-06-01 16:45:44.502554 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5464e9c6-00a3-4639-83ba-b48b0ff5646e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f18ab1de700>]}
2021-06-01 16:45:44.505456 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5464e9c6-00a3-4639-83ba-b48b0ff5646e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f18ab1d3f70>]}
2021-06-01 16:45:44.505593 (MainThread): Found 5 models, 4 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-06-01 16:45:44.506285 (MainThread): 
2021-06-01 16:45:44.506516 (MainThread): Acquiring new bigquery connection "master".
2021-06-01 16:45:44.507211 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_oef-stage".
2021-06-01 16:45:44.507334 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-06-01 16:45:44.573780 (MainThread): Connection 'master' was properly closed.
2021-06-01 16:45:44.573907 (MainThread): Connection 'list_oef-stage' was properly closed.
2021-06-01 16:45:44.574016 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f18ab2c7430>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f18ab19ffd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f18ab288610>]}
2021-06-01 16:45:44.574157 (MainThread): Flushing usage events
2021-06-01 16:45:44.953531 (MainThread): Encountered an error:
2021-06-01 16:45:44.953924 (MainThread): Runtime Error
  Unable to generate access token, if you're using impersonate_service_account, make sure your initial account has the "roles/iam.serviceAccountTokenCreator" role on the account you are trying to impersonate.
  
  ('invalid_grant: Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.', {'error': 'invalid_grant', 'error_description': 'Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.'})
2021-06-01 16:45:44.955656 (MainThread): Traceback (most recent call last):
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 149, in exception_handler
    yield
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/impl.py", line 203, in query_schemas
    return [ds.dataset_id for ds in all_datasets]
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/impl.py", line 203, in <listcomp>
    return [ds.dataset_id for ds in all_datasets]
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/page_iterator.py", line 212, in _items_iter
    for page in self._page_iter(increment=False):
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/page_iterator.py", line 243, in _page_iter
    page = self._next_page()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/page_iterator.py", line 369, in _next_page
    response = self._get_next_page_response()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/page_iterator.py", line 418, in _get_next_page_response
    return self.api_request(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 369, in api_request
    return self._call_api(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 636, in _call_api
    return call()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/_http.py", line 427, in api_request
    response = self._make_request(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/_http.py", line 291, in _make_request
    return self._do_request(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/_http.py", line 329, in _do_request
    return self.http.request(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/auth/transport/requests.py", line 478, in request
    self.credentials.before_request(auth_request, method, url, request_headers)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/auth/credentials.py", line 133, in before_request
    self.refresh(request)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/oauth2/service_account.py", line 376, in refresh
    access_token, expiry, _ = _client.jwt_grant(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/oauth2/_client.py", line 193, in jwt_grant
    response_data = _token_endpoint_request(request, token_uri, body)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/oauth2/_client.py", line 165, in _token_endpoint_request
    _handle_error_response(response_data)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/oauth2/_client.py", line 60, in _handle_error_response
    raise exceptions.RefreshError(error_details, response_data)
google.auth.exceptions.RefreshError: ('invalid_grant: Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.', {'error': 'invalid_grant', 'error_description': 'Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.'})

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/main.py", line 125, in main
    results, succeeded = handle_and_check(args)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/main.py", line 203, in handle_and_check
    task, res = run_from_args(parsed)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/main.py", line 256, in run_from_args
    results = task.run()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/runnable.py", line 426, in run
    result = self.execute_with_hooks(selected_uids)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/runnable.py", line 383, in execute_with_hooks
    self.before_run(adapter, selected_uids)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/run.py", line 409, in before_run
    self.create_schemas(adapter, selected_uids)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/runnable.py", line 515, in create_schemas
    existing_schemas_lowered.update(ls_future.result())
  File "/usr/lib/python3.8/concurrent/futures/_base.py", line 432, in result
    return self.__get_result()
  File "/usr/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
    raise self._exception
  File "/usr/lib/python3.8/concurrent/futures/thread.py", line 57, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/utils.py", line 469, in connected
    return func(*args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/runnable.py", line 492, in list_schemas
    for s in adapter.list_schemas(database_quoted)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/impl.py", line 205, in list_schemas
    return self.connections._retry_and_handle(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 166, in exception_handler
    raise RuntimeException(message)
dbt.exceptions.RuntimeException: Runtime Error
  Unable to generate access token, if you're using impersonate_service_account, make sure your initial account has the "roles/iam.serviceAccountTokenCreator" role on the account you are trying to impersonate.
  
  ('invalid_grant: Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.', {'error': 'invalid_grant', 'error_description': 'Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.'})

2021-06-02 09:19:54.364152 (MainThread): Running with dbt=0.19.1
2021-06-02 09:19:54.721475 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/home/femke/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-06-02 09:19:54.722056 (MainThread): Tracking: tracking
2021-06-02 09:19:54.754788 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f14b5ef8fa0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f14b78c3490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f14b5f0a4c0>]}
2021-06-02 09:19:54.780006 (MainThread): Partial parsing not enabled
2021-06-02 09:19:54.780705 (MainThread): Parsing macros/catalog.sql
2021-06-02 09:19:54.812948 (MainThread): Parsing macros/adapters.sql
2021-06-02 09:19:54.849057 (MainThread): Parsing macros/etc.sql
2021-06-02 09:19:54.854462 (MainThread): Parsing macros/materializations/snapshot.sql
2021-06-02 09:19:54.855665 (MainThread): Parsing macros/materializations/copy.sql
2021-06-02 09:19:54.864809 (MainThread): Parsing macros/materializations/table.sql
2021-06-02 09:19:54.885759 (MainThread): Parsing macros/materializations/incremental.sql
2021-06-02 09:19:54.904175 (MainThread): Parsing macros/materializations/view.sql
2021-06-02 09:19:54.906170 (MainThread): Parsing macros/materializations/seed.sql
2021-06-02 09:19:54.908398 (MainThread): Parsing macros/core.sql
2021-06-02 09:19:54.916374 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-06-02 09:19:54.917451 (MainThread): Parsing macros/schema_tests/unique.sql
2021-06-02 09:19:54.922743 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-06-02 09:19:54.923974 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-06-02 09:19:54.932105 (MainThread): Parsing macros/materializations/helpers.sql
2021-06-02 09:19:54.951444 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-06-02 09:19:54.952713 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-06-02 09:19:54.956983 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-06-02 09:19:54.991621 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-06-02 09:19:55.036815 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-06-02 09:19:55.039068 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-06-02 09:19:55.069492 (MainThread): Parsing macros/materializations/table/table.sql
2021-06-02 09:19:55.079133 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-06-02 09:19:55.086574 (MainThread): Parsing macros/materializations/view/view.sql
2021-06-02 09:19:55.096804 (MainThread): Parsing macros/materializations/common/merge.sql
2021-06-02 09:19:55.119950 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-06-02 09:19:55.122608 (MainThread): Parsing macros/etc/query.sql
2021-06-02 09:19:55.123308 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-06-02 09:19:55.123904 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-06-02 09:19:55.132518 (MainThread): Parsing macros/etc/datetime.sql
2021-06-02 09:19:55.146710 (MainThread): Parsing macros/etc/is_incremental.sql
2021-06-02 09:19:55.147888 (MainThread): Parsing macros/adapters/common.sql
2021-06-02 09:19:55.216796 (MainThread): Partial parsing not enabled
2021-06-02 09:19:55.258896 (MainThread): Acquiring new bigquery connection "model.resourceplanner.EmployeeDates".
2021-06-02 09:19:55.275968 (MainThread): Acquiring new bigquery connection "model.resourceplanner.trydates".
2021-06-02 09:19:55.281737 (MainThread): Acquiring new bigquery connection "model.resourceplanner.FactTable".
2021-06-02 09:19:55.284317 (MainThread): Acquiring new bigquery connection "model.resourceplanner.my_second_dbt_model".
2021-06-02 09:19:55.290569 (MainThread): Acquiring new bigquery connection "model.resourceplanner.my_first_dbt_model".
2021-06-02 09:19:55.387155 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '9514a3e2-9476-4a3d-9d3d-0a04028ad2ec', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f14b35d4310>]}
2021-06-02 09:19:55.401513 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '9514a3e2-9476-4a3d-9d3d-0a04028ad2ec', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f14b35f0f10>]}
2021-06-02 09:19:55.401785 (MainThread): Found 5 models, 4 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-06-02 09:19:55.402630 (MainThread): 
2021-06-02 09:19:55.402926 (MainThread): Acquiring new bigquery connection "master".
2021-06-02 09:19:55.410136 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_oef-stage".
2021-06-02 09:19:55.410329 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-06-02 09:19:55.410417 (ThreadPoolExecutor-0_0): Got an error when attempting to create a bigquery client: '[Errno 2] No such file or directory: '/home/femke/Desktop/oef-stage-58d8b62f3603.json''
2021-06-02 09:19:55.410705 (MainThread): Connection 'master' was properly closed.
2021-06-02 09:19:55.410781 (MainThread): Connection 'list_oef-stage' was properly closed.
2021-06-02 09:19:55.410840 (MainThread): ERROR: Database Error
  [Errno 2] No such file or directory: '/home/femke/Desktop/oef-stage-58d8b62f3603.json'
2021-06-02 09:19:55.411075 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f14b36bf3a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f14b358deb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f14b3595f40>]}
2021-06-02 09:19:55.411203 (MainThread): Flushing usage events
2021-06-02 09:24:39.572386 (MainThread): Running with dbt=0.19.1
2021-06-02 09:24:39.790285 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/home/femke/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-06-02 09:24:39.791023 (MainThread): Tracking: tracking
2021-06-02 09:24:39.801617 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3569a89e20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f356b3c2100>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f356b3c24f0>]}
2021-06-02 09:24:39.820982 (MainThread): Partial parsing not enabled
2021-06-02 09:24:39.825646 (MainThread): Parsing macros/catalog.sql
2021-06-02 09:24:39.836289 (MainThread): Parsing macros/adapters.sql
2021-06-02 09:24:39.857863 (MainThread): Parsing macros/etc.sql
2021-06-02 09:24:39.859321 (MainThread): Parsing macros/materializations/snapshot.sql
2021-06-02 09:24:39.860534 (MainThread): Parsing macros/materializations/copy.sql
2021-06-02 09:24:39.865750 (MainThread): Parsing macros/materializations/table.sql
2021-06-02 09:24:39.872866 (MainThread): Parsing macros/materializations/incremental.sql
2021-06-02 09:24:39.884130 (MainThread): Parsing macros/materializations/view.sql
2021-06-02 09:24:39.887831 (MainThread): Parsing macros/materializations/seed.sql
2021-06-02 09:24:39.890489 (MainThread): Parsing macros/core.sql
2021-06-02 09:24:39.894270 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-06-02 09:24:39.897545 (MainThread): Parsing macros/schema_tests/unique.sql
2021-06-02 09:24:39.898780 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-06-02 09:24:39.900015 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-06-02 09:24:39.902025 (MainThread): Parsing macros/materializations/helpers.sql
2021-06-02 09:24:39.908277 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-06-02 09:24:39.910946 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-06-02 09:24:39.917435 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-06-02 09:24:39.933410 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-06-02 09:24:39.956399 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-06-02 09:24:39.957715 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-06-02 09:24:39.972227 (MainThread): Parsing macros/materializations/table/table.sql
2021-06-02 09:24:39.976946 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-06-02 09:24:39.982497 (MainThread): Parsing macros/materializations/view/view.sql
2021-06-02 09:24:39.986880 (MainThread): Parsing macros/materializations/common/merge.sql
2021-06-02 09:24:39.998148 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-06-02 09:24:39.999350 (MainThread): Parsing macros/etc/query.sql
2021-06-02 09:24:40.000032 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-06-02 09:24:40.000669 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-06-02 09:24:40.002094 (MainThread): Parsing macros/etc/datetime.sql
2021-06-02 09:24:40.008049 (MainThread): Parsing macros/etc/is_incremental.sql
2021-06-02 09:24:40.009293 (MainThread): Parsing macros/adapters/common.sql
2021-06-02 09:24:40.045054 (MainThread): Partial parsing not enabled
2021-06-02 09:24:40.065592 (MainThread): Acquiring new bigquery connection "model.resourceplanner.EmployeeDates".
2021-06-02 09:24:40.072856 (MainThread): Acquiring new bigquery connection "model.resourceplanner.trydates".
2021-06-02 09:24:40.075229 (MainThread): Acquiring new bigquery connection "model.resourceplanner.FactTable".
2021-06-02 09:24:40.077696 (MainThread): Acquiring new bigquery connection "model.resourceplanner.my_second_dbt_model".
2021-06-02 09:24:40.082525 (MainThread): Acquiring new bigquery connection "model.resourceplanner.my_first_dbt_model".
2021-06-02 09:24:40.134898 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e2db4e0e-d6ac-427a-997a-f8d339cd872c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3568ac9700>]}
2021-06-02 09:24:40.138150 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e2db4e0e-d6ac-427a-997a-f8d339cd872c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3568abef70>]}
2021-06-02 09:24:40.138294 (MainThread): Found 5 models, 4 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-06-02 09:24:40.138988 (MainThread): 
2021-06-02 09:24:40.139228 (MainThread): Acquiring new bigquery connection "master".
2021-06-02 09:24:40.139868 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_oef-stage".
2021-06-02 09:24:40.140019 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-06-02 09:24:40.140115 (ThreadPoolExecutor-0_0): Got an error when attempting to create a bigquery client: '[Errno 2] No such file or directory: '/home/femke/Desktop/resourceplanner/resourceplanner/oef-stage-9f4eae469a2b''
2021-06-02 09:24:40.140384 (MainThread): Connection 'master' was properly closed.
2021-06-02 09:24:40.140442 (MainThread): Connection 'list_oef-stage' was properly closed.
2021-06-02 09:24:40.140503 (MainThread): ERROR: Database Error
  [Errno 2] No such file or directory: '/home/femke/Desktop/resourceplanner/resourceplanner/oef-stage-9f4eae469a2b'
2021-06-02 09:24:40.140667 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3568bb1430>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3568a8afd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3568adbf40>]}
2021-06-02 09:24:40.140763 (MainThread): Flushing usage events
2021-06-02 09:25:06.154990 (MainThread): Running with dbt=0.19.1
2021-06-02 09:25:06.364441 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/home/femke/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-06-02 09:25:06.365139 (MainThread): Tracking: tracking
2021-06-02 09:25:06.375408 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb5aacebd60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb5ac5de370>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb5ac5de640>]}
2021-06-02 09:25:06.390687 (MainThread): Partial parsing not enabled
2021-06-02 09:25:06.391403 (MainThread): Parsing macros/catalog.sql
2021-06-02 09:25:06.399831 (MainThread): Parsing macros/adapters.sql
2021-06-02 09:25:06.422932 (MainThread): Parsing macros/etc.sql
2021-06-02 09:25:06.424520 (MainThread): Parsing macros/materializations/snapshot.sql
2021-06-02 09:25:06.425815 (MainThread): Parsing macros/materializations/copy.sql
2021-06-02 09:25:06.429271 (MainThread): Parsing macros/materializations/table.sql
2021-06-02 09:25:06.436499 (MainThread): Parsing macros/materializations/incremental.sql
2021-06-02 09:25:06.445545 (MainThread): Parsing macros/materializations/view.sql
2021-06-02 09:25:06.447665 (MainThread): Parsing macros/materializations/seed.sql
2021-06-02 09:25:06.450144 (MainThread): Parsing macros/core.sql
2021-06-02 09:25:06.452680 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-06-02 09:25:06.453712 (MainThread): Parsing macros/schema_tests/unique.sql
2021-06-02 09:25:06.454943 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-06-02 09:25:06.456209 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-06-02 09:25:06.458086 (MainThread): Parsing macros/materializations/helpers.sql
2021-06-02 09:25:06.464231 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-06-02 09:25:06.465514 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-06-02 09:25:06.469885 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-06-02 09:25:06.484172 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-06-02 09:25:06.505057 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-06-02 09:25:06.506348 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-06-02 09:25:06.519359 (MainThread): Parsing macros/materializations/table/table.sql
2021-06-02 09:25:06.523951 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-06-02 09:25:06.527315 (MainThread): Parsing macros/materializations/view/view.sql
2021-06-02 09:25:06.531748 (MainThread): Parsing macros/materializations/common/merge.sql
2021-06-02 09:25:06.540897 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-06-02 09:25:06.542035 (MainThread): Parsing macros/etc/query.sql
2021-06-02 09:25:06.542716 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-06-02 09:25:06.543339 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-06-02 09:25:06.544727 (MainThread): Parsing macros/etc/datetime.sql
2021-06-02 09:25:06.550911 (MainThread): Parsing macros/etc/is_incremental.sql
2021-06-02 09:25:06.552081 (MainThread): Parsing macros/adapters/common.sql
2021-06-02 09:25:06.583975 (MainThread): Partial parsing not enabled
2021-06-02 09:25:06.600453 (MainThread): Acquiring new bigquery connection "model.resourceplanner.EmployeeDates".
2021-06-02 09:25:06.607396 (MainThread): Acquiring new bigquery connection "model.resourceplanner.trydates".
2021-06-02 09:25:06.609725 (MainThread): Acquiring new bigquery connection "model.resourceplanner.FactTable".
2021-06-02 09:25:06.612292 (MainThread): Acquiring new bigquery connection "model.resourceplanner.my_second_dbt_model".
2021-06-02 09:25:06.614707 (MainThread): Acquiring new bigquery connection "model.resourceplanner.my_first_dbt_model".
2021-06-02 09:25:06.663371 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '21ddd411-b75d-4fcf-a4a4-5a57123691a7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb5a9cad850>]}
2021-06-02 09:25:06.666706 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '21ddd411-b75d-4fcf-a4a4-5a57123691a7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb5a9c9c0a0>]}
2021-06-02 09:25:06.666865 (MainThread): Found 5 models, 4 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-06-02 09:25:06.667561 (MainThread): 
2021-06-02 09:25:06.667804 (MainThread): Acquiring new bigquery connection "master".
2021-06-02 09:25:06.668464 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_oef-stage".
2021-06-02 09:25:06.668589 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-06-02 09:25:06.668681 (ThreadPoolExecutor-0_0): Got an error when attempting to create a bigquery client: '[Errno 2] No such file or directory: '/home/femke/Desktop/resourceplanner/resourceplanner/oef-stage-9f4eae469a2b.sjon''
2021-06-02 09:25:06.668984 (MainThread): Connection 'master' was properly closed.
2021-06-02 09:25:06.669035 (MainThread): Connection 'list_oef-stage' was properly closed.
2021-06-02 09:25:06.669088 (MainThread): ERROR: Database Error
  [Errno 2] No such file or directory: '/home/femke/Desktop/resourceplanner/resourceplanner/oef-stage-9f4eae469a2b.sjon'
2021-06-02 09:25:06.669247 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb5a9d96580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb5a9c53520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb5a9c69100>]}
2021-06-02 09:25:06.669351 (MainThread): Flushing usage events
2021-06-02 09:25:27.135893 (MainThread): Running with dbt=0.19.1
2021-06-02 09:25:27.318421 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/home/femke/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-06-02 09:25:27.319014 (MainThread): Tracking: tracking
2021-06-02 09:25:27.333254 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f47234c6dc0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4724e39250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4724e39610>]}
2021-06-02 09:25:27.344309 (MainThread): Partial parsing not enabled
2021-06-02 09:25:27.345064 (MainThread): Parsing macros/catalog.sql
2021-06-02 09:25:27.357589 (MainThread): Parsing macros/adapters.sql
2021-06-02 09:25:27.376825 (MainThread): Parsing macros/etc.sql
2021-06-02 09:25:27.378288 (MainThread): Parsing macros/materializations/snapshot.sql
2021-06-02 09:25:27.379763 (MainThread): Parsing macros/materializations/copy.sql
2021-06-02 09:25:27.382881 (MainThread): Parsing macros/materializations/table.sql
2021-06-02 09:25:27.389716 (MainThread): Parsing macros/materializations/incremental.sql
2021-06-02 09:25:27.398386 (MainThread): Parsing macros/materializations/view.sql
2021-06-02 09:25:27.400268 (MainThread): Parsing macros/materializations/seed.sql
2021-06-02 09:25:27.402584 (MainThread): Parsing macros/core.sql
2021-06-02 09:25:27.405161 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-06-02 09:25:27.406196 (MainThread): Parsing macros/schema_tests/unique.sql
2021-06-02 09:25:27.407312 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-06-02 09:25:27.408540 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-06-02 09:25:27.410423 (MainThread): Parsing macros/materializations/helpers.sql
2021-06-02 09:25:27.416841 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-06-02 09:25:27.418171 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-06-02 09:25:27.422747 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-06-02 09:25:27.437501 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-06-02 09:25:27.458639 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-06-02 09:25:27.459909 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-06-02 09:25:27.472556 (MainThread): Parsing macros/materializations/table/table.sql
2021-06-02 09:25:27.477115 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-06-02 09:25:27.480630 (MainThread): Parsing macros/materializations/view/view.sql
2021-06-02 09:25:27.484866 (MainThread): Parsing macros/materializations/common/merge.sql
2021-06-02 09:25:27.493984 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-06-02 09:25:27.495084 (MainThread): Parsing macros/etc/query.sql
2021-06-02 09:25:27.495939 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-06-02 09:25:27.496566 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-06-02 09:25:27.497951 (MainThread): Parsing macros/etc/datetime.sql
2021-06-02 09:25:27.503858 (MainThread): Parsing macros/etc/is_incremental.sql
2021-06-02 09:25:27.504982 (MainThread): Parsing macros/adapters/common.sql
2021-06-02 09:25:27.536770 (MainThread): Partial parsing not enabled
2021-06-02 09:25:27.554055 (MainThread): Acquiring new bigquery connection "model.resourceplanner.EmployeeDates".
2021-06-02 09:25:27.561283 (MainThread): Acquiring new bigquery connection "model.resourceplanner.trydates".
2021-06-02 09:25:27.563860 (MainThread): Acquiring new bigquery connection "model.resourceplanner.FactTable".
2021-06-02 09:25:27.566222 (MainThread): Acquiring new bigquery connection "model.resourceplanner.my_second_dbt_model".
2021-06-02 09:25:27.568502 (MainThread): Acquiring new bigquery connection "model.resourceplanner.my_first_dbt_model".
2021-06-02 09:25:27.614475 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '06f3241c-eabd-48cd-96b1-a20f2838a60f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f47225064c0>]}
2021-06-02 09:25:27.617522 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '06f3241c-eabd-48cd-96b1-a20f2838a60f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f47224fd490>]}
2021-06-02 09:25:27.617667 (MainThread): Found 5 models, 4 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-06-02 09:25:27.618324 (MainThread): 
2021-06-02 09:25:27.618590 (MainThread): Acquiring new bigquery connection "master".
2021-06-02 09:25:27.619224 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_oef-stage".
2021-06-02 09:25:27.619359 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-06-02 09:25:28.031061 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_oef-stage_TestRecoursePlanner".
2021-06-02 09:25:28.031219 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2021-06-02 09:25:28.036278 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-06-02 09:25:28.220459 (MainThread): 11:25:28 | Concurrency: 5 threads (target='dev')
2021-06-02 09:25:28.220701 (MainThread): 11:25:28 | 
2021-06-02 09:25:28.222492 (Thread-1): Began running node model.resourceplanner.my_first_dbt_model
2021-06-02 09:25:28.222659 (Thread-1): 11:25:28 | 1 of 5 START table model TestRecoursePlanner.my_first_dbt_model...... [RUN]
2021-06-02 09:25:28.222761 (Thread-2): Began running node model.resourceplanner.EmployeeDates
2021-06-02 09:25:28.222868 (Thread-2): 11:25:28 | 2 of 5 START table model TestRecoursePlanner.EmployeeDates........... [RUN]
2021-06-02 09:25:28.222933 (Thread-3): Began running node model.resourceplanner.FactTable
2021-06-02 09:25:28.223029 (Thread-3): 11:25:28 | 3 of 5 START table model TestRecoursePlanner.FactTable............... [RUN]
2021-06-02 09:25:28.223090 (Thread-4): Began running node model.resourceplanner.trydates
2021-06-02 09:25:28.223218 (Thread-4): 11:25:28 | 4 of 5 START table model TestRecoursePlanner.trydates................ [RUN]
2021-06-02 09:25:28.223411 (Thread-1): Acquiring new bigquery connection "model.resourceplanner.my_first_dbt_model".
2021-06-02 09:25:28.223484 (Thread-1): Compiling model.resourceplanner.my_first_dbt_model
2021-06-02 09:25:28.225232 (Thread-1): Writing injected SQL for node "model.resourceplanner.my_first_dbt_model"
2021-06-02 09:25:28.225431 (Thread-2): Acquiring new bigquery connection "model.resourceplanner.EmployeeDates".
2021-06-02 09:25:28.225866 (Thread-2): Compiling model.resourceplanner.EmployeeDates
2021-06-02 09:25:28.227075 (Thread-2): Writing injected SQL for node "model.resourceplanner.EmployeeDates"
2021-06-02 09:25:28.225602 (Thread-3): Acquiring new bigquery connection "model.resourceplanner.FactTable".
2021-06-02 09:25:28.227468 (Thread-3): Compiling model.resourceplanner.FactTable
2021-06-02 09:25:28.228371 (Thread-3): unclosed <socket.socket fd=5, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.0.2.15', 52748), raddr=('172.217.168.234', 443)>
2021-06-02 09:25:28.228522 (Thread-3): unclosed <socket.socket fd=6, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.0.2.15', 34358), raddr=('216.58.211.106', 443)>
2021-06-02 09:25:28.225762 (Thread-4): Acquiring new bigquery connection "model.resourceplanner.trydates".
2021-06-02 09:25:28.230761 (Thread-4): Compiling model.resourceplanner.trydates
2021-06-02 09:25:28.235217 (Thread-4): Writing injected SQL for node "model.resourceplanner.trydates"
2021-06-02 09:25:28.230638 (Thread-3): unclosed <socket.socket fd=8, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.0.2.15', 34362), raddr=('216.58.211.106', 443)>
2021-06-02 09:25:28.235818 (Thread-3): unclosed <socket.socket fd=7, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.0.2.15', 52752), raddr=('172.217.168.234', 443)>
2021-06-02 09:25:28.237082 (Thread-3): Writing injected SQL for node "model.resourceplanner.FactTable"
2021-06-02 09:25:28.227315 (Thread-2): finished collecting timing info
2021-06-02 09:25:28.235593 (Thread-4): finished collecting timing info
2021-06-02 09:25:28.237338 (Thread-3): finished collecting timing info
2021-06-02 09:25:28.260453 (Thread-1): finished collecting timing info
2021-06-02 09:25:28.288024 (Thread-3): Opening a new connection, currently in state init
2021-06-02 09:25:28.304130 (Thread-3): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-06-02 09:25:28.293745 (Thread-2): Opening a new connection, currently in state closed
2021-06-02 09:25:28.308038 (Thread-2): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-06-02 09:25:28.300861 (Thread-1): Opening a new connection, currently in state closed
2021-06-02 09:25:28.299089 (Thread-4): Opening a new connection, currently in state init
2021-06-02 09:25:28.315492 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-06-02 09:25:28.318989 (Thread-4): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-06-02 09:25:28.507044 (Thread-3): Writing runtime SQL for node "model.resourceplanner.FactTable"
2021-06-02 09:25:28.507662 (Thread-3): On model.resourceplanner.FactTable: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "Bigquery", "target_name": "dev", "node_id": "model.resourceplanner.FactTable"} */


  create or replace table `oef-stage`.`TestRecoursePlanner`.`FactTable`
  
  
  OPTIONS()
  as (
    


SELECT
  T.id,
  TD.ID AS ProjectID,
  TD.EmployeeID,
  TD.CompanyID,
  T.PM_AM,
  T.full_date,
  T.day_name,
  CASE
    WHEN T.day_name = "Monday" THEN IF (TD.Monday = 'Available', '0', IF (TD.Monday = 'Full', '0,5', IF (PM_AM = TD.Monday, '0,5', '0') ))
    WHEN T.day_name = "Tuesday" THEN IF (TD.Tuesday = 'Available', '0', IF (TD.Tuesday = 'Full', '0,5', IF (PM_AM = TD.Tuesday, '0,5', '0') ))
    WHEN T.day_name = "Wednesday" THEN IF (TD.Wednesday = 'Available', '0', IF (TD.Wednesday = 'Full', '0,5', IF (PM_AM = TD.Wednesday, '0,5', '0') ))
    WHEN T.day_name = "Thursday" THEN IF (TD.Thursday = 'Available', '0', IF (TD.Thursday = 'Full', '0,5', IF (PM_AM = TD.Thursday, '0,5', '0') ))
    WHEN T.day_name = "Friday" THEN IF (TD.Friday = 'Available', '0', IF (TD.Friday  = 'Full', '0,5', IF (PM_AM = TD.Friday , '0,5', '0') ))
  ELSE
  '0'
END
  AS Is_Booked
FROM
  `oef-stage.TestRecoursePlanner.Time` T
CROSS JOIN
  `oef-stage.TestRecoursePlanner.trydates` TD

WHERE T.full_Date  BETWEEN TD.DateStart
  AND TD.DateEnd
ORDER BY
  T.full_date
  );
    
2021-06-02 09:25:28.520377 (Thread-1): Writing runtime SQL for node "model.resourceplanner.my_first_dbt_model"
2021-06-02 09:25:28.520970 (Thread-1): On model.resourceplanner.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "Bigquery", "target_name": "dev", "node_id": "model.resourceplanner.my_first_dbt_model"} */


  create or replace table `oef-stage`.`TestRecoursePlanner`.`my_first_dbt_model`
  
  
  OPTIONS()
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select M.ID, E.EmployeeID, CU.CustomerID,CO.CompanyID
from oef-stage.TestRecoursePlanner.MainData M
INNER JOIN oef-stage.TestRecoursePlanner.Employee E
ON M.Employee = E.Firstname
INNER JOIN oef-stage.TestRecoursePlanner.Customer CU
ON M.Customer = CU.Customername
INNER JOIN oef-stage.TestRecoursePlanner.Company CO
ON M.Company = CO.Companyname
ORDER BY M.ID

/*
    Uncomment the line below to remove records with null `id` values
*/
  );
    
2021-06-02 09:25:28.522060 (Thread-4): Writing runtime SQL for node "model.resourceplanner.trydates"
2021-06-02 09:25:28.522347 (Thread-4): On model.resourceplanner.trydates: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "Bigquery", "target_name": "dev", "node_id": "model.resourceplanner.trydates"} */


  create or replace table `oef-stage`.`TestRecoursePlanner`.`trydates`
  
  
  OPTIONS()
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/


with source_data as (

    select 1 as id
    union all
    select null as id

)

select M.ID, E.EmployeeID, CU.CustomerID,CO.CompanyID, M.DateStart, M.DateEnd, M.Monday, M.Tuesday, M.Wednesday , M.Thursday , M.Friday
from oef-stage.TestRecoursePlanner.MainData M
INNER JOIN oef-stage.TestRecoursePlanner.Employee E
ON M.Employee = E.Firstname
INNER JOIN oef-stage.TestRecoursePlanner.Customer CU
ON M.Customer = CU.Customername
INNER JOIN oef-stage.TestRecoursePlanner.Company CO
ON M.Company = CO.Companyname
ORDER BY M.ID

/*
    Uncomment the line below to remove records with null `id` values
*/
  );
    
2021-06-02 09:25:28.543485 (Thread-2): Writing runtime SQL for node "model.resourceplanner.EmployeeDates"
2021-06-02 09:25:28.543874 (Thread-2): On model.resourceplanner.EmployeeDates: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "Bigquery", "target_name": "dev", "node_id": "model.resourceplanner.EmployeeDates"} */


  create or replace table `oef-stage`.`TestRecoursePlanner`.`EmployeeDates`
  
  
  OPTIONS()
  as (
    

SELECT DISTINCT E.EmployeeID, T.full_date
FROM oef-stage.TestRecoursePlanner.Time T
CROSS JOIN oef-stage.TestRecoursePlanner.Employee E
ORDER BY T.full_date
  );
    
2021-06-02 09:25:31.219314 (Thread-3): finished collecting timing info
2021-06-02 09:25:31.219632 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '06f3241c-eabd-48cd-96b1-a20f2838a60f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f472034a310>]}
2021-06-02 09:25:31.219836 (Thread-3): 11:25:31 | 3 of 5 OK created table model TestRecoursePlanner.FactTable.......... [CREATE TABLE (992.0 rows, 251.6 KB processed) in 2.99s]
2021-06-02 09:25:31.220223 (Thread-3): Finished running node model.resourceplanner.FactTable
2021-06-02 09:25:32.413476 (Thread-2): finished collecting timing info
2021-06-02 09:25:32.413827 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '06f3241c-eabd-48cd-96b1-a20f2838a60f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4721bc9820>]}
2021-06-02 09:25:32.414032 (Thread-2): 11:25:32 | 2 of 5 OK created table model TestRecoursePlanner.EmployeeDates...... [CREATE TABLE (43.8k rows, 57.8 KB processed) in 4.19s]
2021-06-02 09:25:32.414229 (Thread-2): Finished running node model.resourceplanner.EmployeeDates
2021-06-02 09:25:33.382517 (Thread-4): finished collecting timing info
2021-06-02 09:25:33.382851 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '06f3241c-eabd-48cd-96b1-a20f2838a60f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4721bc9bb0>]}
2021-06-02 09:25:33.383052 (Thread-4): 11:25:33 | 4 of 5 OK created table model TestRecoursePlanner.trydates........... [CREATE TABLE (14.0 rows, 5.4 KB processed) in 5.16s]
2021-06-02 09:25:33.383231 (Thread-4): Finished running node model.resourceplanner.trydates
2021-06-02 09:25:33.647668 (Thread-1): finished collecting timing info
2021-06-02 09:25:33.648223 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '06f3241c-eabd-48cd-96b1-a20f2838a60f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4721bc95e0>]}
2021-06-02 09:25:33.648440 (Thread-1): 11:25:33 | 1 of 5 OK created table model TestRecoursePlanner.my_first_dbt_model. [CREATE TABLE (14.0 rows, 5.4 KB processed) in 5.42s]
2021-06-02 09:25:33.648617 (Thread-1): Finished running node model.resourceplanner.my_first_dbt_model
2021-06-02 09:25:33.649036 (Thread-5): Began running node model.resourceplanner.my_second_dbt_model
2021-06-02 09:25:33.649244 (Thread-5): 11:25:33 | 5 of 5 START view model TestRecoursePlanner.my_second_dbt_model...... [RUN]
2021-06-02 09:25:33.649553 (Thread-5): Acquiring new bigquery connection "model.resourceplanner.my_second_dbt_model".
2021-06-02 09:25:33.649620 (Thread-5): Compiling model.resourceplanner.my_second_dbt_model
2021-06-02 09:25:33.651164 (Thread-5): Writing injected SQL for node "model.resourceplanner.my_second_dbt_model"
2021-06-02 09:25:33.651406 (Thread-5): finished collecting timing info
2021-06-02 09:25:33.671413 (Thread-5): Writing runtime SQL for node "model.resourceplanner.my_second_dbt_model"
2021-06-02 09:25:33.671926 (Thread-5): Opening a new connection, currently in state init
2021-06-02 09:25:33.675109 (Thread-5): On model.resourceplanner.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "Bigquery", "target_name": "dev", "node_id": "model.resourceplanner.my_second_dbt_model"} */


  create or replace view `oef-stage`.`TestRecoursePlanner`.`my_second_dbt_model`
  OPTIONS()
  as -- Use the `ref` function to select from other models

select *
from `oef-stage`.`TestRecoursePlanner`.`my_first_dbt_model`;


2021-06-02 09:25:34.846336 (Thread-5): finished collecting timing info
2021-06-02 09:25:34.846631 (Thread-5): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '06f3241c-eabd-48cd-96b1-a20f2838a60f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f47202d9f10>]}
2021-06-02 09:25:34.846847 (Thread-5): 11:25:34 | 5 of 5 OK created view model TestRecoursePlanner.my_second_dbt_model. [OK in 1.20s]
2021-06-02 09:25:34.847186 (Thread-5): Finished running node model.resourceplanner.my_second_dbt_model
2021-06-02 09:25:34.848204 (MainThread): Acquiring new bigquery connection "master".
2021-06-02 09:25:34.848377 (MainThread): 11:25:34 | 
2021-06-02 09:25:34.848485 (MainThread): 11:25:34 | Finished running 4 table models, 1 view model in 7.23s.
2021-06-02 09:25:34.848575 (MainThread): Connection 'master' was properly closed.
2021-06-02 09:25:34.848614 (MainThread): Connection 'model.resourceplanner.my_first_dbt_model' was properly closed.
2021-06-02 09:25:34.848645 (MainThread): Connection 'model.resourceplanner.EmployeeDates' was properly closed.
2021-06-02 09:25:34.848674 (MainThread): Connection 'model.resourceplanner.FactTable' was properly closed.
2021-06-02 09:25:34.848703 (MainThread): Connection 'model.resourceplanner.trydates' was properly closed.
2021-06-02 09:25:34.848731 (MainThread): Connection 'model.resourceplanner.my_second_dbt_model' was properly closed.
2021-06-02 09:25:34.849458 (MainThread): unclosed <socket.socket fd=15, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.0.2.15', 52772), raddr=('172.217.168.234', 443)>
2021-06-02 09:25:34.849727 (MainThread): unclosed <socket.socket fd=16, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.0.2.15', 34382), raddr=('216.58.211.106', 443)>
2021-06-02 09:25:34.863175 (MainThread): 
2021-06-02 09:25:34.863357 (MainThread): Completed successfully
2021-06-02 09:25:34.863479 (MainThread): 
Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
2021-06-02 09:25:34.863653 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f47225ef550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f47224690d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f47225a70a0>]}
2021-06-02 09:25:34.863778 (MainThread): Flushing usage events
2021-06-02 10:02:38.328119 (MainThread): Running with dbt=0.19.1
2021-06-02 10:02:38.527242 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/home/femke/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-06-02 10:02:38.528012 (MainThread): Tracking: tracking
2021-06-02 10:02:38.542402 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fab79d1bc40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fab7b6901c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fab7b690520>]}
2021-06-02 10:02:38.557725 (MainThread): Partial parsing not enabled
2021-06-02 10:02:38.558470 (MainThread): Parsing macros/catalog.sql
2021-06-02 10:02:38.570942 (MainThread): Parsing macros/adapters.sql
2021-06-02 10:02:38.591634 (MainThread): Parsing macros/etc.sql
2021-06-02 10:02:38.593400 (MainThread): Parsing macros/materializations/snapshot.sql
2021-06-02 10:02:38.594821 (MainThread): Parsing macros/materializations/copy.sql
2021-06-02 10:02:38.598561 (MainThread): Parsing macros/materializations/table.sql
2021-06-02 10:02:38.605907 (MainThread): Parsing macros/materializations/incremental.sql
2021-06-02 10:02:38.615374 (MainThread): Parsing macros/materializations/view.sql
2021-06-02 10:02:38.617438 (MainThread): Parsing macros/materializations/seed.sql
2021-06-02 10:02:38.619837 (MainThread): Parsing macros/core.sql
2021-06-02 10:02:38.622999 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-06-02 10:02:38.624037 (MainThread): Parsing macros/schema_tests/unique.sql
2021-06-02 10:02:38.625190 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-06-02 10:02:38.626543 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-06-02 10:02:38.628384 (MainThread): Parsing macros/materializations/helpers.sql
2021-06-02 10:02:38.634837 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-06-02 10:02:38.636136 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-06-02 10:02:38.648793 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-06-02 10:02:38.663992 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-06-02 10:02:38.686233 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-06-02 10:02:38.687646 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-06-02 10:02:38.701210 (MainThread): Parsing macros/materializations/table/table.sql
2021-06-02 10:02:38.706167 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-06-02 10:02:38.709586 (MainThread): Parsing macros/materializations/view/view.sql
2021-06-02 10:02:38.714246 (MainThread): Parsing macros/materializations/common/merge.sql
2021-06-02 10:02:38.724166 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-06-02 10:02:38.725344 (MainThread): Parsing macros/etc/query.sql
2021-06-02 10:02:38.726091 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-06-02 10:02:38.726762 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-06-02 10:02:38.728231 (MainThread): Parsing macros/etc/datetime.sql
2021-06-02 10:02:38.734619 (MainThread): Parsing macros/etc/is_incremental.sql
2021-06-02 10:02:38.736022 (MainThread): Parsing macros/adapters/common.sql
2021-06-02 10:02:38.771178 (MainThread): Partial parsing not enabled
2021-06-02 10:02:38.789140 (MainThread): Acquiring new bigquery connection "model.resourceplanner.EmployeeDates".
2021-06-02 10:02:38.797180 (MainThread): Acquiring new bigquery connection "model.resourceplanner.trydates".
2021-06-02 10:02:38.799652 (MainThread): Acquiring new bigquery connection "model.resourceplanner.FactTable".
2021-06-02 10:02:38.802109 (MainThread): Acquiring new bigquery connection "model.resourceplanner.my_second_dbt_model".
2021-06-02 10:02:38.804541 (MainThread): Acquiring new bigquery connection "model.resourceplanner.my_first_dbt_model".
2021-06-02 10:02:38.852287 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '975541bc-5836-4eb0-8478-ea1b3a2b2fd1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fab78d5a760>]}
2021-06-02 10:02:38.855657 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '975541bc-5836-4eb0-8478-ea1b3a2b2fd1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fab78d4efa0>]}
2021-06-02 10:02:38.855819 (MainThread): Found 5 models, 4 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-06-02 10:02:38.856565 (MainThread): 
2021-06-02 10:02:38.856806 (MainThread): Acquiring new bigquery connection "master".
2021-06-02 10:02:38.857539 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_oef-stage".
2021-06-02 10:02:38.857666 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-06-02 10:02:38.973492 (MainThread): Connection 'master' was properly closed.
2021-06-02 10:02:38.973611 (MainThread): Connection 'list_oef-stage' was properly closed.
2021-06-02 10:02:38.973727 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fab78e43460>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fab78cf83d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fab78d277c0>]}
2021-06-02 10:02:38.973898 (MainThread): Flushing usage events
2021-06-02 10:02:39.383186 (MainThread): Encountered an error:
2021-06-02 10:02:39.383871 (MainThread): Runtime Error
  Unable to generate access token, if you're using impersonate_service_account, make sure your initial account has the "roles/iam.serviceAccountTokenCreator" role on the account you are trying to impersonate.
  
  ('invalid_grant: Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.', {'error': 'invalid_grant', 'error_description': 'Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.'})
2021-06-02 10:02:39.385714 (MainThread): Traceback (most recent call last):
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 149, in exception_handler
    yield
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/impl.py", line 203, in query_schemas
    return [ds.dataset_id for ds in all_datasets]
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/impl.py", line 203, in <listcomp>
    return [ds.dataset_id for ds in all_datasets]
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/page_iterator.py", line 212, in _items_iter
    for page in self._page_iter(increment=False):
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/page_iterator.py", line 243, in _page_iter
    page = self._next_page()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/page_iterator.py", line 369, in _next_page
    response = self._get_next_page_response()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/page_iterator.py", line 418, in _get_next_page_response
    return self.api_request(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 369, in api_request
    return self._call_api(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 636, in _call_api
    return call()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/_http.py", line 427, in api_request
    response = self._make_request(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/_http.py", line 291, in _make_request
    return self._do_request(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/_http.py", line 329, in _do_request
    return self.http.request(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/auth/transport/requests.py", line 478, in request
    self.credentials.before_request(auth_request, method, url, request_headers)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/auth/credentials.py", line 133, in before_request
    self.refresh(request)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/oauth2/service_account.py", line 376, in refresh
    access_token, expiry, _ = _client.jwt_grant(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/oauth2/_client.py", line 193, in jwt_grant
    response_data = _token_endpoint_request(request, token_uri, body)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/oauth2/_client.py", line 165, in _token_endpoint_request
    _handle_error_response(response_data)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/oauth2/_client.py", line 60, in _handle_error_response
    raise exceptions.RefreshError(error_details, response_data)
google.auth.exceptions.RefreshError: ('invalid_grant: Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.', {'error': 'invalid_grant', 'error_description': 'Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.'})

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/main.py", line 125, in main
    results, succeeded = handle_and_check(args)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/main.py", line 203, in handle_and_check
    task, res = run_from_args(parsed)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/main.py", line 256, in run_from_args
    results = task.run()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/runnable.py", line 426, in run
    result = self.execute_with_hooks(selected_uids)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/runnable.py", line 383, in execute_with_hooks
    self.before_run(adapter, selected_uids)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/run.py", line 409, in before_run
    self.create_schemas(adapter, selected_uids)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/runnable.py", line 515, in create_schemas
    existing_schemas_lowered.update(ls_future.result())
  File "/usr/lib/python3.8/concurrent/futures/_base.py", line 432, in result
    return self.__get_result()
  File "/usr/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
    raise self._exception
  File "/usr/lib/python3.8/concurrent/futures/thread.py", line 57, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/utils.py", line 469, in connected
    return func(*args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/runnable.py", line 492, in list_schemas
    for s in adapter.list_schemas(database_quoted)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/impl.py", line 205, in list_schemas
    return self.connections._retry_and_handle(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 166, in exception_handler
    raise RuntimeException(message)
dbt.exceptions.RuntimeException: Runtime Error
  Unable to generate access token, if you're using impersonate_service_account, make sure your initial account has the "roles/iam.serviceAccountTokenCreator" role on the account you are trying to impersonate.
  
  ('invalid_grant: Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.', {'error': 'invalid_grant', 'error_description': 'Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.'})

2021-06-02 10:02:42.970574 (MainThread): Running with dbt=0.19.1
2021-06-02 10:02:43.159119 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/home/femke/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-06-02 10:02:43.159752 (MainThread): Tracking: tracking
2021-06-02 10:02:43.171599 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f31ac28ff10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f31ac34f490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f31ac2a34c0>]}
2021-06-02 10:02:43.188055 (MainThread): Partial parsing not enabled
2021-06-02 10:02:43.188829 (MainThread): Parsing macros/catalog.sql
2021-06-02 10:02:43.196861 (MainThread): Parsing macros/adapters.sql
2021-06-02 10:02:43.218956 (MainThread): Parsing macros/etc.sql
2021-06-02 10:02:43.220725 (MainThread): Parsing macros/materializations/snapshot.sql
2021-06-02 10:02:43.222166 (MainThread): Parsing macros/materializations/copy.sql
2021-06-02 10:02:43.225405 (MainThread): Parsing macros/materializations/table.sql
2021-06-02 10:02:43.232568 (MainThread): Parsing macros/materializations/incremental.sql
2021-06-02 10:02:43.241808 (MainThread): Parsing macros/materializations/view.sql
2021-06-02 10:02:43.243798 (MainThread): Parsing macros/materializations/seed.sql
2021-06-02 10:02:43.246228 (MainThread): Parsing macros/core.sql
2021-06-02 10:02:43.248955 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-06-02 10:02:43.249968 (MainThread): Parsing macros/schema_tests/unique.sql
2021-06-02 10:02:43.251223 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-06-02 10:02:43.252568 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-06-02 10:02:43.254743 (MainThread): Parsing macros/materializations/helpers.sql
2021-06-02 10:02:43.260868 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-06-02 10:02:43.262148 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-06-02 10:02:43.266453 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-06-02 10:02:43.281707 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-06-02 10:02:43.303266 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-06-02 10:02:43.304930 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-06-02 10:02:43.318140 (MainThread): Parsing macros/materializations/table/table.sql
2021-06-02 10:02:43.323118 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-06-02 10:02:43.326475 (MainThread): Parsing macros/materializations/view/view.sql
2021-06-02 10:02:43.330944 (MainThread): Parsing macros/materializations/common/merge.sql
2021-06-02 10:02:43.340665 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-06-02 10:02:43.341878 (MainThread): Parsing macros/etc/query.sql
2021-06-02 10:02:43.342654 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-06-02 10:02:43.343345 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-06-02 10:02:43.344794 (MainThread): Parsing macros/etc/datetime.sql
2021-06-02 10:02:43.350906 (MainThread): Parsing macros/etc/is_incremental.sql
2021-06-02 10:02:43.352088 (MainThread): Parsing macros/adapters/common.sql
2021-06-02 10:02:43.385153 (MainThread): Partial parsing not enabled
2021-06-02 10:02:43.402314 (MainThread): Acquiring new bigquery connection "model.resourceplanner.EmployeeDates".
2021-06-02 10:02:43.411479 (MainThread): Acquiring new bigquery connection "model.resourceplanner.trydates".
2021-06-02 10:02:43.414065 (MainThread): Acquiring new bigquery connection "model.resourceplanner.FactTable".
2021-06-02 10:02:43.416387 (MainThread): Acquiring new bigquery connection "model.resourceplanner.my_second_dbt_model".
2021-06-02 10:02:43.418853 (MainThread): Acquiring new bigquery connection "model.resourceplanner.my_first_dbt_model".
2021-06-02 10:02:43.466201 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '55a2c57a-bc70-41e9-ab6a-22bc18134fab', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f31a99ed310>]}
2021-06-02 10:02:43.469274 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '55a2c57a-bc70-41e9-ab6a-22bc18134fab', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f31a99e2ee0>]}
2021-06-02 10:02:43.469430 (MainThread): Found 5 models, 4 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-06-02 10:02:43.470354 (MainThread): 
2021-06-02 10:02:43.470594 (MainThread): Acquiring new bigquery connection "master".
2021-06-02 10:02:43.471295 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_oef-stage".
2021-06-02 10:02:43.471428 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-06-02 10:02:43.534927 (MainThread): Connection 'master' was properly closed.
2021-06-02 10:02:43.535053 (MainThread): Connection 'list_oef-stage' was properly closed.
2021-06-02 10:02:43.535166 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f31a9ad73a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f31a99aef40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f31a9a8be80>]}
2021-06-02 10:02:43.535317 (MainThread): Flushing usage events
2021-06-02 10:02:43.924661 (MainThread): Encountered an error:
2021-06-02 10:02:43.925080 (MainThread): Runtime Error
  Unable to generate access token, if you're using impersonate_service_account, make sure your initial account has the "roles/iam.serviceAccountTokenCreator" role on the account you are trying to impersonate.
  
  ('invalid_grant: Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.', {'error': 'invalid_grant', 'error_description': 'Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.'})
2021-06-02 10:02:43.926866 (MainThread): Traceback (most recent call last):
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 149, in exception_handler
    yield
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/impl.py", line 203, in query_schemas
    return [ds.dataset_id for ds in all_datasets]
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/impl.py", line 203, in <listcomp>
    return [ds.dataset_id for ds in all_datasets]
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/page_iterator.py", line 212, in _items_iter
    for page in self._page_iter(increment=False):
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/page_iterator.py", line 243, in _page_iter
    page = self._next_page()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/page_iterator.py", line 369, in _next_page
    response = self._get_next_page_response()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/page_iterator.py", line 418, in _get_next_page_response
    return self.api_request(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 369, in api_request
    return self._call_api(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 636, in _call_api
    return call()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/_http.py", line 427, in api_request
    response = self._make_request(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/_http.py", line 291, in _make_request
    return self._do_request(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/_http.py", line 329, in _do_request
    return self.http.request(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/auth/transport/requests.py", line 478, in request
    self.credentials.before_request(auth_request, method, url, request_headers)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/auth/credentials.py", line 133, in before_request
    self.refresh(request)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/oauth2/service_account.py", line 376, in refresh
    access_token, expiry, _ = _client.jwt_grant(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/oauth2/_client.py", line 193, in jwt_grant
    response_data = _token_endpoint_request(request, token_uri, body)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/oauth2/_client.py", line 165, in _token_endpoint_request
    _handle_error_response(response_data)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/oauth2/_client.py", line 60, in _handle_error_response
    raise exceptions.RefreshError(error_details, response_data)
google.auth.exceptions.RefreshError: ('invalid_grant: Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.', {'error': 'invalid_grant', 'error_description': 'Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.'})

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/main.py", line 125, in main
    results, succeeded = handle_and_check(args)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/main.py", line 203, in handle_and_check
    task, res = run_from_args(parsed)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/main.py", line 256, in run_from_args
    results = task.run()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/runnable.py", line 426, in run
    result = self.execute_with_hooks(selected_uids)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/runnable.py", line 383, in execute_with_hooks
    self.before_run(adapter, selected_uids)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/run.py", line 409, in before_run
    self.create_schemas(adapter, selected_uids)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/runnable.py", line 515, in create_schemas
    existing_schemas_lowered.update(ls_future.result())
  File "/usr/lib/python3.8/concurrent/futures/_base.py", line 432, in result
    return self.__get_result()
  File "/usr/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
    raise self._exception
  File "/usr/lib/python3.8/concurrent/futures/thread.py", line 57, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/utils.py", line 469, in connected
    return func(*args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/runnable.py", line 492, in list_schemas
    for s in adapter.list_schemas(database_quoted)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/impl.py", line 205, in list_schemas
    return self.connections._retry_and_handle(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 166, in exception_handler
    raise RuntimeException(message)
dbt.exceptions.RuntimeException: Runtime Error
  Unable to generate access token, if you're using impersonate_service_account, make sure your initial account has the "roles/iam.serviceAccountTokenCreator" role on the account you are trying to impersonate.
  
  ('invalid_grant: Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.', {'error': 'invalid_grant', 'error_description': 'Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.'})

2021-06-02 10:03:33.181307 (MainThread): Running with dbt=0.19.1
2021-06-02 10:03:33.373951 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/home/femke/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-06-02 10:03:33.374709 (MainThread): Tracking: tracking
2021-06-02 10:03:33.385128 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f75b42e8cd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f75b5c5c220>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f75b5c5c520>]}
2021-06-02 10:03:33.400205 (MainThread): Partial parsing not enabled
2021-06-02 10:03:33.400904 (MainThread): Parsing macros/catalog.sql
2021-06-02 10:03:33.413489 (MainThread): Parsing macros/adapters.sql
2021-06-02 10:03:33.435857 (MainThread): Parsing macros/etc.sql
2021-06-02 10:03:33.437651 (MainThread): Parsing macros/materializations/snapshot.sql
2021-06-02 10:03:33.438884 (MainThread): Parsing macros/materializations/copy.sql
2021-06-02 10:03:33.442278 (MainThread): Parsing macros/materializations/table.sql
2021-06-02 10:03:33.449105 (MainThread): Parsing macros/materializations/incremental.sql
2021-06-02 10:03:33.457944 (MainThread): Parsing macros/materializations/view.sql
2021-06-02 10:03:33.459896 (MainThread): Parsing macros/materializations/seed.sql
2021-06-02 10:03:33.462266 (MainThread): Parsing macros/core.sql
2021-06-02 10:03:33.464919 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-06-02 10:03:33.465969 (MainThread): Parsing macros/schema_tests/unique.sql
2021-06-02 10:03:33.467116 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-06-02 10:03:33.468472 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-06-02 10:03:33.470597 (MainThread): Parsing macros/materializations/helpers.sql
2021-06-02 10:03:33.476816 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-06-02 10:03:33.478104 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-06-02 10:03:33.482531 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-06-02 10:03:33.497390 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-06-02 10:03:33.518731 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-06-02 10:03:33.519978 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-06-02 10:03:33.533331 (MainThread): Parsing macros/materializations/table/table.sql
2021-06-02 10:03:33.538653 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-06-02 10:03:33.542191 (MainThread): Parsing macros/materializations/view/view.sql
2021-06-02 10:03:33.546635 (MainThread): Parsing macros/materializations/common/merge.sql
2021-06-02 10:03:33.556396 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-06-02 10:03:33.557623 (MainThread): Parsing macros/etc/query.sql
2021-06-02 10:03:33.558338 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-06-02 10:03:33.558959 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-06-02 10:03:33.560361 (MainThread): Parsing macros/etc/datetime.sql
2021-06-02 10:03:33.566681 (MainThread): Parsing macros/etc/is_incremental.sql
2021-06-02 10:03:33.567861 (MainThread): Parsing macros/adapters/common.sql
2021-06-02 10:03:33.600732 (MainThread): Partial parsing not enabled
2021-06-02 10:03:33.618536 (MainThread): Acquiring new bigquery connection "model.resourceplanner.EmployeeDates".
2021-06-02 10:03:33.626245 (MainThread): Acquiring new bigquery connection "model.resourceplanner.trydates".
2021-06-02 10:03:33.628879 (MainThread): Acquiring new bigquery connection "model.resourceplanner.FactTable".
2021-06-02 10:03:33.631525 (MainThread): Acquiring new bigquery connection "model.resourceplanner.my_second_dbt_model".
2021-06-02 10:03:33.634998 (MainThread): Acquiring new bigquery connection "model.resourceplanner.my_first_dbt_model".
2021-06-02 10:03:33.693435 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '08cc3720-1cdc-47c0-be97-f06975d1f1d1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f75b3327760>]}
2021-06-02 10:03:33.696755 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '08cc3720-1cdc-47c0-be97-f06975d1f1d1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f75b331bfa0>]}
2021-06-02 10:03:33.696946 (MainThread): Found 5 models, 4 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-06-02 10:03:33.697750 (MainThread): 
2021-06-02 10:03:33.698007 (MainThread): Acquiring new bigquery connection "master".
2021-06-02 10:03:33.698722 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_oef-stage".
2021-06-02 10:03:33.698859 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-06-02 10:03:33.766483 (MainThread): Connection 'master' was properly closed.
2021-06-02 10:03:33.766631 (MainThread): Connection 'list_oef-stage' was properly closed.
2021-06-02 10:03:33.766772 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f75b3410460>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f75b32c53d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f75b32f47c0>]}
2021-06-02 10:03:33.766910 (MainThread): Flushing usage events
2021-06-02 10:03:34.146795 (MainThread): Encountered an error:
2021-06-02 10:03:34.147500 (MainThread): Runtime Error
  Unable to generate access token, if you're using impersonate_service_account, make sure your initial account has the "roles/iam.serviceAccountTokenCreator" role on the account you are trying to impersonate.
  
  ('invalid_grant: Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.', {'error': 'invalid_grant', 'error_description': 'Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.'})
2021-06-02 10:03:34.149420 (MainThread): Traceback (most recent call last):
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 149, in exception_handler
    yield
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/impl.py", line 203, in query_schemas
    return [ds.dataset_id for ds in all_datasets]
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/impl.py", line 203, in <listcomp>
    return [ds.dataset_id for ds in all_datasets]
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/page_iterator.py", line 212, in _items_iter
    for page in self._page_iter(increment=False):
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/page_iterator.py", line 243, in _page_iter
    page = self._next_page()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/page_iterator.py", line 369, in _next_page
    response = self._get_next_page_response()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/page_iterator.py", line 418, in _get_next_page_response
    return self.api_request(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 369, in api_request
    return self._call_api(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 636, in _call_api
    return call()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/_http.py", line 427, in api_request
    response = self._make_request(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/_http.py", line 291, in _make_request
    return self._do_request(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/_http.py", line 329, in _do_request
    return self.http.request(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/auth/transport/requests.py", line 478, in request
    self.credentials.before_request(auth_request, method, url, request_headers)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/auth/credentials.py", line 133, in before_request
    self.refresh(request)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/oauth2/service_account.py", line 376, in refresh
    access_token, expiry, _ = _client.jwt_grant(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/oauth2/_client.py", line 193, in jwt_grant
    response_data = _token_endpoint_request(request, token_uri, body)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/oauth2/_client.py", line 165, in _token_endpoint_request
    _handle_error_response(response_data)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/oauth2/_client.py", line 60, in _handle_error_response
    raise exceptions.RefreshError(error_details, response_data)
google.auth.exceptions.RefreshError: ('invalid_grant: Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.', {'error': 'invalid_grant', 'error_description': 'Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.'})

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/main.py", line 125, in main
    results, succeeded = handle_and_check(args)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/main.py", line 203, in handle_and_check
    task, res = run_from_args(parsed)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/main.py", line 256, in run_from_args
    results = task.run()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/runnable.py", line 426, in run
    result = self.execute_with_hooks(selected_uids)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/runnable.py", line 383, in execute_with_hooks
    self.before_run(adapter, selected_uids)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/run.py", line 409, in before_run
    self.create_schemas(adapter, selected_uids)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/runnable.py", line 515, in create_schemas
    existing_schemas_lowered.update(ls_future.result())
  File "/usr/lib/python3.8/concurrent/futures/_base.py", line 432, in result
    return self.__get_result()
  File "/usr/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
    raise self._exception
  File "/usr/lib/python3.8/concurrent/futures/thread.py", line 57, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/utils.py", line 469, in connected
    return func(*args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/runnable.py", line 492, in list_schemas
    for s in adapter.list_schemas(database_quoted)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/impl.py", line 205, in list_schemas
    return self.connections._retry_and_handle(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 166, in exception_handler
    raise RuntimeException(message)
dbt.exceptions.RuntimeException: Runtime Error
  Unable to generate access token, if you're using impersonate_service_account, make sure your initial account has the "roles/iam.serviceAccountTokenCreator" role on the account you are trying to impersonate.
  
  ('invalid_grant: Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.', {'error': 'invalid_grant', 'error_description': 'Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.'})

2021-06-02 10:08:23.129049 (MainThread): Running with dbt=0.19.1
2021-06-02 10:08:23.325635 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/home/femke/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-06-02 10:08:23.326348 (MainThread): Tracking: tracking
2021-06-02 10:08:23.339018 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8b4528de50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8b46c01220>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8b46c01520>]}
2021-06-02 10:08:23.358172 (MainThread): Partial parsing not enabled
2021-06-02 10:08:23.358909 (MainThread): Parsing macros/catalog.sql
2021-06-02 10:08:23.367740 (MainThread): Parsing macros/adapters.sql
2021-06-02 10:08:23.388858 (MainThread): Parsing macros/etc.sql
2021-06-02 10:08:23.390393 (MainThread): Parsing macros/materializations/snapshot.sql
2021-06-02 10:08:23.391613 (MainThread): Parsing macros/materializations/copy.sql
2021-06-02 10:08:23.395230 (MainThread): Parsing macros/materializations/table.sql
2021-06-02 10:08:23.404140 (MainThread): Parsing macros/materializations/incremental.sql
2021-06-02 10:08:23.413330 (MainThread): Parsing macros/materializations/view.sql
2021-06-02 10:08:23.415302 (MainThread): Parsing macros/materializations/seed.sql
2021-06-02 10:08:23.417703 (MainThread): Parsing macros/core.sql
2021-06-02 10:08:23.420681 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-06-02 10:08:23.421704 (MainThread): Parsing macros/schema_tests/unique.sql
2021-06-02 10:08:23.422890 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-06-02 10:08:23.424136 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-06-02 10:08:23.426062 (MainThread): Parsing macros/materializations/helpers.sql
2021-06-02 10:08:23.432365 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-06-02 10:08:23.433750 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-06-02 10:08:23.439994 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-06-02 10:08:23.454670 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-06-02 10:08:23.476382 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-06-02 10:08:23.477681 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-06-02 10:08:23.492051 (MainThread): Parsing macros/materializations/table/table.sql
2021-06-02 10:08:23.496896 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-06-02 10:08:23.500591 (MainThread): Parsing macros/materializations/view/view.sql
2021-06-02 10:08:23.505323 (MainThread): Parsing macros/materializations/common/merge.sql
2021-06-02 10:08:23.514790 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-06-02 10:08:23.515933 (MainThread): Parsing macros/etc/query.sql
2021-06-02 10:08:23.516683 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-06-02 10:08:23.517293 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-06-02 10:08:23.518765 (MainThread): Parsing macros/etc/datetime.sql
2021-06-02 10:08:23.526200 (MainThread): Parsing macros/etc/is_incremental.sql
2021-06-02 10:08:23.527350 (MainThread): Parsing macros/adapters/common.sql
2021-06-02 10:08:23.562180 (MainThread): Partial parsing not enabled
2021-06-02 10:08:23.579425 (MainThread): Acquiring new bigquery connection "model.resourceplanner.EmployeeDates".
2021-06-02 10:08:23.588058 (MainThread): Acquiring new bigquery connection "model.resourceplanner.trydates".
2021-06-02 10:08:23.590651 (MainThread): Acquiring new bigquery connection "model.resourceplanner.FactTable".
2021-06-02 10:08:23.593087 (MainThread): Acquiring new bigquery connection "model.resourceplanner.my_second_dbt_model".
2021-06-02 10:08:23.595562 (MainThread): Acquiring new bigquery connection "model.resourceplanner.my_first_dbt_model".
2021-06-02 10:08:23.645520 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '07767cce-8ae3-4916-a1cb-bd1cbf69686d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8b442cd760>]}
2021-06-02 10:08:23.649091 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '07767cce-8ae3-4916-a1cb-bd1cbf69686d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8b442c2fa0>]}
2021-06-02 10:08:23.649279 (MainThread): Found 5 models, 4 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-06-02 10:08:23.649988 (MainThread): 
2021-06-02 10:08:23.650239 (MainThread): Acquiring new bigquery connection "master".
2021-06-02 10:08:23.650923 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_oef-stage".
2021-06-02 10:08:23.651053 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-06-02 10:08:23.651181 (ThreadPoolExecutor-0_0): Got an error when attempting to create a bigquery client: 'Extra data: line 1 column 9 (char 8)'
2021-06-02 10:08:23.651438 (MainThread): Connection 'master' was properly closed.
2021-06-02 10:08:23.651485 (MainThread): Connection 'list_oef-stage' was properly closed.
2021-06-02 10:08:23.651542 (MainThread): ERROR: Database Error
  Extra data: line 1 column 9 (char 8)
2021-06-02 10:08:23.651705 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8b443b5460>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8b44273400>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8b442def70>]}
2021-06-02 10:08:23.651831 (MainThread): Flushing usage events
2021-06-02 10:10:19.984017 (MainThread): Running with dbt=0.19.1
2021-06-02 10:10:20.175242 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/home/femke/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-06-02 10:10:20.175955 (MainThread): Tracking: tracking
2021-06-02 10:10:20.186516 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f33f7686ee0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f33f8fb91f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f33f8fb95b0>]}
2021-06-02 10:10:20.205868 (MainThread): Partial parsing not enabled
2021-06-02 10:10:20.206662 (MainThread): Parsing macros/catalog.sql
2021-06-02 10:10:20.215586 (MainThread): Parsing macros/adapters.sql
2021-06-02 10:10:20.236465 (MainThread): Parsing macros/etc.sql
2021-06-02 10:10:20.238068 (MainThread): Parsing macros/materializations/snapshot.sql
2021-06-02 10:10:20.239300 (MainThread): Parsing macros/materializations/copy.sql
2021-06-02 10:10:20.242407 (MainThread): Parsing macros/materializations/table.sql
2021-06-02 10:10:20.249282 (MainThread): Parsing macros/materializations/incremental.sql
2021-06-02 10:10:20.257880 (MainThread): Parsing macros/materializations/view.sql
2021-06-02 10:10:20.259755 (MainThread): Parsing macros/materializations/seed.sql
2021-06-02 10:10:20.262172 (MainThread): Parsing macros/core.sql
2021-06-02 10:10:20.264733 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-06-02 10:10:20.265779 (MainThread): Parsing macros/schema_tests/unique.sql
2021-06-02 10:10:20.274927 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-06-02 10:10:20.282143 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-06-02 10:10:20.283939 (MainThread): Parsing macros/materializations/helpers.sql
2021-06-02 10:10:20.289919 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-06-02 10:10:20.291209 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-06-02 10:10:20.295573 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-06-02 10:10:20.310010 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-06-02 10:10:20.333576 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-06-02 10:10:20.335255 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-06-02 10:10:20.354198 (MainThread): Parsing macros/materializations/table/table.sql
2021-06-02 10:10:20.359028 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-06-02 10:10:20.362429 (MainThread): Parsing macros/materializations/view/view.sql
2021-06-02 10:10:20.367562 (MainThread): Parsing macros/materializations/common/merge.sql
2021-06-02 10:10:20.376871 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-06-02 10:10:20.378032 (MainThread): Parsing macros/etc/query.sql
2021-06-02 10:10:20.378749 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-06-02 10:10:20.379366 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-06-02 10:10:20.380918 (MainThread): Parsing macros/etc/datetime.sql
2021-06-02 10:10:20.386918 (MainThread): Parsing macros/etc/is_incremental.sql
2021-06-02 10:10:20.388041 (MainThread): Parsing macros/adapters/common.sql
2021-06-02 10:10:20.420510 (MainThread): Partial parsing not enabled
2021-06-02 10:10:20.438268 (MainThread): Acquiring new bigquery connection "model.resourceplanner.EmployeeDates".
2021-06-02 10:10:20.445397 (MainThread): Acquiring new bigquery connection "model.resourceplanner.trydates".
2021-06-02 10:10:20.447855 (MainThread): Acquiring new bigquery connection "model.resourceplanner.FactTable".
2021-06-02 10:10:20.450281 (MainThread): Acquiring new bigquery connection "model.resourceplanner.my_second_dbt_model".
2021-06-02 10:10:20.452703 (MainThread): Acquiring new bigquery connection "model.resourceplanner.my_first_dbt_model".
2021-06-02 10:10:20.499107 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd150b993-0eae-4c5f-be87-8f72b46ccfaf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f33f66b1f70>]}
2021-06-02 10:10:20.502753 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd150b993-0eae-4c5f-be87-8f72b46ccfaf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f33f66c57f0>]}
2021-06-02 10:10:20.502956 (MainThread): Found 5 models, 4 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-06-02 10:10:20.503677 (MainThread): 
2021-06-02 10:10:20.503931 (MainThread): Acquiring new bigquery connection "master".
2021-06-02 10:10:20.504635 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_oef-stage".
2021-06-02 10:10:20.504765 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-06-02 10:10:20.504896 (ThreadPoolExecutor-0_0): Got an error when attempting to create a bigquery client: 'Extra data: line 1 column 9 (char 8)'
2021-06-02 10:10:20.505153 (MainThread): Connection 'master' was properly closed.
2021-06-02 10:10:20.505200 (MainThread): Connection 'list_oef-stage' was properly closed.
2021-06-02 10:10:20.505259 (MainThread): ERROR: Database Error
  Extra data: line 1 column 9 (char 8)
2021-06-02 10:10:20.505431 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f33f67ae4f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f33f66d6fd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f33f6681040>]}
2021-06-02 10:10:20.505611 (MainThread): Flushing usage events
2021-06-02 10:13:46.642626 (MainThread): Running with dbt=0.19.1
2021-06-02 10:13:46.835984 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/home/femke/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-06-02 10:13:46.836846 (MainThread): Tracking: tracking
2021-06-02 10:13:46.847684 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbf58fe1d00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbf5a9151c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbf5a915550>]}
2021-06-02 10:13:46.869651 (MainThread): Partial parsing not enabled
2021-06-02 10:13:46.870487 (MainThread): Parsing macros/catalog.sql
2021-06-02 10:13:46.879425 (MainThread): Parsing macros/adapters.sql
2021-06-02 10:13:46.902259 (MainThread): Parsing macros/etc.sql
2021-06-02 10:13:46.904426 (MainThread): Parsing macros/materializations/snapshot.sql
2021-06-02 10:13:46.905717 (MainThread): Parsing macros/materializations/copy.sql
2021-06-02 10:13:46.909058 (MainThread): Parsing macros/materializations/table.sql
2021-06-02 10:13:46.916999 (MainThread): Parsing macros/materializations/incremental.sql
2021-06-02 10:13:46.926498 (MainThread): Parsing macros/materializations/view.sql
2021-06-02 10:13:46.928537 (MainThread): Parsing macros/materializations/seed.sql
2021-06-02 10:13:46.930936 (MainThread): Parsing macros/core.sql
2021-06-02 10:13:46.935716 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-06-02 10:13:46.937580 (MainThread): Parsing macros/schema_tests/unique.sql
2021-06-02 10:13:46.938909 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-06-02 10:13:46.940488 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-06-02 10:13:46.944011 (MainThread): Parsing macros/materializations/helpers.sql
2021-06-02 10:13:46.962660 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-06-02 10:13:46.964138 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-06-02 10:13:46.969049 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-06-02 10:13:46.984550 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-06-02 10:13:47.005667 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-06-02 10:13:47.006931 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-06-02 10:13:47.019634 (MainThread): Parsing macros/materializations/table/table.sql
2021-06-02 10:13:47.024235 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-06-02 10:13:47.027649 (MainThread): Parsing macros/materializations/view/view.sql
2021-06-02 10:13:47.031948 (MainThread): Parsing macros/materializations/common/merge.sql
2021-06-02 10:13:47.041380 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-06-02 10:13:47.042530 (MainThread): Parsing macros/etc/query.sql
2021-06-02 10:13:47.043247 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-06-02 10:13:47.043838 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-06-02 10:13:47.045432 (MainThread): Parsing macros/etc/datetime.sql
2021-06-02 10:13:47.051311 (MainThread): Parsing macros/etc/is_incremental.sql
2021-06-02 10:13:47.052432 (MainThread): Parsing macros/adapters/common.sql
2021-06-02 10:13:47.084177 (MainThread): Partial parsing not enabled
2021-06-02 10:13:47.101157 (MainThread): Acquiring new bigquery connection "model.resourceplanner.EmployeeDates".
2021-06-02 10:13:47.108571 (MainThread): Acquiring new bigquery connection "model.resourceplanner.trydates".
2021-06-02 10:13:47.110949 (MainThread): Acquiring new bigquery connection "model.resourceplanner.FactTable".
2021-06-02 10:13:47.113547 (MainThread): Acquiring new bigquery connection "model.resourceplanner.my_second_dbt_model".
2021-06-02 10:13:47.115899 (MainThread): Acquiring new bigquery connection "model.resourceplanner.my_first_dbt_model".
2021-06-02 10:13:47.163190 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b382f212-cb38-42d0-95d7-f0900f647e1c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbf5801f7c0>]}
2021-06-02 10:13:47.166549 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'b382f212-cb38-42d0-95d7-f0900f647e1c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbf5800cf40>]}
2021-06-02 10:13:47.166741 (MainThread): Found 5 models, 4 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-06-02 10:13:47.167468 (MainThread): 
2021-06-02 10:13:47.167719 (MainThread): Acquiring new bigquery connection "master".
2021-06-02 10:13:47.168475 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_oef-stage".
2021-06-02 10:13:47.168612 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-06-02 10:13:47.168750 (ThreadPoolExecutor-0_0): Got an error when attempting to create a bigquery client: 'Extra data: line 1 column 9 (char 8)'
2021-06-02 10:13:47.169056 (MainThread): Connection 'master' was properly closed.
2021-06-02 10:13:47.169106 (MainThread): Connection 'list_oef-stage' was properly closed.
2021-06-02 10:13:47.169161 (MainThread): ERROR: Database Error
  Extra data: line 1 column 9 (char 8)
2021-06-02 10:13:47.169378 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbf58109490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbf57fdc040>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbf57fd9fa0>]}
2021-06-02 10:13:47.169527 (MainThread): Flushing usage events
2021-06-02 13:11:49.684286 (MainThread): Running with dbt=0.19.1
2021-06-02 13:11:49.864688 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/home/femke/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-06-02 13:11:49.865457 (MainThread): Tracking: tracking
2021-06-02 13:11:49.879763 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f51318efca0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f51331e3190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f51331e3580>]}
2021-06-02 13:11:49.890849 (MainThread): Partial parsing not enabled
2021-06-02 13:11:49.891555 (MainThread): Parsing macros/catalog.sql
2021-06-02 13:11:49.899946 (MainThread): Parsing macros/adapters.sql
2021-06-02 13:11:49.921854 (MainThread): Parsing macros/etc.sql
2021-06-02 13:11:49.923323 (MainThread): Parsing macros/materializations/snapshot.sql
2021-06-02 13:11:49.924549 (MainThread): Parsing macros/materializations/copy.sql
2021-06-02 13:11:49.927670 (MainThread): Parsing macros/materializations/table.sql
2021-06-02 13:11:49.934590 (MainThread): Parsing macros/materializations/incremental.sql
2021-06-02 13:11:49.943388 (MainThread): Parsing macros/materializations/view.sql
2021-06-02 13:11:49.945326 (MainThread): Parsing macros/materializations/seed.sql
2021-06-02 13:11:49.947728 (MainThread): Parsing macros/core.sql
2021-06-02 13:11:49.950372 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-06-02 13:11:49.951441 (MainThread): Parsing macros/schema_tests/unique.sql
2021-06-02 13:11:49.952602 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-06-02 13:11:49.953914 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-06-02 13:11:49.955787 (MainThread): Parsing macros/materializations/helpers.sql
2021-06-02 13:11:49.961793 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-06-02 13:11:49.963072 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-06-02 13:11:49.967432 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-06-02 13:11:49.981432 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-06-02 13:11:50.001879 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-06-02 13:11:50.003134 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-06-02 13:11:50.015800 (MainThread): Parsing macros/materializations/table/table.sql
2021-06-02 13:11:50.020418 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-06-02 13:11:50.023868 (MainThread): Parsing macros/materializations/view/view.sql
2021-06-02 13:11:50.028146 (MainThread): Parsing macros/materializations/common/merge.sql
2021-06-02 13:11:50.037413 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-06-02 13:11:50.038631 (MainThread): Parsing macros/etc/query.sql
2021-06-02 13:11:50.039340 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-06-02 13:11:50.039967 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-06-02 13:11:50.041342 (MainThread): Parsing macros/etc/datetime.sql
2021-06-02 13:11:50.047378 (MainThread): Parsing macros/etc/is_incremental.sql
2021-06-02 13:11:50.048524 (MainThread): Parsing macros/adapters/common.sql
2021-06-02 13:11:50.079388 (MainThread): Partial parsing not enabled
2021-06-02 13:11:50.095566 (MainThread): Acquiring new bigquery connection "model.resourceplanner.EmployeeDates".
2021-06-02 13:11:50.102457 (MainThread): Acquiring new bigquery connection "model.resourceplanner.trydates".
2021-06-02 13:11:50.104841 (MainThread): Acquiring new bigquery connection "model.resourceplanner.FactTable".
2021-06-02 13:11:50.107270 (MainThread): Acquiring new bigquery connection "model.resourceplanner.my_second_dbt_model".
2021-06-02 13:11:50.109610 (MainThread): Acquiring new bigquery connection "model.resourceplanner.my_first_dbt_model".
2021-06-02 13:11:50.154567 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '3e82901b-6943-4f20-9b9a-e489b3245aba', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f513092e7c0>]}
2021-06-02 13:11:50.157908 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '3e82901b-6943-4f20-9b9a-e489b3245aba', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f513091af40>]}
2021-06-02 13:11:50.158062 (MainThread): Found 5 models, 4 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-06-02 13:11:50.158799 (MainThread): 
2021-06-02 13:11:50.159043 (MainThread): Acquiring new bigquery connection "master".
2021-06-02 13:11:50.159733 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_oef-stage".
2021-06-02 13:11:50.159859 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-06-02 13:11:50.554915 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_oef-stage_TestRecoursePlanner".
2021-06-02 13:11:50.555086 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2021-06-02 13:11:50.558199 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-06-02 13:11:50.730342 (MainThread): 15:11:50 | Concurrency: 5 threads (target='dev')
2021-06-02 13:11:50.733400 (MainThread): 15:11:50 | 
2021-06-02 13:11:50.735807 (Thread-1): Began running node model.resourceplanner.my_first_dbt_model
2021-06-02 13:11:50.736105 (Thread-1): 15:11:50 | 1 of 5 START table model TestRecoursePlanner.my_first_dbt_model...... [RUN]
2021-06-02 13:11:50.736269 (Thread-2): Began running node model.resourceplanner.EmployeeDates
2021-06-02 13:11:50.736383 (Thread-2): 15:11:50 | 2 of 5 START table model TestRecoursePlanner.EmployeeDates........... [RUN]
2021-06-02 13:11:50.736452 (Thread-3): Began running node model.resourceplanner.FactTable
2021-06-02 13:11:50.736552 (Thread-3): 15:11:50 | 3 of 5 START table model TestRecoursePlanner.FactTable............... [RUN]
2021-06-02 13:11:50.736617 (Thread-4): Began running node model.resourceplanner.trydates
2021-06-02 13:11:50.736719 (Thread-4): 15:11:50 | 4 of 5 START table model TestRecoursePlanner.trydates................ [RUN]
2021-06-02 13:11:50.737013 (Thread-1): Acquiring new bigquery connection "model.resourceplanner.my_first_dbt_model".
2021-06-02 13:11:50.737096 (Thread-1): Compiling model.resourceplanner.my_first_dbt_model
2021-06-02 13:11:50.738995 (Thread-1): Writing injected SQL for node "model.resourceplanner.my_first_dbt_model"
2021-06-02 13:11:50.739211 (Thread-2): Acquiring new bigquery connection "model.resourceplanner.EmployeeDates".
2021-06-02 13:11:50.739659 (Thread-2): Compiling model.resourceplanner.EmployeeDates
2021-06-02 13:11:50.741553 (Thread-2): Writing injected SQL for node "model.resourceplanner.EmployeeDates"
2021-06-02 13:11:50.739384 (Thread-3): Acquiring new bigquery connection "model.resourceplanner.FactTable".
2021-06-02 13:11:50.742084 (Thread-3): Compiling model.resourceplanner.FactTable
2021-06-02 13:11:50.739549 (Thread-4): Acquiring new bigquery connection "model.resourceplanner.trydates".
2021-06-02 13:11:50.743192 (Thread-4): Compiling model.resourceplanner.trydates
2021-06-02 13:11:50.747578 (Thread-4): Writing injected SQL for node "model.resourceplanner.trydates"
2021-06-02 13:11:50.743115 (Thread-3): unclosed <socket.socket fd=5, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.0.2.15', 57606), raddr=('216.58.214.10', 443)>
2021-06-02 13:11:50.748206 (Thread-3): unclosed <socket.socket fd=6, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.0.2.15', 44838), raddr=('216.58.208.106', 443)>
2021-06-02 13:11:50.748424 (Thread-3): unclosed <socket.socket fd=8, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.0.2.15', 44842), raddr=('216.58.208.106', 443)>
2021-06-02 13:11:50.749081 (Thread-3): unclosed <socket.socket fd=7, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.0.2.15', 57610), raddr=('216.58.214.10', 443)>
2021-06-02 13:11:50.747971 (Thread-4): finished collecting timing info
2021-06-02 13:11:50.741968 (Thread-2): finished collecting timing info
2021-06-02 13:11:50.751831 (Thread-3): Writing injected SQL for node "model.resourceplanner.FactTable"
2021-06-02 13:11:50.802889 (Thread-3): finished collecting timing info
2021-06-02 13:11:50.802495 (Thread-1): finished collecting timing info
2021-06-02 13:11:50.824116 (Thread-1): Opening a new connection, currently in state closed
2021-06-02 13:11:50.829368 (Thread-2): Opening a new connection, currently in state closed
2021-06-02 13:11:50.832680 (Thread-3): Opening a new connection, currently in state init
2021-06-02 13:11:50.836560 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-06-02 13:11:50.822970 (Thread-4): Opening a new connection, currently in state init
2021-06-02 13:11:50.845414 (Thread-4): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-06-02 13:11:50.846524 (Thread-3): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-06-02 13:11:50.848537 (Thread-2): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-06-02 13:11:51.063328 (Thread-2): Writing runtime SQL for node "model.resourceplanner.EmployeeDates"
2021-06-02 13:11:51.064301 (Thread-1): Writing runtime SQL for node "model.resourceplanner.my_first_dbt_model"
2021-06-02 13:11:51.065481 (Thread-3): Writing runtime SQL for node "model.resourceplanner.FactTable"
2021-06-02 13:11:51.065916 (Thread-1): On model.resourceplanner.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "Bigquery", "target_name": "dev", "node_id": "model.resourceplanner.my_first_dbt_model"} */


  create or replace table `oef-stage`.`TestRecoursePlanner`.`my_first_dbt_model`
  
  
  OPTIONS()
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select M.ID, E.EmployeeID, CU.CustomerID,CO.CompanyID
from oef-stage.TestRecoursePlanner.MainData M
INNER JOIN oef-stage.TestRecoursePlanner.Employee E
ON M.Employee = E.Firstname
INNER JOIN oef-stage.TestRecoursePlanner.Customer CU
ON M.Customer = CU.Customername
INNER JOIN oef-stage.TestRecoursePlanner.Company CO
ON M.Company = CO.Companyname
ORDER BY M.ID

/*
    Uncomment the line below to remove records with null `id` values
*/
  );
    
2021-06-02 13:11:51.066149 (Thread-3): On model.resourceplanner.FactTable: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "Bigquery", "target_name": "dev", "node_id": "model.resourceplanner.FactTable"} */


  create or replace table `oef-stage`.`TestRecoursePlanner`.`FactTable`
  
  
  OPTIONS()
  as (
    


SELECT
  T.id,
  TD.ID AS ProjectID,
  TD.EmployeeID,
  TD.CompanyID,
  TD.CustomerID,
  T.PM_AM,
  T.full_date,
  T.day_name,
  CASE
    WHEN T.day_name = "Monday" THEN IF (TD.Monday = 'Available', '0', IF (TD.Monday = 'Full', '0,5', IF (PM_AM = TD.Monday, '0,5', '0') ))
    WHEN T.day_name = "Tuesday" THEN IF (TD.Tuesday = 'Available', '0', IF (TD.Tuesday = 'Full', '0,5', IF (PM_AM = TD.Tuesday, '0,5', '0') ))
    WHEN T.day_name = "Wednesday" THEN IF (TD.Wednesday = 'Available', '0', IF (TD.Wednesday = 'Full', '0,5', IF (PM_AM = TD.Wednesday, '0,5', '0') ))
    WHEN T.day_name = "Thursday" THEN IF (TD.Thursday = 'Available', '0', IF (TD.Thursday = 'Full', '0,5', IF (PM_AM = TD.Thursday, '0,5', '0') ))
    WHEN T.day_name = "Friday" THEN IF (TD.Friday = 'Available', '0', IF (TD.Friday  = 'Full', '0,5', IF (PM_AM = TD.Friday , '0,5', '0') ))
  ELSE
  '0'
END
  AS Is_Booked
FROM
  `oef-stage.TestRecoursePlanner.Time` T
CROSS JOIN
  `oef-stage.TestRecoursePlanner.trydates` TD

WHERE T.full_Date  BETWEEN TD.DateStart
  AND TD.DateEnd
ORDER BY
  T.full_date
  );
    
2021-06-02 13:11:51.070294 (Thread-2): On model.resourceplanner.EmployeeDates: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "Bigquery", "target_name": "dev", "node_id": "model.resourceplanner.EmployeeDates"} */


  create or replace table `oef-stage`.`TestRecoursePlanner`.`EmployeeDates`
  
  
  OPTIONS()
  as (
    

SELECT DISTINCT E.EmployeeID, T.full_date
FROM oef-stage.TestRecoursePlanner.Time T
CROSS JOIN oef-stage.TestRecoursePlanner.Employee E
ORDER BY T.full_date
  );
    
2021-06-02 13:11:51.073460 (Thread-4): Writing runtime SQL for node "model.resourceplanner.trydates"
2021-06-02 13:11:51.073721 (Thread-4): On model.resourceplanner.trydates: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "Bigquery", "target_name": "dev", "node_id": "model.resourceplanner.trydates"} */


  create or replace table `oef-stage`.`TestRecoursePlanner`.`trydates`
  
  
  OPTIONS()
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/


with source_data as (

    select 1 as id
    union all
    select null as id

)

select M.ID, E.EmployeeID, CU.CustomerID,CO.CompanyID, M.DateStart, M.DateEnd, M.Monday, M.Tuesday, M.Wednesday , M.Thursday , M.Friday
from oef-stage.TestRecoursePlanner.MainData M
INNER JOIN oef-stage.TestRecoursePlanner.Employee E
ON M.Employee = E.Firstname
INNER JOIN oef-stage.TestRecoursePlanner.Customer CU
ON M.Customer = CU.Customername
INNER JOIN oef-stage.TestRecoursePlanner.Company CO
ON M.Company = CO.Companyname
ORDER BY M.ID

/*
    Uncomment the line below to remove records with null `id` values
*/
  );
    
2021-06-02 13:11:53.102622 (Thread-3): finished collecting timing info
2021-06-02 13:11:53.102965 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3e82901b-6943-4f20-9b9a-e489b3245aba', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f51286e3340>]}
2021-06-02 13:11:53.103183 (Thread-3): 15:11:53 | 3 of 5 OK created table model TestRecoursePlanner.FactTable.......... [CREATE TABLE (992.0 rows, 251.6 KB processed) in 2.36s]
2021-06-02 13:11:53.103398 (Thread-3): Finished running node model.resourceplanner.FactTable
2021-06-02 13:11:54.134310 (Thread-2): finished collecting timing info
2021-06-02 13:11:54.134686 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3e82901b-6943-4f20-9b9a-e489b3245aba', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f512874a760>]}
2021-06-02 13:11:54.134908 (Thread-2): 15:11:54 | 2 of 5 OK created table model TestRecoursePlanner.EmployeeDates...... [CREATE TABLE (43.8k rows, 57.8 KB processed) in 3.40s]
2021-06-02 13:11:54.135091 (Thread-2): Finished running node model.resourceplanner.EmployeeDates
2021-06-02 13:11:55.088490 (Thread-1): finished collecting timing info
2021-06-02 13:11:55.088853 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3e82901b-6943-4f20-9b9a-e489b3245aba', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f51286fa310>]}
2021-06-02 13:11:55.089124 (Thread-1): 15:11:55 | 1 of 5 OK created table model TestRecoursePlanner.my_first_dbt_model. [CREATE TABLE (14.0 rows, 5.4 KB processed) in 4.35s]
2021-06-02 13:11:55.089345 (Thread-1): Finished running node model.resourceplanner.my_first_dbt_model
2021-06-02 13:11:55.089614 (Thread-5): Began running node model.resourceplanner.my_second_dbt_model
2021-06-02 13:11:55.089737 (Thread-5): 15:11:55 | 5 of 5 START view model TestRecoursePlanner.my_second_dbt_model...... [RUN]
2021-06-02 13:11:55.089954 (Thread-5): Acquiring new bigquery connection "model.resourceplanner.my_second_dbt_model".
2021-06-02 13:11:55.090111 (Thread-5): Compiling model.resourceplanner.my_second_dbt_model
2021-06-02 13:11:55.092068 (Thread-5): Writing injected SQL for node "model.resourceplanner.my_second_dbt_model"
2021-06-02 13:11:55.092361 (Thread-5): finished collecting timing info
2021-06-02 13:11:55.112180 (Thread-5): Writing runtime SQL for node "model.resourceplanner.my_second_dbt_model"
2021-06-02 13:11:55.112978 (Thread-5): Opening a new connection, currently in state init
2021-06-02 13:11:55.123421 (Thread-5): On model.resourceplanner.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "Bigquery", "target_name": "dev", "node_id": "model.resourceplanner.my_second_dbt_model"} */


  create or replace view `oef-stage`.`TestRecoursePlanner`.`my_second_dbt_model`
  OPTIONS()
  as -- Use the `ref` function to select from other models

select *
from `oef-stage`.`TestRecoursePlanner`.`my_first_dbt_model`;


2021-06-02 13:11:55.416023 (Thread-4): finished collecting timing info
2021-06-02 13:11:55.416385 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3e82901b-6943-4f20-9b9a-e489b3245aba', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f512876ca00>]}
2021-06-02 13:11:55.416605 (Thread-4): 15:11:55 | 4 of 5 OK created table model TestRecoursePlanner.trydates........... [CREATE TABLE (14.0 rows, 5.4 KB processed) in 4.68s]
2021-06-02 13:11:55.416800 (Thread-4): Finished running node model.resourceplanner.trydates
2021-06-02 13:11:55.662311 (Thread-5): finished collecting timing info
2021-06-02 13:11:55.662624 (Thread-5): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3e82901b-6943-4f20-9b9a-e489b3245aba', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f512877cb80>]}
2021-06-02 13:11:55.662881 (Thread-5): 15:11:55 | 5 of 5 OK created view model TestRecoursePlanner.my_second_dbt_model. [OK in 0.57s]
2021-06-02 13:11:55.663066 (Thread-5): Finished running node model.resourceplanner.my_second_dbt_model
2021-06-02 13:11:55.664018 (MainThread): Acquiring new bigquery connection "master".
2021-06-02 13:11:55.664189 (MainThread): 15:11:55 | 
2021-06-02 13:11:55.664292 (MainThread): 15:11:55 | Finished running 4 table models, 1 view model in 5.51s.
2021-06-02 13:11:55.664382 (MainThread): Connection 'master' was properly closed.
2021-06-02 13:11:55.664423 (MainThread): Connection 'model.resourceplanner.EmployeeDates' was properly closed.
2021-06-02 13:11:55.664455 (MainThread): Connection 'model.resourceplanner.my_first_dbt_model' was properly closed.
2021-06-02 13:11:55.664484 (MainThread): Connection 'model.resourceplanner.FactTable' was properly closed.
2021-06-02 13:11:55.664513 (MainThread): Connection 'model.resourceplanner.trydates' was properly closed.
2021-06-02 13:11:55.664541 (MainThread): Connection 'model.resourceplanner.my_second_dbt_model' was properly closed.
2021-06-02 13:11:55.667717 (MainThread): 
2021-06-02 13:11:55.667837 (MainThread): Completed successfully
2021-06-02 13:11:55.667942 (MainThread): 
Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
2021-06-02 13:11:55.668096 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f51309243a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5130924040>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5130911b50>]}
2021-06-02 13:11:55.668209 (MainThread): Flushing usage events
2021-06-02 17:49:07.242181 (MainThread): Running with dbt=0.19.1
2021-06-02 17:49:07.431371 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/home/femke/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-06-02 17:49:07.431991 (MainThread): Tracking: tracking
2021-06-02 17:49:07.446222 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb99dff6e80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb99f8ea160>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb99f8ea550>]}
2021-06-02 17:49:07.457460 (MainThread): Partial parsing not enabled
2021-06-02 17:49:07.462748 (MainThread): Parsing macros/catalog.sql
2021-06-02 17:49:07.478816 (MainThread): Parsing macros/adapters.sql
2021-06-02 17:49:07.493786 (MainThread): Parsing macros/etc.sql
2021-06-02 17:49:07.495356 (MainThread): Parsing macros/materializations/snapshot.sql
2021-06-02 17:49:07.496626 (MainThread): Parsing macros/materializations/copy.sql
2021-06-02 17:49:07.499672 (MainThread): Parsing macros/materializations/table.sql
2021-06-02 17:49:07.506717 (MainThread): Parsing macros/materializations/incremental.sql
2021-06-02 17:49:07.528740 (MainThread): Parsing macros/materializations/view.sql
2021-06-02 17:49:07.530845 (MainThread): Parsing macros/materializations/seed.sql
2021-06-02 17:49:07.533135 (MainThread): Parsing macros/core.sql
2021-06-02 17:49:07.535758 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-06-02 17:49:07.536762 (MainThread): Parsing macros/schema_tests/unique.sql
2021-06-02 17:49:07.537876 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-06-02 17:49:07.539133 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-06-02 17:49:07.540918 (MainThread): Parsing macros/materializations/helpers.sql
2021-06-02 17:49:07.548050 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-06-02 17:49:07.549763 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-06-02 17:49:07.555795 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-06-02 17:49:07.594019 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-06-02 17:49:07.615123 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-06-02 17:49:07.616388 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-06-02 17:49:07.628731 (MainThread): Parsing macros/materializations/table/table.sql
2021-06-02 17:49:07.633334 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-06-02 17:49:07.636740 (MainThread): Parsing macros/materializations/view/view.sql
2021-06-02 17:49:07.641045 (MainThread): Parsing macros/materializations/common/merge.sql
2021-06-02 17:49:07.650213 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-06-02 17:49:07.651379 (MainThread): Parsing macros/etc/query.sql
2021-06-02 17:49:07.652055 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-06-02 17:49:07.652690 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-06-02 17:49:07.654152 (MainThread): Parsing macros/etc/datetime.sql
2021-06-02 17:49:07.660027 (MainThread): Parsing macros/etc/is_incremental.sql
2021-06-02 17:49:07.661173 (MainThread): Parsing macros/adapters/common.sql
2021-06-02 17:49:07.692395 (MainThread): Partial parsing not enabled
2021-06-02 17:49:07.708950 (MainThread): Acquiring new bigquery connection "model.resourceplanner.EmployeeDates".
2021-06-02 17:49:07.715899 (MainThread): Acquiring new bigquery connection "model.resourceplanner.trydates".
2021-06-02 17:49:07.718303 (MainThread): Acquiring new bigquery connection "model.resourceplanner.FactTable".
2021-06-02 17:49:07.720655 (MainThread): Acquiring new bigquery connection "model.resourceplanner.my_second_dbt_model".
2021-06-02 17:49:07.722970 (MainThread): Acquiring new bigquery connection "model.resourceplanner.my_first_dbt_model".
2021-06-02 17:49:07.770544 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '71cfcf27-8ce3-41d1-bdcf-e4877ea1b9b6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb99d0357c0>]}
2021-06-02 17:49:07.774063 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '71cfcf27-8ce3-41d1-bdcf-e4877ea1b9b6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb99d021f40>]}
2021-06-02 17:49:07.774447 (MainThread): Found 5 models, 4 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-06-02 17:49:07.775162 (MainThread): 
2021-06-02 17:49:07.780434 (MainThread): Acquiring new bigquery connection "master".
2021-06-02 17:49:07.781930 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_oef-stage".
2021-06-02 17:49:07.782171 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-06-02 17:49:08.086181 (MainThread): Connection 'master' was properly closed.
2021-06-02 17:49:08.086303 (MainThread): Connection 'list_oef-stage' was properly closed.
2021-06-02 17:49:08.086590 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb99d11e490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb99cff1040>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb99d087790>]}
2021-06-02 17:49:08.086865 (MainThread): Flushing usage events
2021-06-02 17:49:08.518333 (MainThread): Encountered an error:
2021-06-02 17:49:08.518810 (MainThread): Runtime Error
  Unable to generate access token, if you're using impersonate_service_account, make sure your initial account has the "roles/iam.serviceAccountTokenCreator" role on the account you are trying to impersonate.
  
  ('invalid_grant: Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.', {'error': 'invalid_grant', 'error_description': 'Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.'})
2021-06-02 17:49:08.520746 (MainThread): Traceback (most recent call last):
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 149, in exception_handler
    yield
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/impl.py", line 203, in query_schemas
    return [ds.dataset_id for ds in all_datasets]
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/impl.py", line 203, in <listcomp>
    return [ds.dataset_id for ds in all_datasets]
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/page_iterator.py", line 212, in _items_iter
    for page in self._page_iter(increment=False):
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/page_iterator.py", line 243, in _page_iter
    page = self._next_page()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/page_iterator.py", line 369, in _next_page
    response = self._get_next_page_response()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/page_iterator.py", line 418, in _get_next_page_response
    return self.api_request(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 369, in api_request
    return self._call_api(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 636, in _call_api
    return call()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/_http.py", line 427, in api_request
    response = self._make_request(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/_http.py", line 291, in _make_request
    return self._do_request(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/_http.py", line 329, in _do_request
    return self.http.request(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/auth/transport/requests.py", line 478, in request
    self.credentials.before_request(auth_request, method, url, request_headers)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/auth/credentials.py", line 133, in before_request
    self.refresh(request)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/oauth2/service_account.py", line 376, in refresh
    access_token, expiry, _ = _client.jwt_grant(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/oauth2/_client.py", line 193, in jwt_grant
    response_data = _token_endpoint_request(request, token_uri, body)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/oauth2/_client.py", line 165, in _token_endpoint_request
    _handle_error_response(response_data)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/oauth2/_client.py", line 60, in _handle_error_response
    raise exceptions.RefreshError(error_details, response_data)
google.auth.exceptions.RefreshError: ('invalid_grant: Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.', {'error': 'invalid_grant', 'error_description': 'Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.'})

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/main.py", line 125, in main
    results, succeeded = handle_and_check(args)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/main.py", line 203, in handle_and_check
    task, res = run_from_args(parsed)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/main.py", line 256, in run_from_args
    results = task.run()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/runnable.py", line 426, in run
    result = self.execute_with_hooks(selected_uids)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/runnable.py", line 383, in execute_with_hooks
    self.before_run(adapter, selected_uids)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/run.py", line 409, in before_run
    self.create_schemas(adapter, selected_uids)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/runnable.py", line 515, in create_schemas
    existing_schemas_lowered.update(ls_future.result())
  File "/usr/lib/python3.8/concurrent/futures/_base.py", line 432, in result
    return self.__get_result()
  File "/usr/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
    raise self._exception
  File "/usr/lib/python3.8/concurrent/futures/thread.py", line 57, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/utils.py", line 469, in connected
    return func(*args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/runnable.py", line 492, in list_schemas
    for s in adapter.list_schemas(database_quoted)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/impl.py", line 205, in list_schemas
    return self.connections._retry_and_handle(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 166, in exception_handler
    raise RuntimeException(message)
dbt.exceptions.RuntimeException: Runtime Error
  Unable to generate access token, if you're using impersonate_service_account, make sure your initial account has the "roles/iam.serviceAccountTokenCreator" role on the account you are trying to impersonate.
  
  ('invalid_grant: Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.', {'error': 'invalid_grant', 'error_description': 'Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.'})

2021-06-02 17:49:54.774670 (MainThread): Running with dbt=0.19.1
2021-06-02 17:49:54.958515 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/home/femke/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-06-02 17:49:54.959153 (MainThread): Tracking: tracking
2021-06-02 17:49:54.969497 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4c02980e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4c042b5160>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4c042b5520>]}
2021-06-02 17:49:54.988926 (MainThread): Partial parsing not enabled
2021-06-02 17:49:54.989741 (MainThread): Parsing macros/catalog.sql
2021-06-02 17:49:55.002718 (MainThread): Parsing macros/adapters.sql
2021-06-02 17:49:55.035990 (MainThread): Parsing macros/etc.sql
2021-06-02 17:49:55.038503 (MainThread): Parsing macros/materializations/snapshot.sql
2021-06-02 17:49:55.040532 (MainThread): Parsing macros/materializations/copy.sql
2021-06-02 17:49:55.044531 (MainThread): Parsing macros/materializations/table.sql
2021-06-02 17:49:55.053311 (MainThread): Parsing macros/materializations/incremental.sql
2021-06-02 17:49:55.066333 (MainThread): Parsing macros/materializations/view.sql
2021-06-02 17:49:55.069491 (MainThread): Parsing macros/materializations/seed.sql
2021-06-02 17:49:55.073506 (MainThread): Parsing macros/core.sql
2021-06-02 17:49:55.077331 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-06-02 17:49:55.078738 (MainThread): Parsing macros/schema_tests/unique.sql
2021-06-02 17:49:55.080476 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-06-02 17:49:55.082339 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-06-02 17:49:55.084802 (MainThread): Parsing macros/materializations/helpers.sql
2021-06-02 17:49:55.093619 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-06-02 17:49:55.095605 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-06-02 17:49:55.101814 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-06-02 17:49:55.123592 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-06-02 17:49:55.148456 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-06-02 17:49:55.149733 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-06-02 17:49:55.162670 (MainThread): Parsing macros/materializations/table/table.sql
2021-06-02 17:49:55.167551 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-06-02 17:49:55.171090 (MainThread): Parsing macros/materializations/view/view.sql
2021-06-02 17:49:55.175412 (MainThread): Parsing macros/materializations/common/merge.sql
2021-06-02 17:49:55.184783 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-06-02 17:49:55.185943 (MainThread): Parsing macros/etc/query.sql
2021-06-02 17:49:55.186819 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-06-02 17:49:55.187417 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-06-02 17:49:55.188809 (MainThread): Parsing macros/etc/datetime.sql
2021-06-02 17:49:55.194761 (MainThread): Parsing macros/etc/is_incremental.sql
2021-06-02 17:49:55.195885 (MainThread): Parsing macros/adapters/common.sql
2021-06-02 17:49:55.227242 (MainThread): Partial parsing not enabled
2021-06-02 17:49:55.243549 (MainThread): Acquiring new bigquery connection "model.resourceplanner.EmployeeDates".
2021-06-02 17:49:55.250392 (MainThread): Acquiring new bigquery connection "model.resourceplanner.trydates".
2021-06-02 17:49:55.253207 (MainThread): Acquiring new bigquery connection "model.resourceplanner.FactTable".
2021-06-02 17:49:55.256004 (MainThread): Acquiring new bigquery connection "model.resourceplanner.my_second_dbt_model".
2021-06-02 17:49:55.259024 (MainThread): Acquiring new bigquery connection "model.resourceplanner.my_first_dbt_model".
2021-06-02 17:49:55.308897 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'bc824b21-e394-42bc-ac3d-00710c516d9f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4c019bf760>]}
2021-06-02 17:49:55.312214 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'bc824b21-e394-42bc-ac3d-00710c516d9f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4c019b3fa0>]}
2021-06-02 17:49:55.312403 (MainThread): Found 5 models, 4 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-06-02 17:49:55.313092 (MainThread): 
2021-06-02 17:49:55.313375 (MainThread): Acquiring new bigquery connection "master".
2021-06-02 17:49:55.314041 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_oef-stage".
2021-06-02 17:49:55.314224 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-06-02 17:49:55.389614 (MainThread): Connection 'master' was properly closed.
2021-06-02 17:49:55.389735 (MainThread): Connection 'list_oef-stage' was properly closed.
2021-06-02 17:49:55.389853 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4c01aa8460>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4c0195d3d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4c0198d7c0>]}
2021-06-02 17:49:55.390004 (MainThread): Flushing usage events
2021-06-02 17:49:55.793738 (MainThread): Encountered an error:
2021-06-02 17:49:55.794141 (MainThread): Runtime Error
  Unable to generate access token, if you're using impersonate_service_account, make sure your initial account has the "roles/iam.serviceAccountTokenCreator" role on the account you are trying to impersonate.
  
  ('invalid_grant: Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.', {'error': 'invalid_grant', 'error_description': 'Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.'})
2021-06-02 17:49:55.795951 (MainThread): Traceback (most recent call last):
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 149, in exception_handler
    yield
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/impl.py", line 203, in query_schemas
    return [ds.dataset_id for ds in all_datasets]
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/impl.py", line 203, in <listcomp>
    return [ds.dataset_id for ds in all_datasets]
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/page_iterator.py", line 212, in _items_iter
    for page in self._page_iter(increment=False):
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/page_iterator.py", line 243, in _page_iter
    page = self._next_page()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/page_iterator.py", line 369, in _next_page
    response = self._get_next_page_response()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/page_iterator.py", line 418, in _get_next_page_response
    return self.api_request(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 369, in api_request
    return self._call_api(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 636, in _call_api
    return call()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/_http.py", line 427, in api_request
    response = self._make_request(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/_http.py", line 291, in _make_request
    return self._do_request(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/_http.py", line 329, in _do_request
    return self.http.request(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/auth/transport/requests.py", line 478, in request
    self.credentials.before_request(auth_request, method, url, request_headers)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/auth/credentials.py", line 133, in before_request
    self.refresh(request)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/oauth2/service_account.py", line 376, in refresh
    access_token, expiry, _ = _client.jwt_grant(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/oauth2/_client.py", line 193, in jwt_grant
    response_data = _token_endpoint_request(request, token_uri, body)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/oauth2/_client.py", line 165, in _token_endpoint_request
    _handle_error_response(response_data)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/oauth2/_client.py", line 60, in _handle_error_response
    raise exceptions.RefreshError(error_details, response_data)
google.auth.exceptions.RefreshError: ('invalid_grant: Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.', {'error': 'invalid_grant', 'error_description': 'Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.'})

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/main.py", line 125, in main
    results, succeeded = handle_and_check(args)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/main.py", line 203, in handle_and_check
    task, res = run_from_args(parsed)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/main.py", line 256, in run_from_args
    results = task.run()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/runnable.py", line 426, in run
    result = self.execute_with_hooks(selected_uids)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/runnable.py", line 383, in execute_with_hooks
    self.before_run(adapter, selected_uids)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/run.py", line 409, in before_run
    self.create_schemas(adapter, selected_uids)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/runnable.py", line 515, in create_schemas
    existing_schemas_lowered.update(ls_future.result())
  File "/usr/lib/python3.8/concurrent/futures/_base.py", line 432, in result
    return self.__get_result()
  File "/usr/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
    raise self._exception
  File "/usr/lib/python3.8/concurrent/futures/thread.py", line 57, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/utils.py", line 469, in connected
    return func(*args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/runnable.py", line 492, in list_schemas
    for s in adapter.list_schemas(database_quoted)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/impl.py", line 205, in list_schemas
    return self.connections._retry_and_handle(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 166, in exception_handler
    raise RuntimeException(message)
dbt.exceptions.RuntimeException: Runtime Error
  Unable to generate access token, if you're using impersonate_service_account, make sure your initial account has the "roles/iam.serviceAccountTokenCreator" role on the account you are trying to impersonate.
  
  ('invalid_grant: Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.', {'error': 'invalid_grant', 'error_description': 'Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.'})

2021-06-02 17:50:45.126055 (MainThread): Running with dbt=0.19.1
2021-06-02 17:50:45.311019 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/home/femke/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-06-02 17:50:45.311800 (MainThread): Tracking: tracking
2021-06-02 17:50:45.331548 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5f70464b80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5f71d58310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5f71d58670>]}
2021-06-02 17:50:45.348114 (MainThread): Partial parsing not enabled
2021-06-02 17:50:45.348894 (MainThread): Parsing macros/catalog.sql
2021-06-02 17:50:45.353652 (MainThread): Parsing macros/adapters.sql
2021-06-02 17:50:45.376373 (MainThread): Parsing macros/etc.sql
2021-06-02 17:50:45.377922 (MainThread): Parsing macros/materializations/snapshot.sql
2021-06-02 17:50:45.379300 (MainThread): Parsing macros/materializations/copy.sql
2021-06-02 17:50:45.382649 (MainThread): Parsing macros/materializations/table.sql
2021-06-02 17:50:45.389914 (MainThread): Parsing macros/materializations/incremental.sql
2021-06-02 17:50:45.399008 (MainThread): Parsing macros/materializations/view.sql
2021-06-02 17:50:45.401001 (MainThread): Parsing macros/materializations/seed.sql
2021-06-02 17:50:45.403640 (MainThread): Parsing macros/core.sql
2021-06-02 17:50:45.406357 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-06-02 17:50:45.407470 (MainThread): Parsing macros/schema_tests/unique.sql
2021-06-02 17:50:45.408647 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-06-02 17:50:45.409930 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-06-02 17:50:45.411816 (MainThread): Parsing macros/materializations/helpers.sql
2021-06-02 17:50:45.417929 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-06-02 17:50:45.419218 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-06-02 17:50:45.423678 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-06-02 17:50:45.438144 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-06-02 17:50:45.459291 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-06-02 17:50:45.460523 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-06-02 17:50:45.473495 (MainThread): Parsing macros/materializations/table/table.sql
2021-06-02 17:50:45.478217 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-06-02 17:50:45.481656 (MainThread): Parsing macros/materializations/view/view.sql
2021-06-02 17:50:45.486156 (MainThread): Parsing macros/materializations/common/merge.sql
2021-06-02 17:50:45.495543 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-06-02 17:50:45.496673 (MainThread): Parsing macros/etc/query.sql
2021-06-02 17:50:45.497447 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-06-02 17:50:45.498098 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-06-02 17:50:45.499739 (MainThread): Parsing macros/etc/datetime.sql
2021-06-02 17:50:45.506453 (MainThread): Parsing macros/etc/is_incremental.sql
2021-06-02 17:50:45.507687 (MainThread): Parsing macros/adapters/common.sql
2021-06-02 17:50:45.542835 (MainThread): Partial parsing not enabled
2021-06-02 17:50:45.559960 (MainThread): Acquiring new bigquery connection "model.resourceplanner.EmployeeDates".
2021-06-02 17:50:45.567859 (MainThread): Acquiring new bigquery connection "model.resourceplanner.trydates".
2021-06-02 17:50:45.570631 (MainThread): Acquiring new bigquery connection "model.resourceplanner.FactTable".
2021-06-02 17:50:45.573020 (MainThread): Acquiring new bigquery connection "model.resourceplanner.my_second_dbt_model".
2021-06-02 17:50:45.575402 (MainThread): Acquiring new bigquery connection "model.resourceplanner.my_first_dbt_model".
2021-06-02 17:50:45.624915 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '9e3b0174-f9f8-46d2-9339-685754372bcc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5f6f424520>]}
2021-06-02 17:50:45.628403 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '9e3b0174-f9f8-46d2-9339-685754372bcc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5f6f4130a0>]}
2021-06-02 17:50:45.628599 (MainThread): Found 5 models, 4 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-06-02 17:50:45.629325 (MainThread): 
2021-06-02 17:50:45.629625 (MainThread): Acquiring new bigquery connection "master".
2021-06-02 17:50:45.630351 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_oef-stage".
2021-06-02 17:50:45.630496 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-06-02 17:50:45.630683 (ThreadPoolExecutor-0_0): Got an error when attempting to create a bigquery client: 'Extra data: line 1 column 9 (char 8)'
2021-06-02 17:50:45.630984 (MainThread): Connection 'master' was properly closed.
2021-06-02 17:50:45.631052 (MainThread): Connection 'list_oef-stage' was properly closed.
2021-06-02 17:50:45.631125 (MainThread): ERROR: Database Error
  Extra data: line 1 column 9 (char 8)
2021-06-02 17:50:45.631329 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5f6f50e5b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5f6f3ddd60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5f6f3e0100>]}
2021-06-02 17:50:45.631477 (MainThread): Flushing usage events
2021-06-02 17:51:36.792575 (MainThread): Running with dbt=0.19.1
2021-06-02 17:51:37.002459 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/home/femke/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-06-02 17:51:37.003232 (MainThread): Tracking: tracking
2021-06-02 17:51:37.019487 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ab10b9df0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ab29ae1c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ab29ae4c0>]}
2021-06-02 17:51:37.035343 (MainThread): Partial parsing not enabled
2021-06-02 17:51:37.036173 (MainThread): Parsing macros/catalog.sql
2021-06-02 17:51:37.041123 (MainThread): Parsing macros/adapters.sql
2021-06-02 17:51:37.065162 (MainThread): Parsing macros/etc.sql
2021-06-02 17:51:37.066591 (MainThread): Parsing macros/materializations/snapshot.sql
2021-06-02 17:51:37.067763 (MainThread): Parsing macros/materializations/copy.sql
2021-06-02 17:51:37.071136 (MainThread): Parsing macros/materializations/table.sql
2021-06-02 17:51:37.078083 (MainThread): Parsing macros/materializations/incremental.sql
2021-06-02 17:51:37.086848 (MainThread): Parsing macros/materializations/view.sql
2021-06-02 17:51:37.088939 (MainThread): Parsing macros/materializations/seed.sql
2021-06-02 17:51:37.091937 (MainThread): Parsing macros/core.sql
2021-06-02 17:51:37.095020 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-06-02 17:51:37.096158 (MainThread): Parsing macros/schema_tests/unique.sql
2021-06-02 17:51:37.097283 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-06-02 17:51:37.098564 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-06-02 17:51:37.100358 (MainThread): Parsing macros/materializations/helpers.sql
2021-06-02 17:51:37.107037 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-06-02 17:51:37.108286 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-06-02 17:51:37.112714 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-06-02 17:51:37.127712 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-06-02 17:51:37.149363 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-06-02 17:51:37.150619 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-06-02 17:51:37.164407 (MainThread): Parsing macros/materializations/table/table.sql
2021-06-02 17:51:37.169318 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-06-02 17:51:37.172961 (MainThread): Parsing macros/materializations/view/view.sql
2021-06-02 17:51:37.177213 (MainThread): Parsing macros/materializations/common/merge.sql
2021-06-02 17:51:37.194983 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-06-02 17:51:37.196356 (MainThread): Parsing macros/etc/query.sql
2021-06-02 17:51:37.197150 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-06-02 17:51:37.197883 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-06-02 17:51:37.199853 (MainThread): Parsing macros/etc/datetime.sql
2021-06-02 17:51:37.210098 (MainThread): Parsing macros/etc/is_incremental.sql
2021-06-02 17:51:37.217766 (MainThread): Parsing macros/adapters/common.sql
2021-06-02 17:51:37.253485 (MainThread): Partial parsing not enabled
2021-06-02 17:51:37.270703 (MainThread): Acquiring new bigquery connection "model.resourceplanner.EmployeeDates".
2021-06-02 17:51:37.278018 (MainThread): Acquiring new bigquery connection "model.resourceplanner.trydates".
2021-06-02 17:51:37.280632 (MainThread): Acquiring new bigquery connection "model.resourceplanner.FactTable".
2021-06-02 17:51:37.283415 (MainThread): Acquiring new bigquery connection "model.resourceplanner.my_second_dbt_model".
2021-06-02 17:51:37.286447 (MainThread): Acquiring new bigquery connection "model.resourceplanner.my_first_dbt_model".
2021-06-02 17:51:37.339568 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'f2706fb7-8c64-450b-9fd0-13c5c2f70976', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ab00f9370>]}
2021-06-02 17:51:37.343123 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'f2706fb7-8c64-450b-9fd0-13c5c2f70976', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ab02dbd30>]}
2021-06-02 17:51:37.343272 (MainThread): Found 5 models, 4 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-06-02 17:51:37.343990 (MainThread): 
2021-06-02 17:51:37.344257 (MainThread): Acquiring new bigquery connection "master".
2021-06-02 17:51:37.345064 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_oef-stage".
2021-06-02 17:51:37.345196 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-06-02 17:51:37.414885 (MainThread): Connection 'master' was properly closed.
2021-06-02 17:51:37.415267 (MainThread): Connection 'list_oef-stage' was properly closed.
2021-06-02 17:51:37.415403 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ab01e1400>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ab00b2f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ab0215910>]}
2021-06-02 17:51:37.415584 (MainThread): Flushing usage events
2021-06-02 17:51:37.793592 (MainThread): Encountered an error:
2021-06-02 17:51:37.794001 (MainThread): Runtime Error
  Unable to generate access token, if you're using impersonate_service_account, make sure your initial account has the "roles/iam.serviceAccountTokenCreator" role on the account you are trying to impersonate.
  
  ('invalid_grant: Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.', {'error': 'invalid_grant', 'error_description': 'Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.'})
2021-06-02 17:51:37.796285 (MainThread): Traceback (most recent call last):
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 149, in exception_handler
    yield
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/impl.py", line 203, in query_schemas
    return [ds.dataset_id for ds in all_datasets]
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/impl.py", line 203, in <listcomp>
    return [ds.dataset_id for ds in all_datasets]
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/page_iterator.py", line 212, in _items_iter
    for page in self._page_iter(increment=False):
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/page_iterator.py", line 243, in _page_iter
    page = self._next_page()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/page_iterator.py", line 369, in _next_page
    response = self._get_next_page_response()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/page_iterator.py", line 418, in _get_next_page_response
    return self.api_request(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 369, in api_request
    return self._call_api(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 636, in _call_api
    return call()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/_http.py", line 427, in api_request
    response = self._make_request(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/_http.py", line 291, in _make_request
    return self._do_request(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/cloud/_http.py", line 329, in _do_request
    return self.http.request(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/auth/transport/requests.py", line 478, in request
    self.credentials.before_request(auth_request, method, url, request_headers)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/auth/credentials.py", line 133, in before_request
    self.refresh(request)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/oauth2/service_account.py", line 376, in refresh
    access_token, expiry, _ = _client.jwt_grant(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/oauth2/_client.py", line 193, in jwt_grant
    response_data = _token_endpoint_request(request, token_uri, body)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/oauth2/_client.py", line 165, in _token_endpoint_request
    _handle_error_response(response_data)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/google/oauth2/_client.py", line 60, in _handle_error_response
    raise exceptions.RefreshError(error_details, response_data)
google.auth.exceptions.RefreshError: ('invalid_grant: Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.', {'error': 'invalid_grant', 'error_description': 'Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.'})

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/main.py", line 125, in main
    results, succeeded = handle_and_check(args)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/main.py", line 203, in handle_and_check
    task, res = run_from_args(parsed)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/main.py", line 256, in run_from_args
    results = task.run()
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/runnable.py", line 426, in run
    result = self.execute_with_hooks(selected_uids)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/runnable.py", line 383, in execute_with_hooks
    self.before_run(adapter, selected_uids)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/run.py", line 409, in before_run
    self.create_schemas(adapter, selected_uids)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/runnable.py", line 515, in create_schemas
    existing_schemas_lowered.update(ls_future.result())
  File "/usr/lib/python3.8/concurrent/futures/_base.py", line 432, in result
    return self.__get_result()
  File "/usr/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
    raise self._exception
  File "/usr/lib/python3.8/concurrent/futures/thread.py", line 57, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/utils.py", line 469, in connected
    return func(*args, **kwargs)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/task/runnable.py", line 492, in list_schemas
    for s in adapter.list_schemas(database_quoted)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/impl.py", line 205, in list_schemas
    return self.connections._retry_and_handle(
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/home/femke/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 166, in exception_handler
    raise RuntimeException(message)
dbt.exceptions.RuntimeException: Runtime Error
  Unable to generate access token, if you're using impersonate_service_account, make sure your initial account has the "roles/iam.serviceAccountTokenCreator" role on the account you are trying to impersonate.
  
  ('invalid_grant: Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.', {'error': 'invalid_grant', 'error_description': 'Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.'})

2021-06-03 10:06:23.447913 (MainThread): Running with dbt=0.19.1
2021-06-03 10:06:23.639943 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/home/femke/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-06-03 10:06:23.640585 (MainThread): Tracking: tracking
2021-06-03 10:06:23.655173 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f74c8c10fa0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f74c8c88490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f74c8c204c0>]}
2021-06-03 10:06:23.671055 (MainThread): Partial parsing not enabled
2021-06-03 10:06:23.671805 (MainThread): Parsing macros/catalog.sql
2021-06-03 10:06:23.680686 (MainThread): Parsing macros/adapters.sql
2021-06-03 10:06:23.701710 (MainThread): Parsing macros/etc.sql
2021-06-03 10:06:23.703282 (MainThread): Parsing macros/materializations/snapshot.sql
2021-06-03 10:06:23.704530 (MainThread): Parsing macros/materializations/copy.sql
2021-06-03 10:06:23.707833 (MainThread): Parsing macros/materializations/table.sql
2021-06-03 10:06:23.714977 (MainThread): Parsing macros/materializations/incremental.sql
2021-06-03 10:06:23.724263 (MainThread): Parsing macros/materializations/view.sql
2021-06-03 10:06:23.726314 (MainThread): Parsing macros/materializations/seed.sql
2021-06-03 10:06:23.728661 (MainThread): Parsing macros/core.sql
2021-06-03 10:06:23.731341 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-06-03 10:06:23.732358 (MainThread): Parsing macros/schema_tests/unique.sql
2021-06-03 10:06:23.733610 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-06-03 10:06:23.734995 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-06-03 10:06:23.736926 (MainThread): Parsing macros/materializations/helpers.sql
2021-06-03 10:06:23.743167 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-06-03 10:06:23.744472 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-06-03 10:06:23.749193 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-06-03 10:06:23.763559 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-06-03 10:06:23.785464 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-06-03 10:06:23.786746 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-06-03 10:06:23.799475 (MainThread): Parsing macros/materializations/table/table.sql
2021-06-03 10:06:23.804896 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-06-03 10:06:23.808480 (MainThread): Parsing macros/materializations/view/view.sql
2021-06-03 10:06:23.812764 (MainThread): Parsing macros/materializations/common/merge.sql
2021-06-03 10:06:23.822147 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-06-03 10:06:23.823389 (MainThread): Parsing macros/etc/query.sql
2021-06-03 10:06:23.824118 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-06-03 10:06:23.824736 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-06-03 10:06:23.826161 (MainThread): Parsing macros/etc/datetime.sql
2021-06-03 10:06:23.832057 (MainThread): Parsing macros/etc/is_incremental.sql
2021-06-03 10:06:23.833191 (MainThread): Parsing macros/adapters/common.sql
2021-06-03 10:06:23.865625 (MainThread): Partial parsing not enabled
2021-06-03 10:06:23.882052 (MainThread): Acquiring new bigquery connection "model.resourceplanner.EmployeeDates".
2021-06-03 10:06:23.889528 (MainThread): Acquiring new bigquery connection "model.resourceplanner.trydates".
2021-06-03 10:06:23.892146 (MainThread): Acquiring new bigquery connection "model.resourceplanner.FactTable".
2021-06-03 10:06:23.894748 (MainThread): Acquiring new bigquery connection "model.resourceplanner.my_second_dbt_model".
2021-06-03 10:06:23.897294 (MainThread): Acquiring new bigquery connection "model.resourceplanner.my_first_dbt_model".
2021-06-03 10:06:23.947536 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '4fe1fc1b-ef93-4a40-8815-7a68b6b6c2c1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f74c6325310>]}
2021-06-03 10:06:23.951125 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '4fe1fc1b-ef93-4a40-8815-7a68b6b6c2c1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f74c631aee0>]}
2021-06-03 10:06:23.951339 (MainThread): Found 5 models, 4 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-06-03 10:06:23.952063 (MainThread): 
2021-06-03 10:06:23.952325 (MainThread): Acquiring new bigquery connection "master".
2021-06-03 10:06:23.953013 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_oef-stage".
2021-06-03 10:06:23.953142 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-06-03 10:06:24.479518 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_oef-stage_TestRecoursePlanner".
2021-06-03 10:06:24.479684 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2021-06-03 10:06:24.482878 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-06-03 10:06:24.666547 (MainThread): 12:06:24 | Concurrency: 5 threads (target='dev')
2021-06-03 10:06:24.666803 (MainThread): 12:06:24 | 
2021-06-03 10:06:24.668677 (Thread-1): Began running node model.resourceplanner.my_first_dbt_model
2021-06-03 10:06:24.668875 (Thread-1): 12:06:24 | 1 of 5 START table model TestRecoursePlanner.my_first_dbt_model...... [RUN]
2021-06-03 10:06:24.668978 (Thread-2): Began running node model.resourceplanner.EmployeeDates
2021-06-03 10:06:24.669086 (Thread-2): 12:06:24 | 2 of 5 START table model TestRecoursePlanner.EmployeeDates........... [RUN]
2021-06-03 10:06:24.669153 (Thread-3): Began running node model.resourceplanner.FactTable
2021-06-03 10:06:24.669251 (Thread-3): 12:06:24 | 3 of 5 START table model TestRecoursePlanner.FactTable............... [RUN]
2021-06-03 10:06:24.669313 (Thread-4): Began running node model.resourceplanner.trydates
2021-06-03 10:06:24.669410 (Thread-4): 12:06:24 | 4 of 5 START table model TestRecoursePlanner.trydates................ [RUN]
2021-06-03 10:06:24.669606 (Thread-1): Acquiring new bigquery connection "model.resourceplanner.my_first_dbt_model".
2021-06-03 10:06:24.669681 (Thread-1): Compiling model.resourceplanner.my_first_dbt_model
2021-06-03 10:06:24.674286 (Thread-1): Writing injected SQL for node "model.resourceplanner.my_first_dbt_model"
2021-06-03 10:06:24.675137 (Thread-2): Acquiring new bigquery connection "model.resourceplanner.EmployeeDates".
2021-06-03 10:06:24.675711 (Thread-2): Compiling model.resourceplanner.EmployeeDates
2021-06-03 10:06:24.677257 (Thread-2): Writing injected SQL for node "model.resourceplanner.EmployeeDates"
2021-06-03 10:06:24.675529 (Thread-4): Acquiring new bigquery connection "model.resourceplanner.trydates".
2021-06-03 10:06:24.683028 (Thread-4): Compiling model.resourceplanner.trydates
2021-06-03 10:06:24.686276 (Thread-4): unclosed <socket.socket fd=5, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.0.2.15', 55276), raddr=('142.250.179.170', 443)>
2021-06-03 10:06:24.675343 (Thread-3): Acquiring new bigquery connection "model.resourceplanner.FactTable".
2021-06-03 10:06:24.686680 (Thread-3): Compiling model.resourceplanner.FactTable
2021-06-03 10:06:24.677517 (Thread-2): finished collecting timing info
2021-06-03 10:06:24.686530 (Thread-4): unclosed <socket.socket fd=6, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.0.2.15', 45136), raddr=('216.58.208.106', 443)>
2021-06-03 10:06:24.709518 (Thread-4): unclosed <socket.socket fd=8, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.0.2.15', 45140), raddr=('216.58.208.106', 443)>
2021-06-03 10:06:24.709781 (Thread-4): unclosed <socket.socket fd=7, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.0.2.15', 55280), raddr=('142.250.179.170', 443)>
2021-06-03 10:06:24.690887 (Thread-1): finished collecting timing info
2021-06-03 10:06:24.690630 (Thread-3): Writing injected SQL for node "model.resourceplanner.FactTable"
2021-06-03 10:06:24.723394 (Thread-4): Writing injected SQL for node "model.resourceplanner.trydates"
2021-06-03 10:06:24.736081 (Thread-4): finished collecting timing info
2021-06-03 10:06:24.737509 (Thread-4): Opening a new connection, currently in state init
2021-06-03 10:06:24.735865 (Thread-3): finished collecting timing info
2021-06-03 10:06:24.738955 (Thread-3): Opening a new connection, currently in state init
2021-06-03 10:06:24.734938 (Thread-2): Opening a new connection, currently in state closed
2021-06-03 10:06:24.750268 (Thread-1): Opening a new connection, currently in state closed
2021-06-03 10:06:24.763219 (Thread-3): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-06-03 10:06:24.766243 (Thread-4): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-06-03 10:06:24.758350 (Thread-2): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-06-03 10:06:24.770549 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-06-03 10:06:24.979055 (Thread-2): Writing runtime SQL for node "model.resourceplanner.EmployeeDates"
2021-06-03 10:06:24.980270 (Thread-4): Writing runtime SQL for node "model.resourceplanner.trydates"
2021-06-03 10:06:24.981391 (Thread-3): Writing runtime SQL for node "model.resourceplanner.FactTable"
2021-06-03 10:06:24.985341 (Thread-4): On model.resourceplanner.trydates: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "Bigquery", "target_name": "dev", "node_id": "model.resourceplanner.trydates"} */


  create or replace table `oef-stage`.`TestRecoursePlanner`.`trydates`
  
  
  OPTIONS()
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/


with source_data as (

    select 1 as id
    union all
    select null as id

)

select M.ID, E.EmployeeID, CU.CustomerID,CO.CompanyID, M.DateStart, M.DateEnd, M.Monday, M.Tuesday, M.Wednesday , M.Thursday , M.Friday
from oef-stage.TestRecoursePlanner.MainData M
INNER JOIN oef-stage.TestRecoursePlanner.Employee E
ON M.Employee = E.Firstname
INNER JOIN oef-stage.TestRecoursePlanner.Customer CU
ON M.Customer = CU.Customername
INNER JOIN oef-stage.TestRecoursePlanner.Company CO
ON M.Company = CO.Companyname
ORDER BY M.ID

/*
    Uncomment the line below to remove records with null `id` values
*/
  );
    
2021-06-03 10:06:24.985877 (Thread-3): On model.resourceplanner.FactTable: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "Bigquery", "target_name": "dev", "node_id": "model.resourceplanner.FactTable"} */


  create or replace table `oef-stage`.`TestRecoursePlanner`.`FactTable`
  
  
  OPTIONS()
  as (
    


SELECT
  T.id,
  TD.ID AS ProjectID,
  TD.EmployeeID,
  TD.CompanyID,
  TD.CustomerID,
  T.PM_AM,
  T.full_date,
  T.day_name,
  CASE
    WHEN T.day_name = "Monday" THEN IF (TD.Monday = 'Available', '0', IF (TD.Monday = 'Full', '0,5', IF (PM_AM = TD.Monday, '0,5', '0') ))
    WHEN T.day_name = "Tuesday" THEN IF (TD.Tuesday = 'Available', '0', IF (TD.Tuesday = 'Full', '0,5', IF (PM_AM = TD.Tuesday, '0,5', '0') ))
    WHEN T.day_name = "Wednesday" THEN IF (TD.Wednesday = 'Available', '0', IF (TD.Wednesday = 'Full', '0,5', IF (PM_AM = TD.Wednesday, '0,5', '0') ))
    WHEN T.day_name = "Thursday" THEN IF (TD.Thursday = 'Available', '0', IF (TD.Thursday = 'Full', '0,5', IF (PM_AM = TD.Thursday, '0,5', '0') ))
    WHEN T.day_name = "Friday" THEN IF (TD.Friday = 'Available', '0', IF (TD.Friday  = 'Full', '0,5', IF (PM_AM = TD.Friday , '0,5', '0') ))
  ELSE
  '0'
END
  AS Is_Booked
FROM
  `oef-stage.TestRecoursePlanner.Time` T
CROSS JOIN
  `oef-stage.TestRecoursePlanner.trydates` TD

WHERE T.full_Date  BETWEEN TD.DateStart
  AND TD.DateEnd
ORDER BY
  T.full_date
  );
    
2021-06-03 10:06:24.992512 (Thread-2): On model.resourceplanner.EmployeeDates: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "Bigquery", "target_name": "dev", "node_id": "model.resourceplanner.EmployeeDates"} */


  create or replace table `oef-stage`.`TestRecoursePlanner`.`EmployeeDates`
  
  
  OPTIONS()
  as (
    

SELECT DISTINCT E.EmployeeID,E.Firstname, T.full_date
FROM oef-stage.TestRecoursePlanner.Time T
CROSS JOIN oef-stage.TestRecoursePlanner.Employee E
ORDER BY T.full_date
  );
    
2021-06-03 10:06:24.995937 (Thread-1): Writing runtime SQL for node "model.resourceplanner.my_first_dbt_model"
2021-06-03 10:06:24.999099 (Thread-1): On model.resourceplanner.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "Bigquery", "target_name": "dev", "node_id": "model.resourceplanner.my_first_dbt_model"} */


  create or replace table `oef-stage`.`TestRecoursePlanner`.`my_first_dbt_model`
  
  
  OPTIONS()
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select M.ID, E.EmployeeID, CU.CustomerID,CO.CompanyID
from oef-stage.TestRecoursePlanner.MainData M
INNER JOIN oef-stage.TestRecoursePlanner.Employee E
ON M.Employee = E.Firstname
INNER JOIN oef-stage.TestRecoursePlanner.Customer CU
ON M.Customer = CU.Customername
INNER JOIN oef-stage.TestRecoursePlanner.Company CO
ON M.Company = CO.Companyname
ORDER BY M.ID

/*
    Uncomment the line below to remove records with null `id` values
*/
  );
    
2021-06-03 10:06:27.302234 (Thread-3): finished collecting timing info
2021-06-03 10:06:27.304368 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4fe1fc1b-ef93-4a40-8815-7a68b6b6c2c1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f74c415f220>]}
2021-06-03 10:06:27.304634 (Thread-3): 12:06:27 | 3 of 5 OK created table model TestRecoursePlanner.FactTable.......... [CREATE TABLE (992.0 rows, 251.6 KB processed) in 2.63s]
2021-06-03 10:06:27.304820 (Thread-3): Finished running node model.resourceplanner.FactTable
2021-06-03 10:06:27.871615 (Thread-2): finished collecting timing info
2021-06-03 10:06:27.871940 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4fe1fc1b-ef93-4a40-8815-7a68b6b6c2c1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f74c4137910>]}
2021-06-03 10:06:27.872155 (Thread-2): 12:06:27 | 2 of 5 OK created table model TestRecoursePlanner.EmployeeDates...... [CREATE TABLE (43.8k rows, 57.8 KB processed) in 3.20s]
2021-06-03 10:06:27.872367 (Thread-2): Finished running node model.resourceplanner.EmployeeDates
2021-06-03 10:06:29.123607 (Thread-4): finished collecting timing info
2021-06-03 10:06:29.124451 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4fe1fc1b-ef93-4a40-8815-7a68b6b6c2c1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f74c415f040>]}
2021-06-03 10:06:29.124770 (Thread-4): 12:06:29 | 4 of 5 OK created table model TestRecoursePlanner.trydates........... [CREATE TABLE (14.0 rows, 5.4 KB processed) in 4.45s]
2021-06-03 10:06:29.124953 (Thread-4): Finished running node model.resourceplanner.trydates
2021-06-03 10:06:29.528753 (Thread-1): finished collecting timing info
2021-06-03 10:06:29.529073 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4fe1fc1b-ef93-4a40-8815-7a68b6b6c2c1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f74c41a1d30>]}
2021-06-03 10:06:29.529285 (Thread-1): 12:06:29 | 1 of 5 OK created table model TestRecoursePlanner.my_first_dbt_model. [CREATE TABLE (14.0 rows, 5.4 KB processed) in 4.86s]
2021-06-03 10:06:29.529515 (Thread-1): Finished running node model.resourceplanner.my_first_dbt_model
2021-06-03 10:06:29.529920 (Thread-5): Began running node model.resourceplanner.my_second_dbt_model
2021-06-03 10:06:29.530043 (Thread-5): 12:06:29 | 5 of 5 START view model TestRecoursePlanner.my_second_dbt_model...... [RUN]
2021-06-03 10:06:29.530243 (Thread-5): Acquiring new bigquery connection "model.resourceplanner.my_second_dbt_model".
2021-06-03 10:06:29.530374 (Thread-5): Compiling model.resourceplanner.my_second_dbt_model
2021-06-03 10:06:29.531930 (Thread-5): Writing injected SQL for node "model.resourceplanner.my_second_dbt_model"
2021-06-03 10:06:29.532195 (Thread-5): finished collecting timing info
2021-06-03 10:06:29.552898 (Thread-5): Writing runtime SQL for node "model.resourceplanner.my_second_dbt_model"
2021-06-03 10:06:29.553338 (Thread-5): Opening a new connection, currently in state init
2021-06-03 10:06:29.559337 (Thread-5): On model.resourceplanner.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "Bigquery", "target_name": "dev", "node_id": "model.resourceplanner.my_second_dbt_model"} */


  create or replace view `oef-stage`.`TestRecoursePlanner`.`my_second_dbt_model`
  OPTIONS()
  as -- Use the `ref` function to select from other models

select *
from `oef-stage`.`TestRecoursePlanner`.`my_first_dbt_model`;


2021-06-03 10:06:30.785050 (Thread-5): finished collecting timing info
2021-06-03 10:06:30.785366 (Thread-5): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4fe1fc1b-ef93-4a40-8815-7a68b6b6c2c1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f74c415f0d0>]}
2021-06-03 10:06:30.785611 (Thread-5): 12:06:30 | 5 of 5 OK created view model TestRecoursePlanner.my_second_dbt_model. [OK in 1.26s]
2021-06-03 10:06:30.785818 (Thread-5): Finished running node model.resourceplanner.my_second_dbt_model
2021-06-03 10:06:30.786845 (MainThread): Acquiring new bigquery connection "master".
2021-06-03 10:06:30.787032 (MainThread): 12:06:30 | 
2021-06-03 10:06:30.787151 (MainThread): 12:06:30 | Finished running 4 table models, 1 view model in 6.83s.
2021-06-03 10:06:30.787242 (MainThread): Connection 'master' was properly closed.
2021-06-03 10:06:30.787285 (MainThread): Connection 'model.resourceplanner.my_first_dbt_model' was properly closed.
2021-06-03 10:06:30.787318 (MainThread): Connection 'model.resourceplanner.EmployeeDates' was properly closed.
2021-06-03 10:06:30.787349 (MainThread): Connection 'model.resourceplanner.FactTable' was properly closed.
2021-06-03 10:06:30.787379 (MainThread): Connection 'model.resourceplanner.trydates' was properly closed.
2021-06-03 10:06:30.787409 (MainThread): Connection 'model.resourceplanner.my_second_dbt_model' was properly closed.
2021-06-03 10:06:30.788300 (MainThread): unclosed <socket.socket fd=15, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.0.2.15', 55300), raddr=('142.250.179.170', 443)>
2021-06-03 10:06:30.788530 (MainThread): unclosed <socket.socket fd=16, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.0.2.15', 45160), raddr=('216.58.208.106', 443)>
2021-06-03 10:06:30.791625 (MainThread): unclosed <socket.socket fd=5, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.0.2.15', 55284), raddr=('142.250.179.170', 443)>
2021-06-03 10:06:30.791828 (MainThread): unclosed <socket.socket fd=6, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.0.2.15', 55286), raddr=('142.250.179.170', 443)>
2021-06-03 10:06:30.792050 (MainThread): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.0.2.15', 45152), raddr=('216.58.208.106', 443)>
2021-06-03 10:06:30.792198 (MainThread): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.0.2.15', 45154), raddr=('216.58.208.106', 443)>
2021-06-03 10:06:30.792338 (MainThread): unclosed <socket.socket fd=14, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.0.2.15', 45156), raddr=('216.58.208.106', 443)>
2021-06-03 10:06:30.792493 (MainThread): unclosed <socket.socket fd=8, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.0.2.15', 55288), raddr=('142.250.179.170', 443)>
2021-06-03 10:06:30.793472 (MainThread): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.0.2.15', 45150), raddr=('216.58.208.106', 443)>
2021-06-03 10:06:30.793652 (MainThread): unclosed <socket.socket fd=7, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.0.2.15', 55290), raddr=('142.250.179.170', 443)>
2021-06-03 10:06:30.804762 (MainThread): 
2021-06-03 10:06:30.805235 (MainThread): Completed successfully
2021-06-03 10:06:30.805561 (MainThread): 
Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
2021-06-03 10:06:30.805789 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f74c6337b20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f74c6337eb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f74c4105190>]}
2021-06-03 10:06:30.805952 (MainThread): Flushing usage events
